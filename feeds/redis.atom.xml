<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>ning</title><link href="/" rel="alternate"></link><link href="http://idning.github.io/feeds/redis.atom.xml" rel="self"></link><id>/</id><updated>2014-11-02T11:41:38+08:00</updated><entry><title>redis-data-migrate</title><link href="/redis-data-migrate.html" rel="alternate"></link><updated>2014-11-02T11:41:38+08:00</updated><author><name>ning</name></author><id>tag:,2014-11-02:redis-data-migrate.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么要设计这样的扩容方式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id8"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;怎么实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id9"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof" id="id10"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;aof不是幂等的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id11"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;切流量时的不一致&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id12"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-mgr" id="id13"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr 集成&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id14"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;在 &lt;a class="reference external" href="/redis-instance-migrate.html"&gt;这篇blog&lt;/a&gt; 里面提到2种扩容:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;一个是 redis-mgr 中redis实例的迁移, 迁到一个内存大的机器&lt;/li&gt;
&lt;li&gt;另外一个是新搭建集群, 把数据迁移过去.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里考虑第二种思路.&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么要设计这样的扩容方式&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;简单可依赖&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;从架构上, 这不需要像redis-cluster那样复杂的重新设计, 用现有的redis就可以完成扩容,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不需要升级redis服务端, 也不需要升级client端(redis-cluster需要client支持)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;这套方案可以用于:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;从单机redis迁移到 redis-mgr / twemproxy 管理的 集群.&lt;/li&gt;
&lt;li&gt;从一种集群架构迁移到另一种, 比如迁移到官方redis3.0 集群&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总之, 就算redis3.0 的cluster 成熟以后, 还是需要这样的一套迁移方案.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;怎么实现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;mysql 的主从同步是基于binlog, redis主从是一个op buf, mongo主从同步是oplog.&lt;/p&gt;
&lt;p&gt;redis里的aof就是类似binlog, 记录每个操作的log&lt;/p&gt;
&lt;p&gt;所以, 我们可以利用aof, 把它当作binlog, 用于做迁移, 具体的迁移我们在mysql, mongo里面都多次用过了, 分三步:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;迁移基准数据&lt;/li&gt;
&lt;li&gt;追增量&lt;/li&gt;
&lt;li&gt;追上后, 上层切流量.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;redis的aof包含了基准数据和增量, 所以我们只需要把旧集群中redis实例上的aof重放到新集群, 重放追上时修改上层, 把入口换为新集群即可.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="aof"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;aof不是幂等的&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;aof不像binlog那样可以重做 &lt;tt class="docutils literal"&gt;redolog&lt;/tt&gt;, binlog 记录的操作是 &lt;tt class="docutils literal"&gt;幂等(idempotent)&lt;/tt&gt; 的, 意味着如果失败了, 可以重做一次.&lt;/p&gt;
&lt;p&gt;这是因为binlog记录的是操作的结果, 比如:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
op                  log
---------------------------
set x 0             x = 0
incr x              x = 1
incr x              x = 2
&lt;/pre&gt;
&lt;p&gt;但是redis的aof记录的是操作:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
op                  log
---------------------------
set x 0             x = 0
incr x              incr x
incr x              incr x
&lt;/pre&gt;
&lt;p&gt;这就是说, 如果我们在重放aof的过程中出错(比如网络中断):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;不能继续(不好找到上次同步到哪),&lt;/li&gt;
&lt;li&gt;也不能重新重放一次, (incr两次, 值就错了)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;只能清除目标集群的数据重新迁移一次 ( &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-mgr&lt;/span&gt;&lt;/tt&gt; 里面有 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;clean-keys&lt;/span&gt;&lt;/tt&gt; 命令按照前缀清除)&lt;/p&gt;
&lt;p&gt;不过, 好在redis单实例的afo数据都不大, 一般10G左右, 重放大约20min就能完成, 出错的概率也很小. (这也是redis可以这样做, 而其他持久存储比如mysql, mongo必须支持断点同步的原因)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;切流量时的不一致&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;前面说的步骤是:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;追aof&lt;/li&gt;
&lt;li&gt;追上后, 切流量.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;追aof是一个动态的过程, 追上后, 新的写操作马上就来, 所以这里追上的意思是说, 新的写入马上会被消化掉.&lt;/p&gt;
&lt;p&gt;但是考虑这样一种场景:&lt;/p&gt;
&lt;p&gt;假设client上做对x做两次set(一个机器上做两次, 或者两个app-server上分别做):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
client          old_cluster         new_cluster
-----------------------------------------------
set x 1(a)      set x 1(客户操作)
-----------------------------------------------&amp;gt; 切流量到new_cluster
set x 2(b)                          set x 2 (客户操作)
                                    set x 1 (b 操作被重放到 new_cluster)
&lt;/pre&gt;
&lt;p&gt;a操作还没同步到new_cluster, 流量就已经切到了new_cluster, 这时候对同一个key的更新, 会被老集群上的操作覆盖掉.&lt;/p&gt;
&lt;p&gt;解决:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;这个短暂的不一致, 对多数业务, 是能容忍的(很少有业务会高速更新同一个key)&lt;/li&gt;
&lt;li&gt;如果非要达到一致, 当追aof追上后, app-server停写, 等待彻底追上(此时老集群的aof不会有更新了), 然后再切流量.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id12"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;有两份代码:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;推荐 &lt;a class="reference external" href="https://github.com/cen-li/redis/blob/redis-2.8.3_replay-aof/src/redis-replay-aof.c"&gt;https://github.com/cen-li/redis/blob/redis-2.8.3_replay-aof/src/redis-replay-aof.c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;写着玩: &lt;a class="reference external" href="https://github.com/idning/redis/blob/replay/src/redis-cli.c"&gt;https://github.com/idning/redis/blob/replay/src/redis-cli.c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原理就是不断的看aof文件是否有更新, 有更新的话写到目标集群, 支持 按前缀过滤, 加前缀, 换前缀之类的操作.&lt;/p&gt;
&lt;div class="section" id="redis-mgr"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id13"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr 集成&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-mgr&lt;/span&gt;&lt;/tt&gt; 里面集成了一个命令来方便操作:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#从cluster1迁移到cluster5
./bin/deploy.py cluster1 replay_aof cluster5 'prefix_'
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id14"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;文档: &lt;a class="reference external" href="https://github.com/idning/redis-mgr/blob/master/doc/scalablity.rst"&gt;https://github.com/idning/redis-mgr/blob/master/doc/scalablity.rst&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis设计与实现 笔记</title><link href="/book-redis-implement.html" rel="alternate"></link><updated>2014-09-29T17:39:16+08:00</updated><author><name>ning</name></author><id>tag:,2014-09-29:book-redis-implement.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c4-hash" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;c4 hash&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#rehash" id="id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;rehash&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;渐进式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c5-skiplist" id="id7"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;c5 跳表(skiplist)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c8-object" id="id8"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;c8 object(类型和编码)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c9" id="id9"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;c9 数据库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c16-sentinel" id="id10"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;c16 sentinel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;事物&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#lua" id="id12"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;lua&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id13"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;读的比较粗, 部分笔记:&lt;/p&gt;
&lt;div class="section" id="c4-hash"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;c4 hash&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="rehash"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;rehash&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;扩展与收缩(rehash) 下面条件满足时:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;没有在进行bgsave或bgrewriteaof, 并且hash表的负载因子大于1&lt;/li&gt;
&lt;li&gt;在进行bgsave或bgrewriteaof, 并且hash表的负载因子大于5&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因为在bgsave或bgrewriteaof的时候, 有子进程存在, redis会尽量避免进行rehash, 从而避免不必要的内存写入, 节约内存  - 这个分析很赞.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;渐进式&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;每次操作一个桶.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="c5-skiplist"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;c5 跳表(skiplist)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;sorted set 的实现:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
方法1: skip list
方法2: skiplist + hash
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="c8-object"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;c8 object(类型和编码)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;几种编码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
REDIS_ENCODING_RAW 0            // 编码为字符串
REDIS_ENCODING_INT 1            // 编码为整数
REDIS_ENCODING_HT 2             // 编码为哈希表
REDIS_ENCODING_ZIPMAP 3         // 编码为 zipmap
REDIS_ENCODING_LINKEDLIST 4     // 编码为双端链表
REDIS_ENCODING_ZIPLIST 5        // 编码为压缩列表
REDIS_ENCODING_INTSET 6         // 编码为整数集合
REDIS_ENCODING_SKIPLIST 7       // 编码为跳跃表
&lt;/pre&gt;
&lt;p&gt;不同类型可能的编码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
string      REDIS_ENCODING_INT
string      REDIS_ENCODING_EMBSTR
string      REDIS_ENCODING_RAW
list        REDIS_ENCODING_ZIPLIST
list        REDIS_ENCODING_LINKEDLIST
hash        REDIS_ENCODING_INTSET
hash        REDIS_ENCODING_HT
set         REDIS_ENCODING_INTSET
set         REDIS_ENCODING_HT
zset        REDIS_ENCODING_ZIPLIST
zset        REDIS_ENCODING_SKIPLIST
&lt;/pre&gt;
&lt;p&gt;object 命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
object encoding numberso
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="c9"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;c9 数据库&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;expire 保存在一个单独的dict里面:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
-----------------------------------------------------------------------

                        +------+
             ---------&amp;gt; |dict  |
             |          +======+
             |          |a     |  -&amp;gt; string val
             |          +------+
+---------+  |          |b     |  -&amp;gt; string val
|redisDB  |  |          +------+
+=========+  |          |c     |  -&amp;gt; string val
|dict     | --          +------+
+---------+
|expires  | --          +------+
+---------+  |--------&amp;gt; |dict  |
                        +======+
                        |a     |  -&amp;gt; longlong 1411987363000
                        +------+
                        |b     |  -&amp;gt; longlong 1411987363000
                        +------+
&lt;/pre&gt;
&lt;p&gt;p113 主从在复制问题上可能出现不一致:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;从上不会主动淘汰key,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不会在cron上尝试删除key&lt;/li&gt;
&lt;li&gt;就算访问到一个已经过期的key, 也不会删除, 而是返回它&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;从库只会从主同步 del命令.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="c16-sentinel"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id10"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;c16 sentinel&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;p229讲的很细致, 不过还是太复杂.&lt;/p&gt;
&lt;p&gt;INFO: 发现slave
publish: 发现其它sentinel&lt;/p&gt;
&lt;p&gt;p244, sentinel选举是 &lt;strong&gt;raft&lt;/strong&gt; 算法 (得看下论文)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id11"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;事物&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;watch 其实是一种cas概念(总算懂了)&lt;/li&gt;
&lt;li&gt;redis事物满足ACID&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="lua"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id12"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;lua&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;对于有些lua中执行的命令, 会对输出做一个排序:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;比如 smember, keys等, 为了保证每次在lua中调用顺序一致.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;如果执行lua超时阻塞, 那么redis 只会接受 shutdown nosave / script kill 命令&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;有的地方比较罗嗦, 比如一个set操作完了之后内存是怎么样的, 不过换句话说, 就是细致.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;很多之前不知道的知识点(不过确实很少用到)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;比如: info/shutdown/publish 这几个命令可以在loading 状态下调用.&lt;/li&gt;
&lt;li&gt;p187, qps的计算: 16个取样, 取平均值.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;关于淘汰: redis 记录访问时间, 从而可以做近似lru&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;v1 链接: &lt;a class="reference external" href="https://github.com/huangz1990/redisbook/"&gt;https://github.com/huangz1990/redisbook/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>hhvm-redis-bug</title><link href="/hhvm-redis-bug.html" rel="alternate"></link><updated>2014-09-09T21:29:40+08:00</updated><author><name>ning</name></author><id>tag:,2014-09-09:hhvm-redis-bug.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试问题复现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fake-redis" id="id14"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;fake-redis 复现&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id15"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;测试1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id16"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis" id="id17"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis库的问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mock" id="id18"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id19"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;修复&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fgets" id="id20"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id21"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id22"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;情况1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id23"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;情况2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fgets-bug" id="id24"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets bug&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id25"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;看实现&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id26"&gt;4.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#readimpl" id="id27"&gt;4.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;readImpl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id28"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hang" id="id29"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;模拟hang住的情况&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id30"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id31"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;更新&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;最近发现hhvm和redis的交互偶尔hang住(这里连接没有设置超时), 分析有三种可能性:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;server端返回错误的response.
比如返回一个超大的 length:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$10240000\r\nabcd\4\n
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
客户端读到这个大数, 但是发现没有这么多字节要读, 于是就一直等着读&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;client解析的时候出错, 如果读到正确的 &lt;tt class="docutils literal"&gt;$12\r\n&lt;/tt&gt; , 解析出错溢出, 被解析成一个超大的数, 也会一直等.&lt;/li&gt;
&lt;li&gt;由于网络问题造成hang住(比如FIN包丢失)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然, 要绕过这个问题最简单的办法是:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;请求加读写超时&lt;/li&gt;
&lt;li&gt;给每个线程加个超时重启机制 (php就可以这么干).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鉴于其它client很少发现类似问题(不过其它client通常都是连接超时, hhvm没有设置), 而且hhvm redis库代码质量较低(之前已经发现了bug), 首先怀疑是client解析出错.&lt;/p&gt;
&lt;p&gt;这篇分析做下面几个事情:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;尝试复现hang住的问题&lt;/li&gt;
&lt;li&gt;通过一个fake-redis稳定复现解析错误.&lt;/li&gt;
&lt;li&gt;检查hhvm Redis/fgets中的bug&lt;/li&gt;
&lt;li&gt;构造hang住的case.&lt;/li&gt;
&lt;li&gt;如何fix.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试问题复现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;由于之前发现 hgetall比较容易hang住, 写了这样一个php来测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;?php
set_time_limit(0);

$r = new Redis();
$r-&amp;gt;setOption('OPT_READ_TIMEOUT', 0.0);
$conn = $r-&amp;gt;connect('10.81.19.14', 4000, 0.1 );

$key = 'kkkkkkkkk';
for ($i=0; $i&amp;lt;3000; $i++) {
    $value = str_pad( $i, $i%100, &amp;quot;\r\n&amp;quot; );

    $r-&amp;gt;hMset($key, array(&amp;quot;field-$i&amp;quot; =&amp;gt; $value));
}

for($i=0; $i&amp;lt;10000000; $i++) {
    $v = $r-&amp;gt;hgetall($key);
    $len = count($v);

    if ($i%100 == 0) {
        echo &amp;quot;$i: $len\n&amp;quot;;
    }
}

hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf a.php
&lt;/pre&gt;
&lt;p&gt;发现不会hang住, 但是经常报错:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[Tue Sep  9 12:58:00 2014] [hphp] [54093:7f598d376340:0:000955] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'o' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processMapResponse()
#2 /home/ning/hhvm/a.php(26): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;这个应该是解析过程中发生的某种错误, 我们先研究这个问题.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fake-redis"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id14"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;fake-redis 复现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;粗略看了hhvm Redis库的代码, 发现读response的地方处理不好, 所以我们构造一个fake-redis用于测试, fake-redis在response的时候, 每次写一个字节, sleep &lt;tt class="docutils literal"&gt;100ms&lt;/tt&gt; .&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/idning/fake-redis/blob/master/fake-redis.py"&gt;https://github.com/idning/fake-redis/blob/master/fake-redis.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(这个测试估计可以让多数网络程序出bug, 包括lighttpd, openssl等)&lt;/p&gt;
&lt;p&gt;应用这个 fake-redis, 做了下面测试&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;测试1&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;c.php:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$r = new Redis();

$conn = $r-&amp;gt;connect('127.1', 9999, 0.1 );

echo &amp;quot;set\n&amp;quot;;
echo $r-&amp;gt;set('k', 'abc');
echo &amp;quot;get\n&amp;quot;;
echo $r-&amp;gt;Get('k');
echo &amp;quot;done\n&amp;quot;;
&lt;/pre&gt;
&lt;p&gt;会出问题:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
get
[Tue Sep  9 22:10:57 2014] [hphp] [54178:7f539ac6f340:0:000001] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'K' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processSerializedResponse()
#2 hhvm/c.php(11): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;加了strace打算看下原因, 发现ok了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
1get
abcdone
&lt;/pre&gt;
&lt;p&gt;后来仔细分析了strace, 发现客户端会经常用100ms 去poll(更详细的分析参考后面):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
recvfrom(7, &amp;quot;O&amp;quot;, 1, MSG_PEEK|MSG_DONTWAIT, NULL, NULL) = 1
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP, revents=POLLIN}], 1, 100) = 1
getsockopt(7, SOL_SOCKET, SO_ERROR, [0], [4]) = 0
recvfrom(7, &amp;quot;O&amp;quot;, 8192, MSG_DONTWAIT, NULL, NULL) = 1
&lt;/pre&gt;
&lt;p&gt;因为server端也是sleep 100ms, 所以用了strace后, cliet慢了一点, server端的response已经来了, 正好就ok了.&lt;/p&gt;
&lt;p&gt;修改 sleep 为150ms, 这时候就能稳定复现, 每次结果都一样:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
NRedis: type=+, resp=
get
[Wed Sep 10 10:43:44 2014] [hphp] [14966:7f42e70f4340:0:000001] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'O' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processSerializedResponse()
#2 /home/ning/hhvm/c.php(56): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;strace如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
recvfrom(7, &amp;quot;O&amp;quot;, 1, MSG_PEEK|MSG_DONTWAIT, NULL, NULL) = 1
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP, revents=POLLIN}], 1, 100) = 1
getsockopt(7, SOL_SOCKET, SO_ERROR, [0], [4]) = 0
recvfrom(7, &amp;quot;O&amp;quot;, 8192, MSG_DONTWAIT, NULL, NULL) = 1
recvfrom(7, 0x7fff6c432e40, 1, 66, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP}], 1, 100) = 0
recvfrom(7, 0x7fa647bf5000, 8192, 64, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id16"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;到了这里, 我们很容易模拟fgets不符合预期的情况了, 通过读代码, 发现主要是fgets的问题.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="redis"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis库的问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="mock"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;我们通过继承Redis，来看看到底发生了什么(这个php被编译在二进制里面了, 每次修改都要重新编译, 不如继承, 方便调试):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class NRedis extends Redis{

  protected function processBooleanResponse() {
    if ($this-&amp;gt;mode === self::ATOMIC) {
      $resp = $this-&amp;gt;sockReadData($type);
      echo &amp;quot;NRedis: type=$type, resp=$resp\r\n&amp;quot;;

      return ($type === self::TYPE_LINE) AND ($resp === 'OK');
    }
    $this-&amp;gt;multiHandler[] = [ 'cb' =&amp;gt; [$this,'processBooleanResponse'] ];
    if (($this-&amp;gt;mode === self::MULTI) &amp;amp;&amp;amp; !$this-&amp;gt;processQueuedResponse()) {
      return false;
    }
    return $this;
  }

  public function hMSet($key, array $pairs) {
    $args = [$this-&amp;gt;prefix($key)];
    foreach ($pairs as $k =&amp;gt; $v) {
      $args[] = $k;
      $args[] = $this-&amp;gt;serialize($v);
    }
    $this-&amp;gt;processArrayCommand('HMSET', $args);
    return $this-&amp;gt;processBooleanResponse();
  }
}


$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
NRedis: type=+, resp=
get
[Wed Sep 10 10:43:44 2014] [hphp] [14966:7f42e70f4340:0:000001] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'O' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processSerializedResponse()
#2 /home/ning/hhvm/c.php(56): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;发现第一个set请求, server 端的返回是 &lt;tt class="docutils literal"&gt;+OK\r\n&lt;/tt&gt;, 但是客户端读到 &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; 就返回了, 此时返回的type是 &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; , resp为空, 所以接下来读get请求的response的时候, 就读到了 'O', 这就是上面这个异常的原因.&lt;/p&gt;
&lt;p&gt;这里 &lt;tt class="docutils literal"&gt;fgets&lt;/tt&gt; 返回了 &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; , 还没遇到 &lt;tt class="docutils literal"&gt;\n&lt;/tt&gt; 就返回, 这是 &lt;tt class="docutils literal"&gt;fgets&lt;/tt&gt; 的问题, 我们后面再分析&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;修复&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;既然fgets有问题, 我们可以换一个比较保守的readLine实现:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class NRedis extends Redis{
  ...
  protected function sockReadLine() {
   if (!$this-&amp;gt;checkConnection()) {
     return false;
   }

   $line = '';
   while(1) {
     $c = fgetc($this-&amp;gt;connection);
     $line .= $c;
     if (substr($line, -2) == &amp;quot;\r\n&amp;quot;) {
       $line = substr($line, 0, -2);
       return $line;
     }
   }

   return false;
  }
}
&lt;/pre&gt;
&lt;p&gt;使用修复版的NRedis, 测试OK:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
NRedis: type=+, resp=OK
1get
abcdone
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="fgets"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id20"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id21"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;利用前面的fake-redis server, 写了这样一个测试代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat d.php
&amp;lt;?php

$conn = fsockopen('127.1', 9999, $errno, $errstr, 0.1);

fwrite($conn, &amp;quot;*3\r\n$3\r\nSET\r\n$1\r\nk\r\n$1\r\nv\r\n&amp;quot;);
$r = fgets($conn);
var_dump($r);

fwrite($conn, &amp;quot;*2\r\n$3\r\nGET\r\n$1\r\nk\r\n&amp;quot;);

$r = fgets($conn);
var_dump($r);

$r = fgets($conn);
var_dump($r);
&lt;/pre&gt;
&lt;div class="section" id="id6"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id22"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;情况1&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;server端不sleep时, 返回一切正常:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf d.php
string(5) &amp;quot;+OK
&amp;quot;
string(4) &amp;quot;$1
&amp;quot;
string(3) &amp;quot;v
&amp;quot;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id23"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;情况2&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;server端每发送1个byte sleep 150ms:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf d.php
string(1) &amp;quot;+&amp;quot;
string(1) &amp;quot;O&amp;quot;
string(1) &amp;quot;K&amp;quot;
&lt;/pre&gt;
&lt;p&gt;每次 &lt;tt class="docutils literal"&gt;fgets&lt;/tt&gt; 只能读到一个字节.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="fgets-bug"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id24"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets bug&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="http://php.net/manual/en/function.fgets.php"&gt;http://php.net/manual/en/function.fgets.php&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;php.net上fgets 的文档:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Reading ends when length - 1 bytes have been read, or a newline (which is included in the return value), or an EOF (whichever comes first). If no length is specified, it will keep reading from the stream until it reaches the end of the line.
&lt;/pre&gt;
&lt;p&gt;有三种情况这个函数返回:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;读到1行&lt;/li&gt;
&lt;li&gt;读到eof&lt;/li&gt;
&lt;li&gt;读到(length-1) 字节&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id8"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id25"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;看实现&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="id9"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id26"&gt;4.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;implement of fgets hphp/runtime/ext/ext_file.cpp&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Variant f_fgets(const Resource&amp;amp; handle, int64_t length /* = 0 */) {
  if (length &amp;lt; 0) {
    throw_invalid_argument(&amp;quot;length (negative): %&amp;quot; PRId64, length);
    return false;
  }
  CHECK_HANDLE(handle, f);
  String line = f-&amp;gt;readLine(length);
  if (!line.isNull()) {
    return line;
  }
  return false;
}
&lt;/pre&gt;
&lt;p&gt;hphp/runtime/base/file.cpp:readLine:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1   String File::readLine(int64_t maxlen /* = 0 */) {
2     size_t current_buf_size = 0;
3     size_t total_copied = 0;
4     char *ret = nullptr;
5     for (;;) {
6       int64_t avail = bufferedLen();
7       if (avail &amp;gt; 0) {
8         int64_t cpysz = 0;
9         bool done = false;
10
11        char *readptr = m_buffer + m_readpos;
12        const char *eol;
13        const char *cr;
14        const char *lf;
15        cr = (const char *)memchr(readptr, '\r', avail);
16        lf = (const char *)memchr(readptr, '\n', avail);
17        if (cr &amp;amp;&amp;amp; lf != cr + 1 &amp;amp;&amp;amp; !(lf &amp;amp;&amp;amp; lf &amp;lt; cr)) {
18          /* mac */
19          eol = cr;
20        } else if ((cr &amp;amp;&amp;amp; lf &amp;amp;&amp;amp; cr == lf - 1) || (lf)) {
21          /* dos or unix endings */
22          eol = lf;
23        } else {
24          eol = cr;
25        }
26
27        if (eol) {
28          cpysz = eol - readptr + 1;
29          done = true;
30        } else {
31          cpysz = avail;
32        }
33        if (maxlen &amp;gt; 0 &amp;amp;&amp;amp; maxlen &amp;lt;= cpysz) {
34          cpysz = maxlen;
35          done = true;
36        }
37
38        current_buf_size += cpysz + 1;
39        if (ret) {
40          ret = (char *)realloc(ret, current_buf_size);
41        } else {
42          ret = (char *)malloc(current_buf_size);
43        }
44        memcpy(ret + total_copied, readptr, cpysz);
45
46        m_position += cpysz;
47        m_readpos += cpysz;
48        maxlen -= cpysz;
49        total_copied += cpysz;
50
51        if (done) {
52          break;                              ////////////////////////// 1: eol 或者读到了maxlen
53        }
54      } else if (eof()) {
55        break;                                /////////////////////////  2: eof
56      } else {
57        if (m_buffer == nullptr) {
58          m_buffer = (char *)malloc(CHUNK_SIZE);
59          m_bufferSize = CHUNK_SIZE;
60        }
61        m_writepos = filteredReadToBuffer();
62        m_readpos = 0;
63        if (bufferedLen() == 0) {
64          break;                              /////////////////////////  3: 一次读返回空.
65        }
66      }
67    }
68
69    if (total_copied == 0) {
70      assert(ret == nullptr);
71      return String();
72    }
73
74    ret[total_copied] = '\0';
75    return String(ret, total_copied, AttachString);
76  }
&lt;/pre&gt;
&lt;p&gt;看这个长函数, 有几个情况会返回, 我在代码中标了1, 2, 3. 根据fgets的定义, 1,2两处返回是合理的, 3不应该返回, 而应该继续读, 这就是 &lt;strong&gt;fgets的bug&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这个函数的另一个问题是, 如果一个socket上发来 &lt;tt class="docutils literal"&gt;abc\r\n&lt;/tt&gt;, 但是一次读只读到 &lt;tt class="docutils literal"&gt;abc\r&lt;/tt&gt; 的时候, 它就会返回以 &lt;tt class="docutils literal"&gt;\r&lt;/tt&gt; 结尾的一行, 这个问题, Redis.php已经针对它做了专门的适配, 这里不讨论:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
protected function sockReadLine() {
  if (!$this-&amp;gt;checkConnection()) {
    return false;
  }
  $line = fgets($this-&amp;gt;connection);
  if (substr($line, -2) == &amp;quot;\r\n&amp;quot;) {
    $line = substr($line, 0, -2);
  } else if (substr($line, -1) == &amp;quot;\r&amp;quot;) {             //就是这里.
    $line = substr($line, 0, -1);
    $lf = fgetc($this-&amp;gt;connection);
    if ($lf === false) {
      // A response must terminate with both CR and LF. Refuse to guess.
      return false;
    } else if ($lf !== &amp;quot;\n&amp;quot;) {
      throw new RedisException(&amp;quot;Protocol error: CR not followed by LF&amp;quot;);
    }
  }

  return $line;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="readimpl"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id27"&gt;4.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;readImpl&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;上面的readLine会调用filteredReadToBuffer 来read more bytes, 实际上就是调用readImpl(), 下面我们分析readImpl可能返回空的情况:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int64_t File::filteredReadToBuffer() {
  int64_t bytes_read = readImpl(m_buffer, CHUNK_SIZE);
  if (LIKELY(m_readFilters.empty())) {
    return bytes_read;
  }
&lt;/pre&gt;
&lt;p&gt;readImpl for Socket: hphp/runtime/base/socket.cpp::readImpl:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1   int64_t Socket::readImpl(char *buffer, int64_t length) {
2     assert(m_fd);
3     assert(length &amp;gt; 0);
4
5     IOStatusHelper io(&amp;quot;socket::recv&amp;quot;, m_address.c_str(), m_port);
6
7     int recvFlags = 0;
8     if (m_timeout &amp;gt; 0) {
9       int flags = fcntl(m_fd, F_GETFL, 0);  // ning: we will get into this.
10      if ((flags &amp;amp; O_NONBLOCK) == 0) {
11        if (!waitForData()) {
12          m_eof = true;
13          return 0;
14        }
15        recvFlags = MSG_DONTWAIT; // polled, so no need to wait any more
16      }
17    }
18
19    int64_t ret = recv(m_fd, buffer, length, recvFlags);
20    if (ret == 0 || (ret == -1 &amp;amp;&amp;amp; errno != EWOULDBLOCK)) {
21      m_eof = true;
22    }
23    return (ret &amp;lt; 0) ? 0 : ret;
24  }
25
26  bool Socket::waitForData() {
27    m_timedOut = false;
28    while (true) {
29      struct pollfd fds[1];
30      fds[0].fd = m_fd;
31      fds[0].events = POLLIN|POLLERR|POLLHUP;
32      if (poll(fds, 1, m_timeout / 1000)) {
33        socklen_t lon = sizeof(int);
34        int valopt;
35        getsockopt(m_fd, SOL_SOCKET, SO_ERROR, (void*)(&amp;amp;valopt), &amp;amp;lon);
36        if (valopt == EINTR) continue;
37        return valopt == 0;
38      } else {
39        m_timedOut = true;
40        return true;
41      }
42    }
43    return false;
44  }
&lt;/pre&gt;
&lt;p&gt;Socket::readImpl 会进入11行的waitForData函数(从strace结果看, 这里m_timeout是设为100*1000的):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
recvfrom(7, 0x7fff5be32f00, 1, 66, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP, revents=POLLIN}], 1, 100) = 1
&lt;/pre&gt;
&lt;p&gt;我们可以先不管m_timeout怎么设置的, 这个值设为多大, 或者设为0, 都不影响分析, 看waitForData函数, 如果poll超时后没有收到事件, 就会设置m_timedOut=true, 并且return true.&lt;/p&gt;
&lt;p&gt;所以此时 readImpl 进入 19行recv, 明显是返回 EAGAIN 的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP}], 1, 100) = 0
recvfrom(7, 0x7f3a3d9e2000, 8192, 64, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
&lt;/pre&gt;
&lt;p&gt;EAGAIN就是EWOULDBLOCK, 所以这里没有进入21行, 而是进入23行, 返回 &lt;tt class="docutils literal"&gt;ret = 0&lt;/tt&gt; .&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id28"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;所以, 这应该认为是 &lt;a class="reference external" href="File::readLine"&gt;File::readLine&lt;/a&gt; 的一个bug, 建议的修改是这样:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git diff
diff --git a/hphp/runtime/base/file.cpp b/hphp/runtime/base/file.cpp
index b180301..3d216bd 100644
--- a/hphp/runtime/base/file.cpp
+++ b/hphp/runtime/base/file.cpp
&amp;#64;&amp;#64; -611,9 +611,9 &amp;#64;&amp;#64; String File::readLine(int64_t maxlen /* = 0 */) {
       }
       m_writepos = filteredReadToBuffer();
       m_readpos = 0;
-      if (bufferedLen() == 0) {
-        break;
-      }
+      //if (bufferedLen() == 0) {
+        //break;
+      //}
     }
   }
&lt;/pre&gt;
&lt;p&gt;这需要重新编译hhvm, 所以我没有测试.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="hang"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id29"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;模拟hang住的情况&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最后, 知道bug的原因, 怎么模拟hang住呢, 我们需要构造合法的返回, 被这个bug的解析代码解析认为符合协议, 同时又解析出错。&lt;/p&gt;
&lt;p&gt;因为fgets在server端sleep 200ms 的时候就会返回当前已经读到的 部分, 构造如下response:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$10\r\n$123456789\r\n
  ^
  |
  返回 '$1' 后sleep, 此时client读到 '$1' 认为是读到了一行, 并且认为这个response的阵阵大小是1, 接下来读到 '0\r\n', 所以client 会认为服务器返回了 '0' 这个长度为1的字符串.
  接下来, 下一个get请求来的时候, 会读到 ``$123456789\r\n`` 这一行, 它会认为这个response有123456789这么多字节, 就会一致尝试去读, 当然就一直hang住了.
&lt;/pre&gt;
&lt;p&gt;模拟这个响应的代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def handle_get(self, argv):
    key = argv[1]
    if key == 'special-key-for-hhvm':

        # $10\r\n$123456789\r\n
        self.request.sendall('$1')
        time.sleep(.15)
        self.request.sendall('0\r\n$123456789\r\n')

    elif key in store:
        self.reply_bulk(store[key])
    else:
        self.reply_bulk(None)
&lt;/pre&gt;
&lt;p&gt;这是一个完全合法的get请求的response, 表达的值为 '$123456789', 客户端测试代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$r = new Redis();

$conn = $r-&amp;gt;connect('127.1', 9999, 0.1 );

$t = $r-&amp;gt;get('special-key-for-hhvm');
var_dump($t);
$t = $r-&amp;gt;get('special-key-for-hhvm');
var_dump($t);

$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
string(1) &amp;quot;0&amp;quot;
--- 这里hang住
[Wed Sep 10 11:37:39 2014] [hphp] [52895:7ffc15e5c340:0:000001] []
Fatal error: Maximum execution time of 30 seconds exceeded
&lt;/pre&gt;
&lt;p&gt;使用修改了 &lt;tt class="docutils literal"&gt;sockReadLine&lt;/tt&gt; 后的NRedis代码, 就ok:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
string(10) &amp;quot;$123456789&amp;quot;
string(10) &amp;quot;$123456789&amp;quot;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id30"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;fgets有bug, 修复方法参考正文&lt;/li&gt;
&lt;li&gt;Redis类最好不要用有bug的fgets代码, 自己实现一个sockReadLine即可.&lt;/li&gt;
&lt;li&gt;不排除server端(redis/twemproxy) 也有类似bug的可能性.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id31"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;更新&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;fgets其实没有bug, hhvm在这里的行为和php是一致的, 就是:&lt;/p&gt;
&lt;p&gt;超时后返回已读到的部分, 实际上, 这时候应该通过stream_get_meta_data() 获取是否超时信息:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$conn = fsockopen('127.1', 9999, $errno, $errstr, 0.1);
//$conn = fsockopen('127.1', 9999);

fwrite($conn, &amp;quot;*3\r\n$3\r\nSET\r\n$1\r\nk\r\n$1\r\nv\r\n&amp;quot;);
$r = fgets($conn);
var_dump($r);

fwrite($conn, &amp;quot;*2\r\n$3\r\nGET\r\n$1\r\nk\r\n&amp;quot;);

$r = fgets($conn);
var_dump($r);
$info = stream_get_meta_data($conn);
var_dump($info);


$r = fgets($conn);
var_dump($r);
$info = stream_get_meta_data($conn);
var_dump($info);
&lt;/pre&gt;
&lt;p&gt;输出如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
string(1) &amp;quot;+&amp;quot;
string(1) &amp;quot;O&amp;quot;
array(10) {
  ...
  [&amp;quot;timed_out&amp;quot;]=&amp;gt;
  bool(true)
  [&amp;quot;eof&amp;quot;]=&amp;gt;
  bool(false)
  [&amp;quot;wrapper_data&amp;quot;]=&amp;gt;
  NULL
}
string(1) &amp;quot;K&amp;quot;
array(10) {
  [&amp;quot;timed_out&amp;quot;]=&amp;gt;
  bool(true)
  [&amp;quot;blocked&amp;quot;]=&amp;gt;
  bool(false)
  [&amp;quot;eof&amp;quot;]=&amp;gt;
  bool(false)
  [&amp;quot;wrapper_data&amp;quot;]=&amp;gt;
  NULL
}
&lt;/pre&gt;
&lt;p&gt;接口会输出timeout.&lt;/p&gt;
&lt;p&gt;所以fgets应该认为没bug, 修改Redis库即可.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>ssdb-benchmark</title><link href="/ssdb-benchmark.html" rel="alternate"></link><updated>2014-08-13T14:48:03+08:00</updated><author><name>ning</name></author><id>tag:,2014-08-13:ssdb-benchmark.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hdd" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;hdd 测试结果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ssd" id="id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 测试结果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#leveldb" id="id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB的问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;关于读性能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id8"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;改进&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id9"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;注意&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;因为小规模benchmark时文件都被cache, IO访问其实只有内存操作而已, 所以测试数据只能说明系统在基本无IO操作时的处理能力.&lt;/p&gt;
&lt;p&gt;为了避免文件被cache, 可以减少机器空闲内存, 或者使操作的数据集远大于内存, 我们的测试机内存64G, 所以测试时, 我们使用大约100G的数据集来进行测试.&lt;/p&gt;
&lt;p&gt;benchmark场景:&lt;/p&gt;
&lt;p&gt;先写, 后读, 采集的数据包括:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;qps随时间的变化&lt;/li&gt;
&lt;li&gt;进程内存, cpu占用,&lt;/li&gt;
&lt;li&gt;磁盘读写带宽, r/s, w/s, await, %util,&lt;/li&gt;
&lt;li&gt;磁盘占用量.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为此, 写了这样一个程序用于benchmark和记录结果:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
...
class LoadThread(threading.Thread):
    def run(self):
        global g_qps
        num = 1000000000
        #num = 100000
        cmd = 'redis-benchmark  -p 8888 -t set -n %s -r 100000000000 -d 100' % num
        p = Popen(cmd, shell=True, stdout=PIPE, bufsize=1024)

        for line in iter(lambda: p.stdout.readline(), ''):
            line = str(line).strip()
            #print(&amp;quot;&amp;gt;&amp;gt;&amp;gt; &amp;quot; + line)
            if line.startswith('SET'):
                g_qps = line.split()[1]

        cmd = 'redis-benchmark  -p 8888 -t get -n %s -r 100000000000 -d 100' % num
        p = Popen(cmd, shell=True, stdout=PIPE, bufsize=1024)
        for line in iter(lambda: p.stdout.readline(), ''):
            line = str(line).strip()
            #print(&amp;quot;&amp;gt;&amp;gt;&amp;gt; &amp;quot; + line)
            if line.startswith('GET'):
                g_qps = line.split()[1]
...
&lt;/pre&gt;
&lt;p&gt;代码在此: &lt;a class="reference external" href="https://github.com/idning/iostat-py/blob/master/ssdb-bench/ssdb-bench.py"&gt;https://github.com/idning/iostat-py/blob/master/ssdb-bench/ssdb-bench.py&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="hdd"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;hdd 测试结果&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这个测试是手工完成和记录的, 没有图.&lt;/p&gt;
&lt;p&gt;写:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark  -p 8888 -t set -n 1000000000 -r 100000000000 -d 100
38000
&lt;/pre&gt;
&lt;p&gt;持续写1000000000条, (93G)&lt;/p&gt;
&lt;p&gt;磁盘写带宽持续70M/s左右, 内存使用会上升到10G左右, 低峰会回落, 12核cpu上, cpu占用约30%(4个核占满)&lt;/p&gt;
&lt;p&gt;qps稳定在3.8w/s, 不会随着写数据增多而变差.&lt;/p&gt;
&lt;p&gt;写完之后, 读:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark  -p 8888 -t get -n 1000000000 -r 100000000000 -d 100
60~400
&lt;/pre&gt;
&lt;p&gt;如果能命中热点:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark  -p 8888 -t get -n 1000000000 -r 100000 -d 100
23803.46
&lt;/pre&gt;
&lt;p&gt;初始qps只能达到60/s, 逐渐上升到400/s趋于稳定.&lt;/p&gt;
&lt;p&gt;此时磁盘每秒读请求达到150-300r/s (达到磁盘IOPS极限):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
sda               0.00     0.00  137.00    0.00 12940.00     0.00   188.91     1.08    7.86   6.86  94.00
&lt;/pre&gt;
&lt;p&gt;小结:&lt;/p&gt;
&lt;p&gt;ssdb在hdd上的表现:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;写性能稳定在40000/s左右. 不随着数据集的增大而变差.&lt;/li&gt;
&lt;li&gt;读性能在不能命中热点的情况下, 受限于磁盘的IOPS (400/s)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;hdd上, ssdb适合写多读少的场景.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ssd"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 测试结果&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/dev/sdb1 on /ssd type ext4 (rw,noatime)
mem: 48G
cpu: 12
ssd: Intel SSD 530 480GB, 2.5in SATA  参数: http://ark.intel.com/products/75336/Intel-SSD-530-Series-480GB-2_5in-SATA-6Gbs-20nm-MLC
&lt;/pre&gt;
&lt;p&gt;这块SSD 的性能参数:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Random Read : 48000 IOPS&lt;/li&gt;
&lt;li&gt;Random Write : 80000 IOPS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们实际上是3块ssd做RAID0, fio测试结果:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ sudo fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=1k -size=200G -numjobs=30 -runtime=1000 -group_repor
5.7w/s

$rw=randread
7.3w/s
&lt;/pre&gt;
&lt;p&gt;ssdb测试结果:&lt;/p&gt;
&lt;img alt="" src="/imgs/stat.log.ssdb.0.png" style="width: 800px;" /&gt;
&lt;p&gt;小结&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ssd上写性能稳定在3.8wqps, 不会随着写数据增多而变差, 和hdd差不多,&lt;/li&gt;
&lt;li&gt;读性能稳定在5000qps, 明显好与hdd.&lt;/li&gt;
&lt;li&gt;读性能不够, 只能到5000qps, 而此时ssd上的iops大约 5000-7000/s, 此时util%只能到50%, cpu利用率也上不去, 这里可以优化.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="leveldb"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB的问题&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;LevelDB只有block级别的cache, 所有Key集合是记录在磁盘上, 内存中并没有一个记录key是否存在的hash表或树结构, 所以每次查询, 不管key是否存在, LevelDB都需要到磁盘上去找, 如果block不在缓存中, 就要一层层去找, 是非常耗时的,&lt;/p&gt;
&lt;p&gt;为此, LevelDB增加了bloomfilter支持, 可以过滤掉一些key不存在的情况, 减少对磁盘的访问:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssdb-&amp;gt;options.filter_policy = leveldb::NewBloomFilterPolicy(10);
ssdb-&amp;gt;options.block_cache = leveldb::NewLRUCache(cache_size * 1048576);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;关于读性能&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;benchmark显示 &lt;strong&gt;100G数据&lt;/strong&gt; 时, 读性能稳定在大约5000 qps&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;自己实现了一个单线程的服务ndb对比, 发现读qps存在和SSDB一样的低效问题, 而且更低(2000), 如下图:&lt;/li&gt;
&lt;/ul&gt;
&lt;img alt="" src="/imgs/stat.log.ndbv0.0.png" style="width: 800px;" /&gt;
&lt;p&gt;原因:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;ssdb读的时候并未判断expire, 一个读操作只需要一次LevelDB查询, 所以性能较ndb高.&lt;/li&gt;
&lt;li&gt;ssdb是使用单线程去读(并且没有加锁), IO队列上一次只有一个IO请求, 此时avgqu-sz是0.5,
这样想当于把IO操作串行化了, 根据ssd的基本数据, 平均读延迟是90us左右, 也就是说串行使用最多之能支持 1w/s的读操作, 这和我们测的数据比较接近了.
多线程的读操作应该有利于更好的利用io调度器(几个io请求可以排队, 一起发给磁盘控制器)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;改进&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;修改:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static Command commands[] = {
-       PROC(get, &amp;quot;r&amp;quot;),
+       PROC(get, &amp;quot;rt&amp;quot;),
&lt;/pre&gt;
&lt;p&gt;把读放到多线程里面去做, &lt;strong&gt;性能从5000提到15000&lt;/strong&gt; , 磁盘r/s 达到23000左右, 日志级别改为error后可以达到16000/s&lt;/p&gt;
&lt;p&gt;读没有用Transaction加锁, 所以这时候已经能同时向IO系统发多个IO请求了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int SSDB::get(const Bytes &amp;amp;key, std::string *val) const{
    std::string buf = encode_kv_key(key);
    leveldb::Status s = db-&amp;gt;Get(leveldb::ReadOptions(), buf, val);
    ...
    return 1;
}
&lt;/pre&gt;
&lt;p&gt;调整 &lt;tt class="docutils literal"&gt;READER_THREADS = 10&lt;/tt&gt; 为5, 20, 50, 发现在我的机器上10貌似是个最佳值,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;注意&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;coding for ssd 系列 关于多线程read的观点:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;concurrent read threads can impair the readahead (prefetching buffer) capabilities of SSDs&lt;/li&gt;
&lt;li&gt;A single large read is better than many small concurrent reads
Concurrent random reads cannot fully make use of the readahead mechanism. In addition, multiple Logical Block Addresses may end up on the same chip, not taking advantage or of the internal parallelism.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a class="reference external" href="http://codecapsule.com/2014/02/12/coding-for-ssds-part-5-access-patterns-and-system-optimizations/"&gt;http://codecapsule.com/2014/02/12/coding-for-ssds-part-5-access-patterns-and-system-optimizations/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>reading: coding-for-ssd &amp; implement a kv</title><link href="/coding-for-ssd.html" rel="alternate"></link><updated>2014-07-30T16:58:07+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-30:coding-for-ssd.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#coding-for-ssds" id="id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Coding for SSDs&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-1-introduction-and-table-of-contents" id="id8"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 1: Introduction and Table of Contents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-2-architecture-of-an-ssd-and-benchmarking" id="id9"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 2: Architecture of an SSD and Benchmarking&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ssd" id="id10"&gt;1.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#benchmark" id="id11"&gt;1.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何做benchmark:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-3-pages-blocks-and-the-flash-translation-layer" id="id12"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 3: Pages, Blocks, and the Flash Translation Layer&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id13"&gt;1.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基本操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id14"&gt;1.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;写放大&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#wear-leveling" id="id15"&gt;1.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;wear leveling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#flash-translation-layer-ftl" id="id16"&gt;1.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Flash Translation Layer (FTL)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-4-advanced-functionalities-and-internal-parallelism" id="id17"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 4: Advanced Functionalities and Internal Parallelism&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#trim" id="id18"&gt;1.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;TRIM 命令&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#over-provisioning" id="id19"&gt;1.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;over-provisioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#secure-erase" id="id20"&gt;1.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Secure Erase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#internal-parallelism-in-ssds" id="id21"&gt;1.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Internal Parallelism in SSDs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-5-access-patterns-and-system-optimizations" id="id22"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 5: Access Patterns and System Optimizations&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id23"&gt;1.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;访问模式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-6-a-summary-what-every-programmer-should-know-about-solid-state-drives" id="id24"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 6: A Summary – What every programmer should know about solid-state drives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id25"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#implementing-a-key-value-store-felixdb" id="id26"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;Implementing a Key-Value Store(FelixDB)&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#what-are-key-value-stores-and-why-implement-one" id="id27"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1 What are key-value stores, and why implement one?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#using-existing-key-value-stores-as-models" id="id28"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2 Using existing key-value stores as models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#comparative-analysis-of-the-architectures-of-kyoto-cabinet-and-leveldb" id="id29"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3 Comparative Analysis of the Architectures of Kyoto Cabinet and LevelDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#api-design" id="id30"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4 API Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hash-table-implementations" id="id31"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5 Hash table implementations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#implementing-a-memory-efficient-hash-table-stored-on-the-file-system" id="id32"&gt;2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;-6 Implementing a memory-efficient hash table stored on the file system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#memory-management" id="id33"&gt;2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;7 Memory Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#networking" id="id34"&gt;2.8&amp;nbsp;&amp;nbsp;&amp;nbsp;8 Networking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#interfaces-rest-memcached-etc" id="id35"&gt;2.9&amp;nbsp;&amp;nbsp;&amp;nbsp;9 Interfaces: REST, memcached, etc.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#going-further" id="id36"&gt;2.10&amp;nbsp;&amp;nbsp;&amp;nbsp;10 Going further&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id37"&gt;2.11&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id38"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="coding-for-ssds"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Coding for SSDs&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://codecapsule.com/2014/02/12/coding-for-ssds-part-1-introduction-and-table-of-contents/"&gt;http://codecapsule.com/2014/02/12/coding-for-ssds-part-1-introduction-and-table-of-contents/&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="part-1-introduction-and-table-of-contents"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 1: Introduction and Table of Contents&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="part-2-architecture-of-an-ssd-and-benchmarking"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 2: Architecture of an SSD and Benchmarking&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;两种flash:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;NOR flash&lt;/li&gt;
&lt;li&gt;NAND flash (主流)&lt;/li&gt;
&lt;li&gt;寿命有限, Each cell has a maximum number of P/E cycles (Program/Erase)&lt;/li&gt;
&lt;li&gt;高温会导致数据清除.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;存储单元类型:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 bit per cell (single level cell, &lt;strong&gt;SLC&lt;/strong&gt; ),   &lt;tt class="docutils literal"&gt;寿命相对较长&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;2 bits per cell (multiple level cell, &lt;strong&gt;MLC&lt;/strong&gt; ),  &lt;tt class="docutils literal"&gt;成本低&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;3 bits per cell (triple-level cell, &lt;strong&gt;TLC&lt;/strong&gt; ).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MLC/TLC成本较低  目前多数是MLC或TLC, 如果update很多的话, 还是SLC好.&lt;/p&gt;
&lt;div class="section" id="ssd"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id10"&gt;1.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 架构&lt;/a&gt;&lt;/h4&gt;
&lt;img alt="" src="/imgs/ssd_architecture.jpg" style="width: 360px; height: 207px;" /&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;接口主要是  Serial ATA (SATA), PCI Express (PCIe), 现在还有新的SAS.&lt;/li&gt;
&lt;li&gt;通常都有RAM存储(256M+), 用作buffer/cache/map关系等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;厂商给的数字通常是在某种条件下测得的, 不见得能表示真实性能:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
In his articles about common flaws in SSD benchmarking [66], Marc Bevand mentioned that for instance it is common for the IOPS of random write workloads to be reported without any mention of the span of the LBA, and that many IOPS are also reported for queue depth of 1 instead of the maximum value for the drive being tested. There are also many cases of bugs and misuses of the benchmarking tools.

Correctly assessing the performance of SSDs is not an easy task.
&lt;/pre&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;span&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;queue-depth很重要.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;测试时间, 和SSD的size有很大关系:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
the performance of SSDs only drops under a sustained workload of random writes, which depending on the total size of the SSD can take just 30 minutes or up to three hours
&lt;/pre&gt;
&lt;p&gt;如下图, 30min后性能有明显下降:&lt;/p&gt;
&lt;img alt="" src="/imgs/writes_preconditioning.jpg" style="width: 360px; height: 414px;" /&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;原因:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;garbage collection must erase blocks as write commands arrive, therefore competing with the foreground operations from the host,&lt;/li&gt;
&lt;li&gt;GC影响正常流量.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里: &lt;a class="reference external" href="http://www.storagereview.com/samsung_ssd_840_pro_review"&gt;http://www.storagereview.com/samsung_ssd_840_pro_review&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="benchmark"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id11"&gt;1.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何做benchmark:&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The parameters used are generally the following:
- The type of workload: can be a specific benchmark based on data collected from users, or just only sequential or random accesses of the same type (ex: only random writes)
- The percentages of reads and writes performed concurrently (ex: 30% reads and 70% writes)
- The queue length: this is the number of concurrent execution threads running commands on a drive
- The size of the data chunks being accessed (4 KB, 8 KB, etc.)&lt;/p&gt;
&lt;p&gt;结果:
- Throughput (对顺序读写)
- ipos (对随机读写)
- Latancy&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-3-pages-blocks-and-the-flash-translation-layer"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id12"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 3: Pages, Blocks, and the Flash Translation Layer&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;不少概念:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;how writes are handled at the page and block level,&lt;/li&gt;
&lt;li&gt;write amplification&lt;/li&gt;
&lt;li&gt;wear leveling&lt;/li&gt;
&lt;li&gt;Flash Translation Layer (FTL),&lt;/li&gt;
&lt;li&gt;logical block mapping&lt;/li&gt;
&lt;li&gt;garbage collection&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id1"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id13"&gt;1.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基本操作&lt;/a&gt;&lt;/h4&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Reads are aligned on page size (It is not possible to read less than one page at once.)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;和hdd其实一样.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Writes are aligned on page size&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;每次读一个page比较好理解, 每次怎么写一个page??&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;write amplification(写放大)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;写操作不是直接覆盖原来的page, 而是 拷贝这个page到ssd的RAM中, 在RAM中修改, 最后写到一个新的page里面去.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;When data is changed, the content of the page is copied into an internal register, the data is updated, and the new version is stored in a “free” page,  an operation called “read-modify-write”. The data is not updated in-place, as the “free” page is a different page than the page that originally contained the data. Once the data is persisted to the drive, the original page is marked as being “stale”, and will remain as such until it is erased.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Erases are aligned on block size&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;对于write造成的 &lt;tt class="docutils literal"&gt;stale&lt;/tt&gt; 状态的page, 需要一个erase操作, 变成 &lt;tt class="docutils literal"&gt;free&lt;/tt&gt; 状态.&lt;/li&gt;
&lt;li&gt;但是, 又不能Erase单独的一个Page, 只能Erase整个block.&lt;/li&gt;
&lt;li&gt;这些都是由ssd控制器的garbage collection process来处理的, 所以这里有很多各种算法(因为寿命有限, 所以寿命管理也需要复杂算法)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="" src="/imgs/ssd_writing_data.jpg" style="width: 360px; height: 380px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id14"&gt;1.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;写放大&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;写一个字节也会导致整个page的read-modify-write&lt;/p&gt;
&lt;p&gt;应该尽量避免 small write.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="wear-leveling"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id15"&gt;1.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;wear leveling&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;写均衡. 避免总是写同一个page.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="flash-translation-layer-ftl"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id16"&gt;1.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Flash Translation Layer (FTL)&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Flash Translation Layer 是一个地址映射机制, 提供像磁盘一样的逻辑地址.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;logical block mapping&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;一个逻辑地址到page的有映射表.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;This mapping table is stored in the RAM of the SSD for speed of access, and is persisted in flash memory in case of power failure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;When the SSD powers up, the table is read from the persisted version and reconstructed into the RAM of the SSD&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;block-level&lt;/span&gt; mapping&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;page-level&lt;/span&gt; mapping&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;page-level 太费内存. Let’s assume that an SSD drive has 256 pages per block. This means that block-level mapping requires 256 times less memory than page-level mapping&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;block-level 让写放大更加明显&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;which uses an approach similar to log-structured file systems. Incoming write operations are written sequentially to log blocks. When a log block is full, it is merged with the data block associated to the same logical block number (LBN) into a free block&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; 应该是现在ssd写能达到和读一样性能的关键点.&lt;/li&gt;
&lt;li&gt;This allows random writes to be handled like sequential writes.&lt;/li&gt;
&lt;li&gt;但是read requests need to check both the log-block mapping table and the data-block mapping table, 性能损耗应该很小.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;garbage collection.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;做ssd控制器的厂商比较少:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
seven companies are providing controllers for 90% of the solid-state drive market(做ssd的厂商很多, 但是做控制芯片/算法的很少)
&lt;/pre&gt;
&lt;p&gt;Erase: 1500-3500 μs
Write: 250-1500 μs&lt;/p&gt;
&lt;p&gt;A less important reason for blocks to be moved is the read disturb. Reading can change the state of nearby cells, thus blocks need to be moved around after a certain number of reads have been reached [14].&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-4-advanced-functionalities-and-internal-parallelism"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 4: Advanced Functionalities and Internal Parallelism&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="trim"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id18"&gt;1.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;TRIM 命令&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;which can be sent by the operating system to notify the SSD controller that pages are no longer in use in the logical space&lt;/p&gt;
&lt;p&gt;帮助控制器更好的GC.&lt;/p&gt;
&lt;p&gt;The TRIM command will only work if the SSD controller, the operating system, and the filesystem are supporting it.&lt;/p&gt;
&lt;p&gt;Under Linux, support for the ATA TRIM was added in version &lt;tt class="docutils literal"&gt;2.6.33&lt;/tt&gt; .
ext2 and ext3 filesystems do not support TRIM,
&lt;tt class="docutils literal"&gt;ext4&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;XFS&lt;/tt&gt; , among others, do support it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="over-provisioning"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id19"&gt;1.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;over-provisioning&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Over-provisioning is simply having more physical blocks than logical blocks, by keeping a ratio of the physical blocks reserved for the controller and not visible to the user. Most manufacturers of professional SSDs already include some over-provisioning, generally in the order of 7 to 25%&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="secure-erase"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id20"&gt;1.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Secure Erase&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Some SSD controllers offer the ATA Secure Erase functionality&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="internal-parallelism-in-ssds"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id21"&gt;1.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Internal Parallelism in SSDs&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Due to physical limitations, an asynchronous NAND-flash I/O bus cannot provide more than 32-40 MB/s of bandwidth [5].&lt;/p&gt;
&lt;p&gt;所以实际上, ssd控制器内部有多个芯片, 类似raid那样.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-5-access-patterns-and-system-optimizations"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 5: Access Patterns and System Optimizations&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id3"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id23"&gt;1.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;访问模式&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;在ssd里面, 因为映射关系是动态的, contiguous addresses in the logical space may refer to addresses that are not contiguous in the physical space.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;避免随机small write.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;amall write 实际上需要写整个block. 所以写一个小数据和一个大数据都需要同样的copy-erase-write操作&lt;/li&gt;
&lt;li&gt;需要大量操作映射关系表.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Reads are faster than writes&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;顺序读比随机读throughput好.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;其它优化&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;对齐读写(有比较小的提升)&lt;/li&gt;
&lt;li&gt;打开 TRIM&lt;/li&gt;
&lt;li&gt;IO scheduler, (默认是CFQ,  NOOP or Deadline 会好一些)&lt;/li&gt;
&lt;li&gt;尽量不要用ssd存临时文件或做swap (写次数有限)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-6-a-summary-what-every-programmer-should-know-about-solid-state-drives"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id24"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 6: A Summary – What every programmer should know about solid-state drives&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id25"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;ssd在大量写压力下, 性能可能恶化到8000iops.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;因为很多update, GC可能跟不上, 如果每次写操作需要做一次erase整个block, 就悲剧了.&lt;/li&gt;
&lt;li&gt;正常情况下, GC利用后台的时间, 可以完成erase工作.&lt;/li&gt;
&lt;li&gt;The TRIM command and over-provisioning are two great ways to reduce this effect, and are covered in more details in Sections 6.1 and 6.2.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;写放大, 写一个字节也会导致整个page的read-modify-write&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;应该尽量避免 small write.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;很多ssd会通过hybrid log-block mapping来做写merge. 从而减轻写放大.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;ssd 适合写少, 读多的情况&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们到底要不要避免用small write 呢?&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;如果没用 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; , 明显是要避免small-write.&lt;/li&gt;
&lt;li&gt;如果有 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; 呢? 小的写操作还是没有大的写操作效率高.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="implementing-a-key-value-store-felixdb"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id26"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;Implementing a Key-Value Store(FelixDB)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://codecapsule.com/2012/11/07/ikvs-implementing-a-key-value-store-table-of-contents/"&gt;http://codecapsule.com/2012/11/07/ikvs-implementing-a-key-value-store-table-of-contents/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;July 8, 2014: I am currently implementing the key-value store and will write a post about it when it’s done&lt;/p&gt;
&lt;p&gt;1-4: 作者选了半天名字, api形式, 命名风格....&lt;/p&gt;
&lt;div class="section" id="what-are-key-value-stores-and-why-implement-one"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id27"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1 What are key-value stores, and why implement one?&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;练习目的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;I am starting this project as a way to refresh my knowledge of some fundamentals of hardcore back-end engineering&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Reading books and Wikipedia articles is boring and exempt of practice&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;练习点&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;The C++ programming language&lt;/li&gt;
&lt;li&gt;Object-oriented design&lt;/li&gt;
&lt;li&gt;Algorithmics and data structures&lt;/li&gt;
&lt;li&gt;Memory management&lt;/li&gt;
&lt;li&gt;Concurrency control with multi-processors or multi-threading&lt;/li&gt;
&lt;li&gt;Networking with a server/client model&lt;/li&gt;
&lt;li&gt;I/O problems with disk access and use of the file system&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;现有的: Redis, MongoDB, memcached, BerkeleyDB, Kyoto Cabinet and LevelDB.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;打算提供的特性:
- Adapt to a specific data representation (ex: graphs, geographic data, etc.)
- Adapt to a specific operation (ex: performing very well for reads only, or writes only, etc.)
- Offer more data access options. For instance in LevelDB, data can be accessed forward or backward, with iterators&lt;/p&gt;
&lt;p&gt;貌似没有什么特点..&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;I will use a hash table for the underlying data Structure, the data will be persistent on disk, and a network interface will also be implemented.&lt;/li&gt;
&lt;li&gt;不求速度 I will not run for absolute speed&lt;/li&gt;
&lt;li&gt;将基于一个现有c/c++项目(见第2节)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="using-existing-key-value-stores-as-models"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id28"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2 Using existing key-value stores as models&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;One of the most memorable projects is DBM, the initial database manager coded by Kenneth Thompson for Unix version 7 and released in 1979&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主要考察:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;DBM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Berkeley DB , 当时作为改进的DBM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Kyoto Cabinet, &lt;strong&gt;主要考察对象&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;(a straightforward implementation of DBM)一般性能7w/s, 在超过某一个buckets值之后有性能问题&lt;/li&gt;
&lt;li&gt;hash 或者B+ tree.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;LevelDB &lt;strong&gt;主要考察对象&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;LSM structures are allegedly optimized for SSD drives [13].&lt;/li&gt;
&lt;li&gt;有测试, 当条目数从1e6 到1e9的时候, 性能有下降: &lt;tt class="docutils literal"&gt;找不到原始文章了&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;作者认为LevelDB 代码很好: it is just pure beauty. Everything is clear, simple, and logical.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Memcached and MemcacheDB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;MongoDB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Redis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;OpenLDAP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;SQLite&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="comparative-analysis-of-the-architectures-of-kyoto-cabinet-and-leveldb"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id29"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3 Comparative Analysis of the Architectures of Kyoto Cabinet and LevelDB&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;分成这些模块:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Interface, Get/Put/Delete&lt;/li&gt;
&lt;li&gt;配置参数&lt;/li&gt;
&lt;li&gt;String库&lt;/li&gt;
&lt;li&gt;Logging&lt;/li&gt;
&lt;li&gt;Compression&lt;/li&gt;
&lt;li&gt;Checksum&lt;/li&gt;
&lt;li&gt;Data Storage&lt;/li&gt;
&lt;li&gt;Data Structure Hash/B+Tree/LSM-Tree&lt;/li&gt;
&lt;li&gt;Memory Management&lt;/li&gt;
&lt;li&gt;Iteration&lt;/li&gt;
&lt;li&gt;Lock 管理&lt;/li&gt;
&lt;li&gt;Error管理&lt;/li&gt;
&lt;li&gt;Transaction&lt;/li&gt;
&lt;li&gt;Comparators&lt;/li&gt;
&lt;li&gt;Snapshot&lt;/li&gt;
&lt;li&gt;Sharding&lt;/li&gt;
&lt;li&gt;Replication&lt;/li&gt;
&lt;li&gt;Testing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;太多了... 后面4个不该考虑.&lt;/p&gt;
&lt;p&gt;作者认为Kyoto Cabinet 代码耦合较重, 比如: such as the definition of the Parametrization module inside the Core.&lt;/p&gt;
&lt;p&gt;String库:
- LevelDB is using a specialized class called “Slice
- Kyoto Cabinet is using std::string&lt;/p&gt;
&lt;p&gt;Memory Management
- Kyoto Cabinet 用mmap()
- LevelDB: 用LSM-tree&lt;/p&gt;
&lt;p&gt;Data Storage&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Kyoto Cabinet, LevelDB, BerkeleyDB, MongoDB and Redis are using the file system to store the data. Memcached, on the contrary, is storing the data in memory (RAM).&lt;/li&gt;
&lt;li&gt;对Redis 说错了.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于代码:&lt;/p&gt;
&lt;p&gt;Kyoto Cabinet 会把实现写在.h里面, Kyoto Cabinet 代码比Tokyo Cabinet好多了(The overall architecture and naming conventions have been greatly improved.) 但是还是很糟糕:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
embcomp, trhard, fmtver(), fpow()
&lt;/pre&gt;
&lt;p&gt;LevelDB 的代码命名就很好.&lt;/p&gt;
&lt;p&gt;Kyoto Cabinet 的代码重复也很严重.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="api-design"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id30"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4 API Design&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Opening and closing a database&lt;/li&gt;
&lt;li&gt;Reading and writing data to a database&lt;/li&gt;
&lt;li&gt;Iterating over the full collection of keys and values in a database&lt;/li&gt;
&lt;li&gt;Offer a way to tune parameters&lt;/li&gt;
&lt;li&gt;Offer a decent error notification interface&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者考虑的: Kyoto, LevelDB, BDB, SQLite, 都是库的形式.&lt;/p&gt;
&lt;p&gt;LevelDB 的api有open(). 但是没有close(), 关闭的时候是通过delete 指针做的 -&amp;gt; 不对称.&lt;/p&gt;
&lt;p&gt;Iteration接口, sqlite 是通过一个回调, 不好:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* SQLite3 */
static int callback(void *NotUsed, int argc, char **argv, char **szColName) {
  for(int i = 0; i &amp;lt; argc; i++) {
    printf(&amp;quot;%s = %s\n&amp;quot;, szColName[i], argv[i] ? argv[i] : &amp;quot;NULL&amp;quot;);
  }
  printf(&amp;quot;\n&amp;quot;);
  return 0;
}

char *query = “SELECT * FROM table”;
sqlite3_exec(db, query, callback, 0, &amp;amp;szErrMsg);
&lt;/pre&gt;
&lt;p&gt;it's always interesting to see how different engineers solved the same problems.&lt;/p&gt;
&lt;p&gt;小结: 作者很喜欢LevelDB的api. 除了没有close.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="hash-table-implementations"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id31"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5 Hash table implementations&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这都研究cache line的优化去了, 每必要把.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;gcc4.8中stl 的 hash&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2. sparsehash库, 提供 sparse_hash_map 和 dense_hash_map两个类.
其中dense_hash_map可以scales up or down&lt;/p&gt;
&lt;ol class="arabic" start="3"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Kyoto Cabinet 中的HashDB&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不会自动扩容.&lt;/li&gt;
&lt;li&gt;一旦冲突后, 性能就很差.&lt;/li&gt;
&lt;li&gt;it is very difficult to allow the bucket array to be resized for an on-disk hash table implementation&lt;/li&gt;
&lt;li&gt;把hash表存在磁盘里面, 导致一旦冲突, 就需要在磁盘中访问链表, 这是严重的随机IO&lt;/li&gt;
&lt;li&gt;所以, 基于ssd的cache应该优化: &lt;strong&gt;读操作最多进行多少次IO&lt;/strong&gt; .&lt;/li&gt;
&lt;li&gt;碎片: 有磁盘整理&lt;/li&gt;
&lt;li&gt;一个基于磁盘的存储引擎确实较复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;也许我们能设计这样一个引擎:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;hash表放在内存, 对hash的所有操作写aof(像redis一样)&lt;/li&gt;
&lt;li&gt;数据操作直接写磁盘.&lt;/li&gt;
&lt;li&gt;如何解决碎片.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://code.google.com/p/sparsehash/"&gt;https://code.google.com/p/sparsehash/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="implementing-a-memory-efficient-hash-table-stored-on-the-file-system"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id32"&gt;2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;-6 Implementing a memory-efficient hash table stored on the file system&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="memory-management"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id33"&gt;2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;7 Memory Management&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="networking"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id34"&gt;2.8&amp;nbsp;&amp;nbsp;&amp;nbsp;8 Networking&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="interfaces-rest-memcached-etc"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id35"&gt;2.9&amp;nbsp;&amp;nbsp;&amp;nbsp;9 Interfaces: REST, memcached, etc.&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="going-further"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id36"&gt;2.10&amp;nbsp;&amp;nbsp;&amp;nbsp;10 Going further&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id37"&gt;2.11&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这里作者考察的一些KV系统, 实际是一些库(KV引擎), 从我的角度看, 有这些引擎:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;BDB&lt;/li&gt;
&lt;li&gt;LevelDB&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id38"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;参考&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这里有很多ssd测试数据: &lt;a class="reference external" href="http://www.storagereview.com/samsung_ssd_840_pro_review"&gt;http://www.storagereview.com/samsung_ssd_840_pro_review&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>cr-ssdb</title><link href="/cr-ssdb.html" rel="alternate"></link><updated>2014-07-24T15:12:18+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-24:cr-ssdb.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id18"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id19"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#util" id="id20"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;util&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id21"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;请求处理模型&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#link" id="id22"&gt;2.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redislink" id="id23"&gt;2.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RedisLink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id24"&gt;2.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;命令表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id25"&gt;2.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;处理模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#serv-proc" id="id26"&gt;2.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;serv.proc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#workerpool" id="id27"&gt;2.2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;WorkerPool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id28"&gt;2.2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id29"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;功能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#kv" id="id30"&gt;2.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;kv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hash" id="id31"&gt;2.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;hash&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hscan-hkeys" id="id32"&gt;2.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;hscan/hkeys的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#queue" id="id33"&gt;2.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;queue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#zset" id="id34"&gt;2.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;zset&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#zrank" id="id35"&gt;2.3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;zrank&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id36"&gt;2.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;名字空间划分&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id37"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从相关&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#binlog" id="id38"&gt;2.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;binlog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#binlogqueue" id="id39"&gt;2.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;BinlogQueue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id40"&gt;2.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Binlog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id41"&gt;2.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从同步&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slave" id="id42"&gt;2.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;slave&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dump" id="id43"&gt;2.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;dump&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id44"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#incr" id="id45"&gt;2.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;incr 如何保证原子性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#expire" id="id46"&gt;2.5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何实现expire&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#benchmark" id="id47"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id48"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id14" id="id49"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;读性能的问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#compact" id="id50"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何compact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#expirekey" id="id51"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;所有expire的key记录在内存&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id15" id="id52"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;兼容问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#del" id="id53"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;del 兼容&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ttlkey" id="id54"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;ttl一个不存在的key&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id55"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;没有expire命令&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#scan" id="id56"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;scan类&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id17" id="id57"&gt;4.4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;scan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-hscan" id="id58"&gt;4.4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;没有redis 的hscan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;style type="text/css"&gt;
      table {
        width: 30%
      }
&lt;/style&gt;&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id18"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;请求处理模型, 每个线程一个req?&lt;/li&gt;
&lt;li&gt;如何在kv上实现hash/zset/queue&lt;/li&gt;
&lt;li&gt;如何处理expire/ttl&lt;/li&gt;
&lt;li&gt;如何支持事务, binlog?&lt;/li&gt;
&lt;li&gt;如何主从同步.&lt;/li&gt;
&lt;li&gt;LevelDB读有没有缓存, 如果没有缓存, 那么读性能 &amp;lt; iops&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id19"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;代码量大约9000行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/test/ssdb/src$ cat *.cpp *.h | wc -l
7223

ning&amp;#64;ning-laptop:~/test/ssdb/src$ cat util/*.cpp util/*.h | wc -l
2404
&lt;/pre&gt;
&lt;p&gt;协议解析:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
link.cpp
link.h
link_redis.cpp
link_redis.h
&lt;/pre&gt;
&lt;p&gt;数据类型:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
t_hash.cpp
t_hash.h
t_kv.cpp
t_kv.h
t_queue.cpp
t_queue.h
t_zset.cpp
t_zset.h
proc_hash.cpp
proc_kv.cpp
proc_queue.cpp
proc_zset.cpp

#ttl 也相当于是一种数据类型.
ttl.cpp
ttl.h
&lt;/pre&gt;
&lt;p&gt;主从同步:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
binlog.cpp
binlog.h
slave.cpp
slave.h
#backend_dump.cpp
#backend_dump.h
backend_sync.cpp
backend_sync.h
&lt;/pre&gt;
&lt;p&gt;服务框架:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
serv.cpp
serv.h
ssdb.cpp
ssdb.h
ssdb-server.cpp
&lt;/pre&gt;
&lt;p&gt;其它:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
include.h
version.h
iterator.cpp
iterator.h
&lt;/pre&gt;
&lt;div class="section" id="util"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id20"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;util&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;和icomet一样:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
config.cpp
config.h
daemon.h
file.h
ip_filter.h
log.cpp
log.h
strings.h
&lt;/pre&gt;
&lt;p&gt;epoll:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fde.cpp
fde_epoll.cpp
fde.h
fde_select.cpp
&lt;/pre&gt;
&lt;p&gt;bytes.cpp bytes.h Bytes, Buffer 用于实现string的一些操作.&lt;/p&gt;
&lt;p&gt;sorted_set.cpp
sorted_set.h&lt;/p&gt;
&lt;p&gt;SelectableQueue: 提供一个基于管道实现的Queue, 从而使得这个Queue 可以做Select.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id21"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;请求处理模型&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="link"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id22"&gt;2.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Link&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
class Link{
    int sock;
    bool noblock_;
    static int min_recv_buf;
    static int min_send_buf;

    std::vector&amp;lt;Bytes&amp;gt; recv_data; //recv_data 是解析后的bulk链表.
    Buffer *input;
    Buffer *output;

    double create_time;
    double active_time;

    int read();                             //从网络读到input
    int write();                            //从output写到网络
    int flush();                            //调用wirte.

    const std::vector&amp;lt;Bytes&amp;gt;* recv();       //从input解析到recv_data

    int send(const Bytes &amp;amp;s1);              //写到output
    int send(const Bytes &amp;amp;s1, const Bytes &amp;amp;s2);
    int send(const Bytes &amp;amp;s1, const Bytes &amp;amp;s2, const Bytes &amp;amp;s3);
    ...

    const std::vector&amp;lt;Bytes&amp;gt;* response();                           //通过read() 和recv() 读取response.

    const std::vector&amp;lt;Bytes&amp;gt;* request(const Bytes &amp;amp;s1);             //铜鼓send() 和flush() 写request.
    const std::vector&amp;lt;Bytes&amp;gt;* request(const Bytes &amp;amp;s1, const Bytes &amp;amp;s2);
    ...
}
&lt;/pre&gt;
&lt;p&gt;这里:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;read/recv 是一样的语义, 很容易混淆, write/send也是类似,
read, write 为内部函数, 如果改为 _read, _write 就好懂些.&lt;/li&gt;
&lt;li&gt;request, response 之类, 使用名词做函数名. 不好.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="redislink"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id23"&gt;2.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RedisLink&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;两个函数, 处理对象是input, output:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
send_resp(Buffer *output, const std::vector&amp;lt;std::string&amp;gt; &amp;amp;resp)  //发送redis格式的响应, resp是一个 string 构成的vector.
parse_req(Buffer *input)                                         //读redis格式的请求
recv_req(Buffer *input)                                          //调用parse_req 之后调用convert 转为内部cmd格式.
&lt;/pre&gt;
&lt;p&gt;parse_req 对input的处理是, 如果一次没有解析到一个完整的命令, 那么input buffer不动, 下次继续.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id24"&gt;2.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;命令表&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;命令表:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#define PROC(c, f) {#c, f, 0, proc_##c, 0, 0, 0}
static Command commands[] = {
    PROC(get, &amp;quot;r&amp;quot;),
    PROC(set, &amp;quot;wt&amp;quot;),        //t表示在线程池里面run
    ...
    PROC(dump, &amp;quot;b&amp;quot;),        //b表示在后台run
}
&lt;/pre&gt;
&lt;p&gt;全局变量:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static proc_map_t proc_map;

//启动时初始化 这个map
for(Command *cmd=commands; cmd-&amp;gt;name; cmd++){
    proc_map[cmd-&amp;gt;name] = cmd;
}
&lt;/pre&gt;
&lt;p&gt;收到请求后, Server::proc函数会在proc_map里面查找&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id25"&gt;2.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;处理模型&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;ssdb-server.cpp&lt;/p&gt;
&lt;p&gt;全局:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Config *conf = NULL;
SSDB *ssdb = NULL;
Link *serv_link = NULL;
IpFilter *ip_filter = NULL;

typedef std::vector&amp;lt;Link *&amp;gt; ready_list_t;
volatile bool quit = false;
volatile uint32_t g_ticks = 0;
&lt;/pre&gt;
&lt;p&gt;main:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
main(){
    init(); //load cfg, daemon, listen, init ipfilter, init SSDB, signal
    run(argc, argv);
}
&lt;/pre&gt;
&lt;p&gt;run():&lt;/p&gt;
&lt;pre class="literal-block"&gt;
run(){
    Fdevents fdes;
    fdes.set(serv_link-&amp;gt;fd(), FDEVENT_IN, 0, serv_link);            //监听socket
    fdes.set(serv.reader-&amp;gt;fd(), FDEVENT_IN, 0, serv.reader);        //reader.SelectableQueue.fd
    fdes.set(serv.writer-&amp;gt;fd(), FDEVENT_IN, 0, serv.writer);

    while(!quit){
        ready_list.clear();
        ready_list_2.clear();

        events = fdes.wait(50);
        for(int i=0; i&amp;lt;(int)events-&amp;gt;size(); i++){
            if(fde-&amp;gt;data.ptr == serv_link){
                //do accept
            }else if(fde-&amp;gt;data.ptr == serv.reader || fde-&amp;gt;data.ptr == serv.writer){
                //从子进程那里收结果, 这里比较复杂
                proc_result(job, fdes, ready_list_2);
            }else{
                if(fde-&amp;gt;events &amp;amp; FDEVENT_IN){
                    int len = link-&amp;gt;read();                 //用read
                    ready_list.push_back(link);                         //放到ready_list
                }else if(fde-&amp;gt;events &amp;amp; FDEVENT_OUT){
                    int len = link-&amp;gt;write();                //用write
                    ready_list.push_back(link);                         //放到ready_list
                }
            }
        }
        for(it = ready_list.begin(); it != ready_list.end(); it ++){
            Link *link = *it;
            const Request *req = link-&amp;gt;recv();

            ProcJob job;
            job.link = link;
            serv.proc(&amp;amp;job);                        //这里面可能把Job发到一个线程去.
            if(job.result == PROC_THREAD){
                fdes.del(link-&amp;gt;fd());
                continue;
            }
            if(job.result == PROC_BACKEND){
                fdes.del(link-&amp;gt;fd());
                link_count --;
                continue;
            }
            //这里是直接处理的情况.
            if(proc_result(job, fdes, ready_list_2) == PROC_ERROR){
                link_count --;
            }
        }
        ready_list.swap(ready_list_2);
    }
}
&lt;/pre&gt;
&lt;p&gt;所以请求可以在主线程里面处理, 也可能在线程池里面处理, 如果在线程里面处理, 就会返回PROC_THREAD或者PROC_BACKEND, 此时fd被摘掉, 等请求处理完, 发送response后, 再把fd加入epoll.&lt;/p&gt;
&lt;p&gt;TODO: 为什么最后把ready_list_2 里面的元素放到ready_list里面去了, 但是到下一个循环一开始就   &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ready_list.clear();&lt;/span&gt;&lt;/tt&gt;, 这个clear() 是不是不应该有?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="serv-proc"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id26"&gt;2.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;serv.proc&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;这个函数会根据command_table里的标记, 决定是在主线程处理, 还是在线程池处理, 或者新开一个线程处理:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void Server::proc(ProcJob *job){
    proc_map_t::iterator it = proc_map.find(req-&amp;gt;at(0));
    if(it == proc_map.end()){
        resp.push_back(&amp;quot;client_error&amp;quot;);
    }else{
        Command *cmd = it-&amp;gt;second;
        job-&amp;gt;cmd = cmd;
        if(cmd-&amp;gt;flags &amp;amp; Command::FLAG_THREAD){              //标记为thread的cmd, 会被分到2个线程池里面去跑
            if(cmd-&amp;gt;flags &amp;amp; Command::FLAG_WRITE){
                job-&amp;gt;result = PROC_THREAD;
                writer-&amp;gt;push(*job);
                return; /////
            }else if(cmd-&amp;gt;flags &amp;amp; Command::FLAG_READ){
                job-&amp;gt;result = PROC_THREAD;
                reader-&amp;gt;push(*job);
                return; /////
            }else{
                log_error(&amp;quot;bad command config: %s&amp;quot;, cmd-&amp;gt;name);
            }
        }

        proc_t p = cmd-&amp;gt;proc;
        job-&amp;gt;time_wait = 1000 *(millitime() - job-&amp;gt;stime);
        job-&amp;gt;result = (*p)(this, job-&amp;gt;link, *req, &amp;amp;resp);   //直接在主线程处理.
        job-&amp;gt;time_proc = 1000 *(millitime() - job-&amp;gt;stime);
    }
}
&lt;/pre&gt;
&lt;p&gt;这里调用cmd-&amp;gt;proc, 就是prox_xxx 函数, 它们都是然后调用 &lt;tt class="docutils literal"&gt;SSDB&lt;/tt&gt; 类的相应函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_hdel(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    int ret = serv-&amp;gt;ssdb-&amp;gt;hdel(req[1], req[2]);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="workerpool"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id27"&gt;2.2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;WorkerPool&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;thread.h 提供线程池(WorkerPool), ssdb里面一个writer 线程池, 一个reader 线程池:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt; *writer;
WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt; *reader;

writer = new WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt;(&amp;quot;writer&amp;quot;);
writer-&amp;gt;start(WRITER_THREADS);                                  //1
reader = new WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt;(&amp;quot;reader&amp;quot;);
reader-&amp;gt;start(READER_THREADS);                                  //10
&lt;/pre&gt;
&lt;p&gt;每个WorkerPool有两个 Queue:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Queue&amp;lt;JOB&amp;gt; jobs;
SelectableQueue&amp;lt;JOB&amp;gt; results;

template&amp;lt;class W, class JOB&amp;gt;
int WorkerPool&amp;lt;W, JOB&amp;gt;::push(JOB job){
    return this-&amp;gt;jobs.push(job);
}

template&amp;lt;class W, class JOB&amp;gt;
int WorkerPool&amp;lt;W, JOB&amp;gt;::pop(JOB *job){
    return this-&amp;gt;results.pop(job);
}

template&amp;lt;class W, class JOB&amp;gt;
void* WorkerPool&amp;lt;W, JOB&amp;gt;::_run_worker(void *arg){
    while(1){
        JOB job;
        tp-&amp;gt;jobs.pop(&amp;amp;job);
        worker-&amp;gt;proc(&amp;amp;job);
        tp-&amp;gt;results.push(job);
    }
}
&lt;/pre&gt;
&lt;p&gt;SelectableQueue的fd, 在前面epoll_初始化的时候, 已经把这个fd加入监听, 每次一个job处理完成, 就会向SelectableQueue的fd上写一个字节, 这样主线程就能知道这个Job处理完了&lt;/p&gt;
&lt;p&gt;worker-&amp;gt;porc(&amp;amp;job) 的逻辑:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int Server::ProcWorker::proc(ProcJob *job){
    const Request *req = job-&amp;gt;link-&amp;gt;last_recv();
    Response resp;

    double stime = millitime();
    proc_t p = job-&amp;gt;cmd-&amp;gt;proc;
    job-&amp;gt;result = (*p)(job-&amp;gt;serv, job-&amp;gt;link, *req, &amp;amp;resp);
    double etime = millitime();
    job-&amp;gt;time_wait = 1000 * (stime - job-&amp;gt;stime);
    job-&amp;gt;time_proc = 1000 *(etime - stime);

    if(job-&amp;gt;link-&amp;gt;send(resp) == -1){
        job-&amp;gt;result = PROC_ERROR;
    }else{
        log_debug(&amp;quot;w:%.3f,p:%.3f, req: %s, resp: %s&amp;quot;,
            job-&amp;gt;time_wait, job-&amp;gt;time_proc,
            serialize_req(*req).c_str(),
            serialize_req(resp).c_str());
    }
    return 0;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id28"&gt;2.2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;这种请求处理模型没见过, 觉得很巧妙.&lt;/p&gt;
&lt;p&gt;HERE&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id29"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;功能&lt;/a&gt;&lt;/h3&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="30%" /&gt;
&lt;col width="70%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;redis&lt;/th&gt;
&lt;th class="head"&gt;ssdb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hash&lt;/td&gt;
&lt;td&gt;hash&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;list&lt;/td&gt;
&lt;td&gt;queue(不等于list)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;set&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zset&lt;/td&gt;
&lt;td&gt;zset&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;hash的hset, hget 可以O(n)实现,  list 的rpush/lpop也可以O(n) 实现, 但是list的 LINSERT, LINDEX是O(n), 所以ssdb没有实现, 只是实现了可以保持O(n)操作的queue&lt;/p&gt;
&lt;p&gt;如何在kv上实现hash/zset/queue&lt;/p&gt;
&lt;p&gt;kv:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(get);
DEF_PROC(set);
&lt;/pre&gt;
&lt;p&gt;hash:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(hget);
DEF_PROC(hset);
&lt;/pre&gt;
&lt;p&gt;zset:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(zrank);
DEF_PROC(zrrank);
DEF_PROC(zrange);
&lt;/pre&gt;
&lt;p&gt;queue:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(qsize);
DEF_PROC(qfront);
DEF_PROC(qback);
DEF_PROC(qpush);
&lt;/pre&gt;
&lt;div class="section" id="kv"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id30"&gt;2.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;kv&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;get:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_get(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    if(req.size() &amp;lt; 2){
        resp-&amp;gt;push_back(&amp;quot;client_error&amp;quot;);
    }else{
        std::string val;
        int ret = serv-&amp;gt;ssdb-&amp;gt;get(req[1], &amp;amp;val);
        if(ret == 1){
            resp-&amp;gt;push_back(&amp;quot;ok&amp;quot;);      //找到  这里是ok这个字符串, 后面会转为redis协议.
            resp-&amp;gt;push_back(val);
        }else if(ret == 0){
            resp-&amp;gt;push_back(&amp;quot;not_found&amp;quot;);
        }else{
            log_error(&amp;quot;fail&amp;quot;);
            resp-&amp;gt;push_back(&amp;quot;fail&amp;quot;);
        }
    }
    return 0;
}

typedef std::vector&amp;lt;std::string&amp;gt; Response;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="hash"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id31"&gt;2.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;hash&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;实现了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(hsize);        // O(1)
DEF_PROC(hget);         // O(1)
DEF_PROC(hset);         // O(1)
DEF_PROC(hdel);         // O(1)
DEF_PROC(hincr);        // O(1)
DEF_PROC(hdecr);        // O(1)
DEF_PROC(hexists);      //O(1)

DEF_PROC(hclear);       // O(n)
DEF_PROC(hscan);        // O(n)
DEF_PROC(hrscan);       // O(n)
DEF_PROC(hkeys);        // O(n)
DEF_PROC(hvals);        // O(n)
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;hkey: {a: b}&lt;/tt&gt; 存储结构:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
_hkey : 1           #size = 1
_hkey_a : b         # hkey.a = b
&lt;/pre&gt;
&lt;p&gt;hset_one时, 组一个新的key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
// returns the number of newly added items
static int hset_one(const SSDB *ssdb, const Bytes &amp;amp;name, const Bytes &amp;amp;key, const Bytes &amp;amp;val, char log_type){
    ...
    int ret = 0;
    std::string dbval;
    if(ssdb-&amp;gt;hget(name, key, &amp;amp;dbval) == 0){ // not found
        std::string hkey = encode_hash_key(name, key); ///////////////////////////////组新key.
        ssdb-&amp;gt;binlogs-&amp;gt;Put(hkey, val.Slice());
        ssdb-&amp;gt;binlogs-&amp;gt;add(log_type, BinlogCommand::HSET, hkey);
        ret = 1;
    }
}

inline static
std::string encode_hash_key(const Bytes &amp;amp;name, const Bytes &amp;amp;key){
    std::string buf;
    buf.append(1, DataType::HASH);
    buf.append(1, (uint8_t)name.size());
    buf.append(name.data(), name.size());
    buf.append(1, '=');
    buf.append(key.data(), key.size());
    return buf;
}
&lt;/pre&gt;
&lt;p&gt;专门存size的key, 参考:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int incr_hsize(SSDB *ssdb, const Bytes &amp;amp;name, int64_t incr){
&lt;/pre&gt;
&lt;div class="section" id="hscan-hkeys"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id32"&gt;2.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;hscan/hkeys的实现&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;需要客户端传来, 从那个key scan到哪个key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_hscan(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    uint64_t limit = req[4].Uint64();
    HIterator *it = serv-&amp;gt;ssdb-&amp;gt;hscan(req[1], req[2], req[3], limit);
    resp-&amp;gt;push_back(&amp;quot;ok&amp;quot;);
    while(it-&amp;gt;next()){
        resp-&amp;gt;push_back(it-&amp;gt;key);
        resp-&amp;gt;push_back(it-&amp;gt;val);
    }
}
&lt;/pre&gt;
&lt;p&gt;用法应该是:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hscan hkey a '' 100
&lt;/pre&gt;
&lt;p&gt;只有ssdb协议支持hscan, 不支持redis的hscan.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="queue"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id33"&gt;2.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;queue&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;实现了这些命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{STRATEGY_AUTO,         &amp;quot;lpush&amp;quot;,                &amp;quot;qpush_front&amp;quot;,          REPLY_STATUS},
{STRATEGY_AUTO,         &amp;quot;rpush&amp;quot;,                &amp;quot;qpush_back&amp;quot;,           REPLY_STATUS},
{STRATEGY_AUTO,         &amp;quot;lpop&amp;quot;,                 &amp;quot;qpop_front&amp;quot;,           REPLY_BULK},
{STRATEGY_AUTO,         &amp;quot;rpop&amp;quot;,                 &amp;quot;qpop_back&amp;quot;,            REPLY_BULK},
{STRATEGY_AUTO,         &amp;quot;llen&amp;quot;,                 &amp;quot;qsize&amp;quot;,                        REPLY_INT},
&lt;/pre&gt;
&lt;p&gt;只能在端上操作, 不能在list中间插入/删除等.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static uint64_t QFRONT_SEQ = 2;
static uint64_t QBACK_SEQ  = 3;
static uint64_t QITEM_MIN_SEQ = 10000;
static uint64_t QITEM_MAX_SEQ = 9223372036854775807ULL;
static uint64_t QITEM_SEQ_INIT = QITEM_MAX_SEQ/2;           //4611686018427387903
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;rpush qkey msg&lt;/tt&gt; 后, 存储结构如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
qkey_2: 4611686018427387903             //front下标
qkey_3:  4611686018427387904            //end下标
qkey_4611686018427387904                //msg
&lt;/pre&gt;
&lt;p&gt;这里 &lt;tt class="docutils literal"&gt;qkey_4611686018427387904&lt;/tt&gt; 后面这个数字在leveldb key里面是直接存binary格式, 8个字节.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="zset"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id34"&gt;2.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;zset&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;每个zset中的元素对应2个key: zset_key, zscore_key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
k2 = encode_zscore_key(name, key, new_score);
k0 = encode_zset_key(name, key);
&lt;/pre&gt;
&lt;p&gt;如下操作:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
127.0.0.1:8888&amp;gt; Zadd zkey 3 a
(integer) 1
127.0.0.1:8888&amp;gt; ZSCORE zkey a
&amp;quot;3&amp;quot;
&lt;/pre&gt;
&lt;p&gt;存储结构:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
zkey: 1                 #size
zkey_a_3: ''            #zscore_key
zkey_a: 3               #zset_key
&lt;/pre&gt;
&lt;p&gt;每次zset, 先用zset_key 取的score, 构造zscore_key, 删除老记录.&lt;/p&gt;
&lt;p&gt;再写新的zset_key和zscore_key.&lt;/p&gt;
&lt;div class="section" id="zrank"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id35"&gt;2.3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;zrank&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;利用zscore_key, 遍历:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int64_t SSDB::zrank(const Bytes &amp;amp;name, const Bytes &amp;amp;key) const{
    ZIterator *it = ziterator(this, name, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, INT_MAX, Iterator::FORWARD);
    uint64_t ret = 0;
    while(true){
        if(it-&amp;gt;next() == false){
            ret = -1;
            break;
        }
        if(key == it-&amp;gt;key){
            break;
        }
        ret ++;
    }
    delete it;
    return ret;
}
&lt;/pre&gt;
&lt;p&gt;zrange类似&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id36"&gt;2.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;名字空间划分&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;LevelDB里面, 每种key都有一个前缀:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class DataType{
public:
    static const char SYNCLOG       = 1;
    static const char KV            = 'k';
    static const char HASH          = 'h'; // hashmap(sorted by key)
    static const char HSIZE         = 'H';
    static const char ZSET          = 's'; // key =&amp;gt; score
    static const char ZSCORE        = 'z'; // key|score =&amp;gt; &amp;quot;&amp;quot;
    static const char ZSIZE         = 'Z';
    static const char QUEUE         = 'q';
    static const char QSIZE         = 'Q';
    static const char MIN_PREFIX = HASH;
    static const char MAX_PREFIX = ZSET;
};
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id37"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从相关&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="binlog"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id38"&gt;2.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;binlog&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;class Binlog
class BinlogQueue
class Transaction&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class Transaction{
private:
    BinlogQueue *logs;
public:
    Transaction(BinlogQueue *logs){
        this-&amp;gt;logs = logs;
        logs-&amp;gt;mutex.lock();
        logs-&amp;gt;begin();
    }

    ~Transaction(){
        // it is safe to call rollback after commit
        logs-&amp;gt;rollback();
        logs-&amp;gt;mutex.unlock();
    }
};
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="binlogqueue"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id39"&gt;2.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;BinlogQueue&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;整个SSDB只有一个BinlogQueue, 而且和数据存放在同一个leveldb里面:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssdb-&amp;gt;binlogs = new BinlogQueue(ssdb-&amp;gt;db);
&lt;/pre&gt;
&lt;p&gt;启动SSDB时, 申请一个BinlogQueue对象, seek 到最后一条binlog, (最后一条是用 encode_seq_key(UINT64_MAX) )
然后启动一个线程, 来删Binlog:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int err = pthread_create(&amp;amp;tid, NULL, &amp;amp;BinlogQueue::log_clean_thread_func, this);
&lt;/pre&gt;
&lt;p&gt;具体写操作的时候:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int SSDB::set(const Bytes &amp;amp;key, const Bytes &amp;amp;val, char log_type){
    Transaction trans(binlogs);                                     //这里开始加锁

    std::string buf = encode_kv_key(key);
    binlogs-&amp;gt;Put(buf, val.Slice());                                 //这里是真正的写操作.
    binlogs-&amp;gt;add(log_type, BinlogCommand::KSET, buf);               //这里是记录一条日志, 说我对这个key, 做了一次set操作 (没记录value, 难道同步的时候再去取value?)
    leveldb::Status s = binlogs-&amp;gt;commit();                          //两个操作一起写
}
&lt;/pre&gt;
&lt;p&gt;其实这里 ssdb-&amp;gt;binlogs 相当于存储层, 所有 set/del leveldb 读写操作都是通过 ssdb-&amp;gt;binlog 进行的, 但是Get操作却不是通过ssdb-&amp;gt;binlog() 操作的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int64_t SSDB::qsize(const Bytes &amp;amp;name){
    std::string key = encode_qsize_key(name);
    std::string val;

    leveldb::Status s;
    s = db-&amp;gt;Get(leveldb::ReadOptions(), key, &amp;amp;val);
}
&lt;/pre&gt;
&lt;p&gt;这就不太统一, 不方便换下面的存储引擎.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id40"&gt;2.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Binlog&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;有多种类型:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class BinlogCommand{
public:
    static const char NONE  = 0;
    static const char KSET  = 1;
    static const char KDEL  = 2;
    static const char HSET  = 3;
    static const char HDEL  = 4;
    static const char ZSET  = 5;
    static const char ZDEL  = 6;

    static const char BEGIN  = 7;
    static const char END    = 8;
};
&lt;/pre&gt;
&lt;p&gt;都是只记录key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssdb-&amp;gt;binlogs-&amp;gt;add(log_type, BinlogCommand::HSET, hkey);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id41"&gt;2.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从同步&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;由Master 主动向从数据, 一个Server 有一个BackendSync实例:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Server::Server(SSDB *ssdb){
    this-&amp;gt;ssdb = ssdb;
    backend_sync = new BackendSync(ssdb);
    ...
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="slave"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id42"&gt;2.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;slave&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
void Slave::start(){
    load_status();
    log_debug(&amp;quot;last_seq: %&amp;quot; PRIu64 &amp;quot;, last_key: %s&amp;quot;,
        last_seq, hexmem(last_key.data(), last_key.size()).c_str());

    thread_quit = false;
    int err = pthread_create(&amp;amp;run_thread_tid, NULL, &amp;amp;Slave::_run_thread, this);
    if(err != 0){
        log_error(&amp;quot;can't create thread: %s&amp;quot;, strerror(err));
    }
}
&lt;/pre&gt;
&lt;p&gt;启动时load last_seq , 然后连上master, 发一个 sync140 告诉服务器从哪里开始发binlog:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sprintf(seq_buf, &amp;quot;%&amp;quot; PRIu64 &amp;quot;&amp;quot;, this-&amp;gt;last_seq);
const char *type = is_mirror? &amp;quot;mirror&amp;quot; : &amp;quot;sync&amp;quot;;
link-&amp;gt;send(&amp;quot;sync140&amp;quot;, seq_buf, this-&amp;gt;last_key, type);
&lt;/pre&gt;
&lt;p&gt;当Slave通过sync命令连上来, Master就会从这个socket把最新的更新发给Slave:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_sync140(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    serv-&amp;gt;backend_sync-&amp;gt;proc(link);
    return PROC_BACKEND;
}

int BackendSync::Client::sync(BinlogQueue *logs){
    Binlog log;
    ret = logs-&amp;gt;find_next(expect_seq, &amp;amp;log);

    switch(log.cmd()){
        case BinlogCommand::KSET:
        case BinlogCommand::HSET:
        case BinlogCommand::ZSET:
            ret = backend-&amp;gt;ssdb-&amp;gt;raw_get(log.key(), &amp;amp;val);
            if(ret == -1){
                log_error(&amp;quot;fd: %d, raw_get error!&amp;quot;, link-&amp;gt;fd());
            }else if(ret == 0){
                //log_debug(&amp;quot;%s&amp;quot;, hexmem(log.key().data(), log.key().size()).c_str());
                log_trace(&amp;quot;fd: %d, skip not found: %s&amp;quot;, link-&amp;gt;fd(), log.dumps().c_str());
            }else{
                log_trace(&amp;quot;fd: %d, %s&amp;quot;, link-&amp;gt;fd(), log.dumps().c_str());
                link-&amp;gt;send(log.repr(), val);
            }
&lt;/pre&gt;
&lt;p&gt;因为binlog只记录了key, 所以这里会再查一次, 把value查出来一起发过去(需要一次读)&lt;/p&gt;
&lt;p&gt;问题: 基准数据怎么过去呢? =&amp;gt; 可以拷贝.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dump"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id43"&gt;2.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;dump&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
backend_dump.cpp
backend_dump.h
&lt;/pre&gt;
&lt;p&gt;有个dump命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PROC(dump, &amp;quot;b&amp;quot;),
&lt;/pre&gt;
&lt;p&gt;相当于redis 的keys,&lt;/p&gt;
&lt;p&gt;收到这个命令, 服务器新开一个线程, 把所有数据通过一个socket发过来, 问题:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;非redis 协议&lt;/li&gt;
&lt;li&gt;容易断&lt;/li&gt;
&lt;li&gt;有scan, 应该就不需要这个了 (不过这个简单, 简单一个命令就可以做backup了)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/ndb$ printf '*1\r\n$4\r\ndump\r\n' | socat - TCP:localhost:8888,shut-close | xxd
0000000: 350a 6265 6769 6e0a 0a33 0a73 6574 0a39  5.begin..3.set.9
0000010: 0a01 0000 0000 001e 953a 0a32 370a 3a95  .........:.27.:.
0000020: 1e00 0000 0000 0101 6b6b 6579 3a30 3030  ........kkey:000
0000030: 3030 3234 3833 3631 320a 0a33 0a73 6574  002483612..3.set
0000040: 0a39 0a01 0000 0000 001e 953b 0a32 370a  .9.........;.27.
0000050: 3b95 1e00 0000 0000 0101 6b6b 6579 3a30  ;.........kkey:0
0000060: 3030 3030 3738 3833 3133 310a 0a33 0a73  00007883131..3.s
0000070: 6574 0a39 0a01 0000 0000 001e 953c 0a32  et.9.........&amp;lt;.2
0000080: 370a 3c95 1e00 0000 0000 0101 6b6b 6579  7.&amp;lt;.........kkey
0000090: 3a30 3030 3030 3236 3435 3335 320a 0a33  :000002645352..3
00000a0: 0a73 6574 0a39 0a01 0000 0000 001e 953d  .set.9.........=
00000b0: 0a32 370a 3d95 1e00 0000 0000 0101 6b6b  .27.=.........kk
00000c0: 6579 3a30 3030 3030 3935 3033 3539 380a  ey:000009503598.
00000d0: 0a33 0a73 6574 0a39 0a01 0000 0000 001e  .3.set.9........
00000e0: 953e 0a32 370a 3e95 1e00 0000 0000 0101  .&amp;gt;.27.&amp;gt;.........
00000f0: 6b6b 6579 3a30 3030 3030 3938 3038 3139  kkey:00000980819
0000100: 360a 0a33 0a73 6574 0a39 0a01 0000 0000  6..3.set.9......
0000110: 001e 953f 0a32 370a 3f95 1e00 0000 0000  ...?.27.?.......
0000120: 0101 6b6b 6579 3a30 3030 3030 3238 3232  ..kkey:000002822
0000130: 3337 360a 0a33 0a73 6574 0a39 0a01 0000  376..3.set.9....
0000140: 0000 001e 9540 0a32 370a 4095 1e00 0000  .....&amp;#64;.27.&amp;#64;.....
0000150: 0000 0101 6b6b 6579 3a30 3030 3030 3134  ....kkey:0000014
0000160: 3936 3935 320a 0a33 0a73 6574 0a39 0a01  96952..3.set.9..
0000170: 0000 0000 001e 9541 0a32 370a 4195 1e00  .......A.27.A...
0000180: 0000 0000 0101 6b6b 6579 3a30 3030 3030  ......kkey:00000
0000190: 3432 3033 3036 370a 0a33 0a73 6574 0a39  4203067..3.set.9
00001a0: 0a01 0000 0000 001e 9542 0a32 370a 4295  .........B.27.B.
00001b0: 1e00 0000 0000 0101 6b6b 6579 3a30 3030  ........kkey:000
00001c0: 3030 3139 3133 3036 320a 0a33 0a73 6574  001913062..3.set
00001d0: 0a39 0a01 0000 0000 001e 9543 0a32 370a  .9.........C.27.
00001e0: 4395 1e00 0000 0000 0101 6b6b 6579 3a30  C.........kkey:0
00001f0: 3030 3030 3637 3432 3136 310a 0a33 0a65  00006742161..3.e
0000200: 6e64 0a32 0a31 300a 0a                   nd.2.10..
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id44"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="incr"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id45"&gt;2.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;incr 如何保证原子性&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;通过Transaction上的锁实现.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="expire"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id46"&gt;2.5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何实现expire&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;ssdb为每个带有过期设置的key, 保存了2个结构:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;内存里面的一个sorted_set (全量)&lt;/li&gt;
&lt;li&gt;leveldb里面以 EXPIRATION_LIST_KEY 开头的一系列key.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ssdb 里面保留这个key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#define EXPIRATION_LIST_KEY &amp;quot;\xff\xff\xff\xff\xff|EXPIRE_LIST|KV&amp;quot;
&lt;/pre&gt;
&lt;p&gt;用这个key作为一个大zset(基于ssdb在leveldb上提供的zset), 当需要设置一个key的ttl时, 就向这个zset里面设置某个key的超时时间:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int ExpirationHandler::set_ttl(const Bytes &amp;amp;key, int ttl){
    int64_t expired = time_ms() + ttl * 1000;
    char data[30];
    int size = snprintf(data, sizeof(data), &amp;quot;%&amp;quot; PRId64, expired);
    if(size &amp;lt;= 0){
        log_error(&amp;quot;snprintf return error!&amp;quot;);
        return -1;
    }

    Locking l(&amp;amp;mutex);
    int ret = ssdb-&amp;gt;zset(this-&amp;gt;list_name, key, Bytes(data, size));

}
&lt;/pre&gt;
&lt;p&gt;同时还会放到一个内存的sorted_set(expiration_keys)里面去:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
expiration_keys.add(key.String(), expired);
&lt;/pre&gt;
&lt;p&gt;ssdb启动后, 会有一个线程把所有 EXPIRATION_LIST_KEY 这个 zset 里面的所有key扫描出来, 放到内存的 expiration_keys 里.&lt;/p&gt;
&lt;p&gt;回收时, 由一个线程从 expiration_keys 里面取出每个key, 把key和它对应的expire记录删掉:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if(handler-&amp;gt;expiration_keys.front(&amp;amp;key, &amp;amp;score)){
    int64_t now = time_ms();
    if(score &amp;lt;= now){
        log_debug(&amp;quot;expired %s&amp;quot;, key-&amp;gt;c_str());
        ssdb-&amp;gt;del(*key);
        ssdb-&amp;gt;zdel(handler-&amp;gt;list_name, *key);
        handler-&amp;gt;expiration_keys.pop_front();
        continue;
    }
}
&lt;/pre&gt;
&lt;p&gt;问题是: 所有的key都要装到内存, 内存会比较大, 而读的时候又没有利用上这个内存.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="benchmark"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id47"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;benchmark&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;请看:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="/ssdb-benchmark.html"&gt;ssdb benchmark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id13"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id48"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id14"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id49"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;读性能的问题&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;benchmark结果: &lt;strong&gt;100G数据&lt;/strong&gt; 时, 读性能稳定在大约5000qps&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="compact"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id50"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何compact&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;貌似是一个命令. 需要人工调用.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="expirekey"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id51"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;所有expire的key记录在内存&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;如果有10亿条, 每条100字节, 就需要100G+内存.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id15"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id52"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;兼容问题&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="del"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id53"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;del 兼容&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;因为leveldb 的接口, 删除实际上是一个写操作(写为空串).
所以删除接口不能返回这个key在是真的删了, 还是本来就不存在.&lt;/p&gt;
&lt;p&gt;所以在删除一个不存在的key时 for redis:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/redis/src$ redis-cli -p 2000 del xxx
(integer) 0
&lt;/pre&gt;
&lt;p&gt;for ssdb:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/redis/src$ redis-cli -p 8888 del xxx
(integer) 1
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="ttlkey"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id54"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;ttl一个不存在的key&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
127.0.0.1:8888&amp;gt; ttl k
(error) ERR
&lt;/pre&gt;
&lt;p&gt;redis:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
127.0.0.1:5527&amp;gt; ttl k
(integer) -2
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id55"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;没有expire命令&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;改为通过ttl命令设置expire.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scan"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id56"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;scan类&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="id17"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id57"&gt;4.4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;scan&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;一次在一个连接上吐回所有key, 而且要全放到内存resp里面再一次吐出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_scan(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    if(req.size() &amp;lt; 4){
        resp-&amp;gt;push_back(&amp;quot;client_error&amp;quot;);
    }else{
        uint64_t limit = req[3].Uint64();
        KIterator *it = serv-&amp;gt;ssdb-&amp;gt;scan(req[1], req[2], limit);
        resp-&amp;gt;push_back(&amp;quot;ok&amp;quot;);
        while(it-&amp;gt;next()){
            resp-&amp;gt;push_back(it-&amp;gt;key);
            resp-&amp;gt;push_back(it-&amp;gt;val);
        }
        delete it;
    }
    return 0;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-hscan"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id58"&gt;4.4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;没有redis 的hscan&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;只有ssdb协议支持hscan, 用法是给出范围.&lt;/p&gt;
&lt;p&gt;支持redis的hgetall, hkeys, hvals&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category><category term="redis"></category></entry><entry><title>从twemproxy计算 redis hitrate</title><link href="/redis-hitrate.html" rel="alternate"></link><updated>2014-07-11T11:37:13+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-11:redis-hitrate.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#get" id="id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;GET&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hmget" id="id2"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;HMGET:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hgetall" id="id3"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;HGETALL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mget" id="id4"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;MGET&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;如何从proxy日志中, 理容response的字节数计算命中率:&lt;/p&gt;
&lt;div class="section" id="get"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;GET&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;key 不存在时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 get kkk
(nil)
$-1..
&lt;/pre&gt;
&lt;p&gt;key存在时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 set k v
OK
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 get k
&amp;quot;v&amp;quot;

$1..v..
&lt;/pre&gt;
&lt;p&gt;判断:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if rsp_len &amp;gt; 5 :
    hit
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="hmget"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id2"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;HMGET:&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;key 不存在时, 或者请求的field都不存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hmget kkk 1 2
1) (nil)
2) (nil)

*2..$-1..$-1..
&lt;/pre&gt;
&lt;p&gt;key 存在, 请求的field有存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hmset kk 1 xxx
OK
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hmget kk 1 2
1) &amp;quot;xxx&amp;quot;
2) (nil)

*2..$3..xxx..$-1..
&lt;/pre&gt;
&lt;p&gt;这样判断:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nfiled = narg - 2
if rsp_len &amp;gt; 3+len(str(nfeild))+(5*nfield):
    hit
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="hgetall"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id3"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;HGETALL&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;key 存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hgetall kk
1) &amp;quot;1&amp;quot;
2) &amp;quot;xxx&amp;quot;
*2..$1..1..$3..xxx..
&lt;/pre&gt;
&lt;p&gt;key不存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hgetall kkk
(empty list or set)

|*0..|
&lt;/pre&gt;
&lt;p&gt;判断:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if rsp_len &amp;gt; 4:
    hit
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="mget"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;MGET&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;用的比较少, 不能简单的从rsp_len来判断.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-latancy问题</title><link href="/redis-latancy.html" rel="alternate"></link><updated>2014-07-09T10:04:00+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-09:redis-latancy.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-latency-problems-troubleshooting" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis latency problems troubleshooting&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1.网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slow-commands" id="id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2.slow commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fork" id="id7"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3.fork&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#swapping" id="id8"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4.swapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof-and-disk-i-o" id="id9"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5.aof and disk I/O&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#expires" id="id10"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;6.expires&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;工具&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#watchdog" id="id12"&gt;1.7.1&amp;nbsp;&amp;nbsp;&amp;nbsp;watchdog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#latancy" id="id13"&gt;1.7.2&amp;nbsp;&amp;nbsp;&amp;nbsp;最新的latancy监控&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id14"&gt;1.8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-latency-problems-troubleshooting"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis latency problems troubleshooting&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;主要来自redis 作者的文章: &lt;a class="reference external" href="http://redis.io/topics/latency"&gt;http://redis.io/topics/latency&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这篇文章介绍了很多工具, iostat, vmstat&lt;/p&gt;
&lt;p&gt;测量:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
redis-cli --latency -h `host` -p `port`
&lt;/pre&gt;
&lt;p&gt;基准(不可能好于这个数):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./redis-cli --intrinsic-latency 100
Max latency so far: 573 microseconds.
Max latency so far: 695 microseconds.
Max latency so far: 919 microseconds.
Max latency so far: 1606 microseconds.
Max latency so far: 3191 microseconds.
Max latency so far: 9243 microseconds.
Max latency so far: 9671 microseconds.
Here we have an intrinsic latency of 9.7 milliseconds: this means that we can't ask better than that to Redis.
&lt;/pre&gt;
&lt;p&gt;可能的原因:&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1.网络&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The typical latency of a 1 GBits/s network is about 200 us, while the latency with a Unix domain socket can be as low as 30 us.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;不要用虚拟机.&lt;/li&gt;
&lt;li&gt;长连接&lt;/li&gt;
&lt;li&gt;use Unix domain sockets&lt;/li&gt;
&lt;li&gt;MSET/MGET/pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;On Linux, some people can achieve better latencies by playing with :&lt;/dt&gt;
&lt;dd&gt;process placement (taskset), cgroups, real-time priorities (chrt), NUMA configuration (numactl), or by using a low-latency kernel.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Please note vanilla Redis is not really suitable to be bound on a single CPU core. Redis can fork background tasks that can be extremely CPU consuming like bgsave or AOF rewrite. These tasks must never run on the same core as the main event loop.&lt;/p&gt;
&lt;p&gt;from Redis 2.4 we use threads in Redis in order to perform some slow I/O operations in the background, mainly related to disk I/O,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="slow-commands"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2.slow commands&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;建议:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;避免keys, sort, lrem, sunion&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="fork"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id7"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3.fork&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;内存page为4K,  24 GB Redis instance requires a page table of 24 GB / 4 KB * 8 = 48 MB&lt;/li&gt;
&lt;li&gt;Xen 上更加糟糕.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;建议:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;使用较小的实例.(&amp;lt;10G)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="swapping"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4.swapping&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;查看swap:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ cat /proc/18941/smaps  | grep Swap
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                156 kB
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="aof-and-disk-i-o"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5.aof and disk I/O&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;write() + fdatasync()&lt;/p&gt;
&lt;p&gt;Both the write(2) and fdatasync(2) calls can be source of latency. For instance write(2) can block both when there is a system wide sync in progress, or when the output buffers are full and the kernel requires to flush on disk in order to accept new writes.&lt;/p&gt;
&lt;p&gt;close 也会导致flush.&lt;/p&gt;
&lt;p&gt;fdatasync 可能从几个ms到几s. 所以redis2.4 尽可能在另一个线程里面做fdatasync.&lt;/p&gt;
&lt;p&gt;When appendfsync is set to the value of no Redis performs no fsync. In this configuration the only source of latency can be write(2).&lt;/p&gt;
&lt;p&gt;测量:&lt;/p&gt;
&lt;blockquote&gt;
sudo strace -p $(pidof redis-server) -T -e trace=fdatasync -f&lt;/blockquote&gt;
&lt;p&gt;因为fdatasync 是在另一个线程, 所以需要加-f&lt;/p&gt;
&lt;p&gt;However since write(2) is also used in order to write data to the client sockets this will likely show too many things unrelated to disk I/O. Apparently there is no way to tell strace to just show slow system calls so I use the following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
strace -f -p $(pidof redis-server) -T -e trace=fdatasync,write 2&amp;gt;&amp;amp;1 | grep -v '0.0' | grep -v unfinished
&lt;/pre&gt;
&lt;p&gt;建议:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;appendfsync no&lt;/li&gt;
&lt;li&gt;Using an SSD disk can help as well,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用这个, 我们在做copy 的时候, 可以观察到:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nhmset\r\n$37\r\np-lc-d687791&amp;quot;..., 272475) = 272475 &amp;lt;0.036430&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;2.030435&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;0.012418&amp;gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nHMSET\r\n$37\r\np-lc-6787211&amp;quot;..., 73) = 73 &amp;lt;0.125906&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;4.476948&amp;gt;
[pid 24734] &amp;lt;... write resumed&amp;gt; )       = 294594 &amp;lt;2.477184&amp;gt;   (2.47s)
&lt;/pre&gt;
&lt;p&gt;此时输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./_binaries/redis-cli --latency-history -h 10.38.114.60 -p 2000
min: 0, max: 223, avg: 1.24 (1329 samples) -- 15.01 seconds range
min: 0, max: 2500, avg: 3.46 (1110 samples) -- 15.00 seconds range   (这里观察到2.5s)
min: 0, max: 5, avg: 1.01 (1355 samples) -- 15.01 seconds range
&lt;/pre&gt;
&lt;p&gt;watchdog 输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[24734] 07 Jul 10:54:41.006 * Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.
[24734 | signal handler] (1404701682)
--- WATCHDOG TIMER EXPIRED ---
bin/redis-server *:2000(logStackTrace+0x4b)[0x443bdb]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
/lib64/tls/libpthread.so.0[0x302b80c420]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
bin/redis-server *:2000(flushAppendOnlyFile+0x76)[0x43f616]
bin/redis-server *:2000(serverCron+0x325)[0x41b5b5]
bin/redis-server *:2000(aeProcessEvents+0x2b2)[0x416a22]
bin/redis-server *:2000(aeMain+0x3f)[0x416bbf]
bin/redis-server *:2000(main+0x1c8)[0x41dcd8]
/lib64/tls/libc.so.6(__libc_start_main+0xdb)[0x302af1c4bb]
bin/redis-server *:2000[0x415b1a]
[24734 | signal handler] (1404701682) --------
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="expires"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;6.expires&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;if the database contains has many many keys expiring in the same second, and this keys are at least 25% of the current population of keys with an expire set,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;工具&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="watchdog"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id12"&gt;1.7.1&amp;nbsp;&amp;nbsp;&amp;nbsp;watchdog&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;redis2.6 自带. 通过时钟中断定时触发检查:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
CONFIG SET watchdog-period 500
&lt;/pre&gt;
&lt;p&gt;会在发现有大延迟时, 打印日志.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="latancy"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id13"&gt;1.7.2&amp;nbsp;&amp;nbsp;&amp;nbsp;最新的latancy监控&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;配置:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
latency-monitor-threshold 100
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;1.8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;2, 3, 5 我们都遇到了.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-aof-latency</title><link href="/redis-aof-latency.html" rel="alternate"></link><updated>2014-07-09T08:36:06+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-09:redis-aof-latency.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;一些分析&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id12"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么慢查询看不到?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id13"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;观察&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#appendfsync-no" id="id14"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么 appendfsync no 无效&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id15"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;一些想法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#page-cache" id="id16"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于page cache&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id17"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;查看当前page cache 状态&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id18"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;参数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#stable-page-write" id="id19"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Stable Page Write&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id20"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;查看线上&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dirty-ratio" id="id21"&gt;3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;调整dirty_ratio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dirty-expire-centisecs" id="id22"&gt;3.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;调整 dirty_expire_centisecs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id23"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id24"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;相关&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;我的redis配置的aof如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
appendonly yes
appendfsync everysec
&lt;/pre&gt;
&lt;p&gt;redis-mgr配置每天早上 6:00-8:00 做aof_rewrite 和 rdb, 所以每天早上这段时间, 我们就会收到twempxoy的forward_err报警, 大约每分钟会损失5000个请求.&lt;/p&gt;
&lt;p&gt;失败率是 10/10000.&lt;/p&gt;
&lt;p&gt;在线上测试, 做一个10G的文件写操作, 就会触发上面问题:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dd if=/dev/zero of=xxxxx bs=1M count=10000 &amp;amp;
&lt;/pre&gt;
&lt;p&gt;我们修改了 &lt;tt class="docutils literal"&gt;appendfsync no&lt;/tt&gt;, 发现这个问题能缓解, 但是不能解决.&lt;/p&gt;
&lt;p&gt;关于redis的各种延迟, 作者antirez的 &lt;a class="reference external" href="/redis-latancy.html"&gt;这篇文章&lt;/a&gt; 已经说的很清楚了.&lt;/p&gt;
&lt;p&gt;我们这里遇到的就是有disk I/O 的时候aof受到影响.&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id11"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;一些分析&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id12"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么慢查询看不到?&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;慢查询统计的时间只包括cpu计算的时间, 写aof这个过程不计入查询时间统计(也不应该计入)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id13"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;观察&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;用下面命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
strace -f -p $(pidof redis-server) -T -e trace=fdatasync,write 2&amp;gt;&amp;amp;1 | grep -v '0.0' | grep -v unfinished
&lt;/pre&gt;
&lt;p&gt;我们在做copy 的时候, 可以观察到:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nhmset\r\n$37\r\np-lc-d687791&amp;quot;..., 272475) = 272475 &amp;lt;0.036430&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;2.030435&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;0.012418&amp;gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nHMSET\r\n$37\r\np-lc-6787211&amp;quot;..., 73) = 73 &amp;lt;0.125906&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;4.476948&amp;gt;
[pid 24734] &amp;lt;... write resumed&amp;gt; )       = 294594 &amp;lt;2.477184&amp;gt;   (2.47s)
&lt;/pre&gt;
&lt;p&gt;此时输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./_binaries/redis-cli --latency-history -h 10.38.114.60 -p 2000
min: 0, max: 223, avg: 1.24 (1329 samples) -- 15.01 seconds range
min: 0, max: 2500, avg: 3.46 (1110 samples) -- 15.00 seconds range   (这里观察到2.5s)
min: 0, max: 5, avg: 1.01 (1355 samples) -- 15.01 seconds range
&lt;/pre&gt;
&lt;p&gt;watchdog 输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[24734] 07 Jul 10:54:41.006 * Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.
[24734 | signal handler] (1404701682)
--- WATCHDOG TIMER EXPIRED ---
bin/redis-server *:2000(logStackTrace+0x4b)[0x443bdb]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
/lib64/tls/libpthread.so.0[0x302b80c420]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
bin/redis-server *:2000(flushAppendOnlyFile+0x76)[0x43f616]
bin/redis-server *:2000(serverCron+0x325)[0x41b5b5]
bin/redis-server *:2000(aeProcessEvents+0x2b2)[0x416a22]
bin/redis-server *:2000(aeMain+0x3f)[0x416bbf]
bin/redis-server *:2000(main+0x1c8)[0x41dcd8]
/lib64/tls/libc.so.6(__libc_start_main+0xdb)[0x302af1c4bb]
bin/redis-server *:2000[0x415b1a]
[24734 | signal handler] (1404701682) --------
&lt;/pre&gt;
&lt;p&gt;所以确定是write hang住&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="appendfsync-no"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么 appendfsync no 无效&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;当磁盘写buf满的时候, write就会阻塞, 释放一些buf才会允许继续写入,&lt;/p&gt;
&lt;p&gt;所以, 如果程序不调用sync, 系统就会在不确定的时候 做sync, 此时 &lt;tt class="docutils literal"&gt;wirte()&lt;/tt&gt; 就会hang住&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id15"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;一些想法&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;能否对rdb/aof_rewrite/cp等命令限速,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不可能针对每个进程(比如有其它写日志的进程) 都做限制. 所以最好不要这样.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;增加proxy timeout, 目前400ms, 增加到2000ms?&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;如果超时400ms, 想当于快速失败. 客户端重试效果一样, 所以还是不必改.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;master 关aof&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这个方法不需要做任何改动, 代价较小, 效果最好, 缺点是提高运维复杂性和数据可靠性, redis-mgr可以做这个支持.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;write 时的阻塞貌似无法避免, 能否用一个新的线程来做write呢?&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;关于这个想法写了个patch提给作者: &lt;a class="reference external" href="https://github.com/antirez/redis/pull/1862"&gt;https://github.com/antirez/redis/pull/1862&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;不过作者貌似不太感冒.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="page-cache"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id16"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于page cache&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;IO调度一般是针对读优化的, 因为读的时候是同步的, 进程读取不到, 就会睡眠.
写是异步的, 只是写到page cache.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;查看当前page cache 状态&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
grep ^Cached: /proc/meminfo # page cache size
grep ^Dirty: /proc/meminfo # total size of all dirty pages
grep ^Writeback: /proc/meminfo # total size of actively processed dirty pages
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;参数&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ sysctl -a | grep dirty
vm.dirty_background_ratio = 10
vm.dirty_background_bytes = 0
vm.dirty_ratio = 20
vm.dirty_bytes = 0
vm.dirty_writeback_centisecs = 1500
vm.dirty_expire_centisecs = 3000
&lt;/pre&gt;
&lt;p&gt;详细参考: &lt;a class="reference external" href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt"&gt;https://www.kernel.org/doc/Documentation/sysctl/vm.txt&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/proc/sys/vm/dirty_expire_centisecs         #3000, 表示3000*0.01s = 30s, 队列中超过30s的被刷盘.
/proc/sys/vm/dirty_writeback_centisecs      #1500, 表示1500*0.01s = 15s, 内核pdflush wakeup 一次.

/proc/sys/vm/dirty_background_ratio
/proc/sys/vm/dirty_ratio
Both values are expressed as a percentage of RAM. When the amount of dirty pages reaches the first threshold (dirty_background_ratio), write-outs begin in the background via the “flush” kernel threads. When the second threshold is reached, processes will block, flushing in the foreground.


The problem with these variables is their minimum value: even 1% can be too much. This is why another two controls were introduced in 2.6.29:
/proc/sys/vm/dirty_background_bytes
/proc/sys/vm/dirty_bytes
&lt;/pre&gt;
&lt;p&gt;x_bytes 和 x_ratio是互斥的, 设置dirty_bytes 的时候, dirty_ratio 会被清0:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_bytes
0
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_ratio
20
root&amp;#64;ning-laptop:~# echo '5000000' &amp;gt; /proc/sys/vm/dirty_bytes
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_bytes
5000000
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_ratio
0
&lt;/pre&gt;
&lt;p&gt;Lower values generate more I/O requests (and more interrupts), significantly decrease sequential I/O bandwidth but also decrease random I/O latency
数值小的时候, 会减小IO系统带宽, 同时减少 随机的IO延迟.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://monolight.cc/2011/06/barriers-caches-filesystems/"&gt;http://monolight.cc/2011/06/barriers-caches-filesystems/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stable-page-write"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Stable Page Write&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="http://yoshinorimatsunobu.blogspot.com/2014/03/why-buffered-writes-are-sometimes.html"&gt;http://yoshinorimatsunobu.blogspot.com/2014/03/why-buffered-writes-are-sometimes.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When a dirty page is written to disk, write() to the same dirty page is blocked until flushing to disk is done. This is called &lt;strong&gt;Stable Page Write&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This may cause write() stalls, especially when using slower disks. Without write cache, flushing to disk takes ~10ms usually, ~100ms in bad cases.&lt;/p&gt;
&lt;p&gt;有patch在较新的内核上能缓解这个问题, 原理是减少write调用 wait_on_page_writeback 的几率:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=1d1d1a767206fbe5d4c69493b7e6d2a8d08cc0a0
Here's the result of using dbench to test latency on ext2:

3.8.0-rc3:
 Operation      Count    AvgLat    MaxLat
 ----------------------------------------
 WriteX        109347     0.028    59.817
 ReadX         347180     0.004     3.391
 Flush          15514    29.828   287.283

Throughput 57.429 MB/sec  4 clients  4 procs  max_latency=287.290 ms

3.8.0-rc3 + patches:
 WriteX        105556     0.029     4.273
 ReadX         335004     0.005     4.112
 Flush          14982    30.540   298.634

Throughput 55.4496 MB/sec  4 clients  4 procs  max_latency=298.650 ms

As you can see, the maximum write latency drops considerably with this
patch enabled.
&lt;/pre&gt;
&lt;p&gt;据说xfs 也能解决问题.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id20"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;查看线上&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
$ cat /proc/sys/vm/dirty_background_ratio
10
$ cat /proc/sys/vm/dirty_ratio
20
&lt;/pre&gt;
&lt;p&gt;平时dirty:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ grep ^Dirty: /proc/meminfo
Dirty:            104616 kB
机器内存128G.
&lt;/pre&gt;
&lt;p&gt;早上做rdb/aof_rewrite时, dirty:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
500,000 kB (500M)
&lt;/pre&gt;
&lt;p&gt;都还没到达配置的 &lt;tt class="docutils literal"&gt;dirty_background_ratio&lt;/tt&gt; , &lt;tt class="docutils literal"&gt;dirty_ratio&lt;/tt&gt; 所以调这两个参数估计没用.&lt;/p&gt;
&lt;p&gt;测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#1. 最常90s.
vm.dirty_expire_centisecs = 9000
echo '9000' &amp;gt; /proc/sys/vm/dirty_expire_centisecs

#2. 改大dirty_ratio
echo '80' &amp;gt; /proc/sys/vm/dirty_ratio
&lt;/pre&gt;
&lt;div class="section" id="dirty-ratio"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id21"&gt;3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;调整dirty_ratio&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;在一个io较差的48G机器上,  设置 dirty_ratio = 80, dirty 会涨的很高, 但是redis延迟看不明显的改善:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ grep ^Dirty: /proc/meminfo
Dirty:           8598180 kB  =&amp;gt;echo '80' &amp;gt; /proc/sys/vm/dirty_ratio
$ grep ^Dirty: /proc/meminfo
Dirty:          11887180 kB
$ grep ^Dirty: /proc/meminfo
Dirty:          21295624 kB
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="dirty-expire-centisecs"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id22"&gt;3.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;调整 dirty_expire_centisecs&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;看上去也没有效果, 有变差趋势.
因为我在线下是通过长期dd来压测, 和线上还不太一样.&lt;/p&gt;
&lt;p&gt;看来只能线上测试了.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id23"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;master关aof应该是目前最可以接受的方法&lt;/li&gt;
&lt;li&gt;antirez在做一个latency采样的工作&lt;/li&gt;
&lt;li&gt;XFS/Solaris 貌似没有这个问题.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id24"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;相关&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;a class="reference external" href="http://redis.io/topics/latency"&gt;http://redis.io/topics/latency&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;11 年就有的讨论 &lt;a class="reference external" href="https://groups.google.com/forum/#!msg/redis-db/jgGuGngDEb0/ZwnvUdx-gdAJ"&gt;https://groups.google.com/forum/#!msg/redis-db/jgGuGngDEb0/ZwnvUdx-gdAJ&lt;/a&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;作者本来想把write和fsync都移到另一个线程, 结论是把fsync移到一个线程了,&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Linkedin 的一个工程师做了这样一个实验, 测试用1/4的带宽来写的时候, 产生的延迟情况:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://blog.empathybox.com/post/35088300798/why-does-fwrite-sometimes-block"&gt;http://blog.empathybox.com/post/35088300798/why-does-fwrite-sometimes-block&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-config-hz</title><link href="/redis-config-hz.html" rel="alternate"></link><updated>2014-06-24T10:19:32+08:00</updated><author><name>ning</name></author><id>tag:,2014-06-24:redis-config-hz.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id3"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;现象&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#cen-li" id="id4"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;cen-li的分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hz-antirez" id="id5"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于hz, antirez 的一个解释&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id6"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id3"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;现象&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;redis 内存居高不下&lt;/p&gt;
&lt;p&gt;我们上线了一个新的业务后, 单实例内存从4G彪到6G左右, 凌晨低峰期大约5G. 调整cache时间, 由4h改为2h, 未见内存下降.&lt;/p&gt;
&lt;p&gt;怀疑是key已经过期, 但是并未淘汰. 通过把线上aof重放到线下看, 线上有19M个key, 线下只有12M个key, 说明存在很多脏key(过期但是未淘汰)&lt;/p&gt;
&lt;p&gt;修改配置 &lt;tt class="docutils literal"&gt;HZ=100&lt;/tt&gt; , 加速淘汰, 内存开始下降, 从5.5G下降到3.5G.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cen-li"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;cen-li的分析&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;至于hz应该设什么值, 可以参考 cen-li的分析: &lt;a class="reference external" href="http://cen-li.github.io/redis-expire.html"&gt;http://cen-li.github.io/redis-expire.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;总结下来:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;key的淘汰有三个时机:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;主动(cron定时执行)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;每秒执行HZ次(理想情况), 每次执行一个固定时间片: &lt;tt class="docutils literal"&gt;1s/HZ/4&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;被动&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;写操作时, 发现内存超过maxmemory, 此时淘汰n个key, 直到内存降到配置maxmemory以下.&lt;/li&gt;
&lt;li&gt;读操作时, 发现当前读取的key已经过期, 则淘汰掉.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;内存不满的集群, 主要受到cron淘汰机制的制约, 此时有一个算法来淘汰, 此时我们可以得出 &lt;tt class="docutils literal"&gt;脏key率&lt;/tt&gt; 和 &lt;tt class="docutils literal"&gt;key 淘汰速度&lt;/tt&gt; 的关系:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
X: 脏key率
Y: 每个主程序循环内执行loop2次数 (Y &amp;gt;= 1)
HZ: 每秒执行多少次cron
qps：qps为key的过期速度，不考虑流量的波动的话，约等于当时的过期操作的请求数
&lt;/pre&gt;
&lt;p&gt;得出如下关系:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
X = qps / (20 * HZ * Y)
&lt;/pre&gt;
&lt;p&gt;因为 &lt;tt class="docutils literal"&gt;Y &amp;gt;= 1&lt;/tt&gt;, 所以上面公式给出了一个 &lt;tt class="docutils literal"&gt;脏key率 X&lt;/tt&gt; 的上限, 比如:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
HZ=10  =&amp;gt; X&amp;lt;=pqs/200.
HZ=100 =&amp;gt; X&amp;lt;=pqs/2000.
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;调大HZ会导致redis空闲时的cpu占用上升, 我们的场景下单实例CPU占用大约增加 &lt;tt class="docutils literal"&gt;1%&lt;/tt&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;其它:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;aof rewrite和rdb不会包括已过期的key&lt;/li&gt;
&lt;li&gt;从库不执行过期操作, 主库过期一个key时，会生成一个DEL操作，该操作会同步到从库。&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="hz-antirez"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于hz, antirez 的一个解释&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://groups.google.com/forum/#!topic/redis-db/6kILekxQXBM"&gt;https://groups.google.com/forum/#!topic/redis-db/6kILekxQXBM&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Redis HZ was 10 in 2.4
Redis HZ is 100 in 2.6
2.8 里面增加HZ配置, 默认10.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;对于快速淘汰的cache集群, 应该设置较大的hz, 100是一个无害值.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>fatcache-cr</title><link href="/fatcache-cr.html" rel="alternate"></link><updated>2014-05-21T14:17:46+08:00</updated><author><name>ning</name></author><id>tag:,2014-05-21:fatcache-cr.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id8"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;设计理念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id9"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fc-request-c" id="id10"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fc_request.c 中的请求处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mmap-map-anonymous" id="id11"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mmap 的和 MAP_ANONYMOUS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#device-size" id="id12"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;如何获取device_size&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slab" id="id13"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;slab逻辑&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id14"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;启动&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id15"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;启动日志如下&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id16"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;写操作过程中对slab的使用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id17"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;性能测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id18"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#todo" id="id19"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;TODO&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;设计理念&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Eliminate small, random disk writes&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;batched write&lt;/li&gt;
&lt;li&gt;如果用mmap的方式使用ssd(比如mongo), 就会产生很多随机写.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Minimize disk reads on cache hit&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Fatcache reduces disk reads by maintaining an in-memory index for all on-disk data.&lt;/li&gt;
&lt;li&gt;no disk accesses on cache miss and only a single disk access on cache hit.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;定期gc, 对所有在磁盘上, 而不在内存索引中的元素清掉.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;内存index&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;所有key放在内存中, 内存中hash表记录value在磁盘上的位置.&lt;/li&gt;
&lt;li&gt;拉链式hash表&lt;/li&gt;
&lt;li&gt;为了减少key放在内存中的大小, 使用sha1, (冲突在读的时候会检测, 写的时候覆盖.)&lt;/li&gt;
&lt;li&gt;The index entry (struct itemx) on a 64-bit system is 44 bytes in size&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;量不大:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/fatcache/src$ cat *.c *.h|wc -l
9830
&lt;/pre&gt;
&lt;p&gt;util:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc_queue.h
fc_array.c
fc_array.h
fc_log.c
fc_log.h
fc_sha1.c
fc_sha1.h
fc_signal.c
fc_signal.h
fc_string.c
fc_string.h
fc_time.c
fc_time.h
fc_util.c
fc_util.h
&lt;/pre&gt;
&lt;p&gt;事件和连接处理:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc_event.c
fc_event.h
fc_connection.c
fc_connection.h
fc_mbuf.c
fc_mbuf.h
fc_core.c
fc_core.h
fc_client.c
fc_client.h
fc_server.c
fc_server.h
&lt;/pre&gt;
&lt;p&gt;请求处理:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc.c
fc_memcache.c           协议解析.
fc_memcache.h
fc_message.c
fc_message.h
fc_request.c            #处理请求, 转化为itemx/slab 存储. 读取.
fc_response.c           #如何发送response
&lt;/pre&gt;
&lt;p&gt;cache模型:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc_item.c
fc_item.h
fc_itemx.c
fc_itemx.h
fc_slab.c
fc_slab.h
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;util&lt;/tt&gt; 和 &lt;tt class="docutils literal"&gt;事件处理&lt;/tt&gt; 部分和twemproxy有极大复用度. 请求处理部分主要是协议的解析.&lt;/p&gt;
&lt;p&gt;fc_request是负责将解析出来的请求转化为存储层的函数调用(操作item/itemx/slab)&lt;/p&gt;
&lt;p&gt;概念:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;item: 一个kv对,&lt;/li&gt;
&lt;li&gt;itemx: 索引项&lt;/li&gt;
&lt;li&gt;slab: 用来存储item, 一个slab默认是1M(最大可配为512M), 可以存放多个item. slab有内存和磁盘两种类型.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;item:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct item {
    uint32_t          magic;      /* item magic (const) */
    uint32_t          offset;     /* raw offset from owner slab base (const) */
    uint32_t          sid;        /* slab id (const) */
    uint8_t           cid;        /* slab class id (const) */
    uint8_t           unused[2];  /* unused */
    uint8_t           nkey;       /* key length */
    uint32_t          ndata;      /* date length */
    rel_time_t        expiry;     /* expiry in secs */
    uint32_t          flags;      /* flags opaque to the server */
    uint8_t           md[20];     /* key sha1*/
    uint32_t          hash;       /* key hash */
    uint8_t           end[1];     /* item data */
};

uint8_t * item_key(struct item *it) { return it-&amp;gt;end; }                                     //获得item-&amp;gt;key
uint8_t * item_data(struct item *it) { return it-&amp;gt;end + it-&amp;gt;nkey; }                         //获得item-&amp;gt;value
size_t item_ntotal(uint8_t nkey, uint32_t ndata) { return ITEM_HDR_SIZE + nkey + ndata; }   //获得item大小.

struct itemx {
    STAILQ_ENTRY(itemx) tqe;    /* link in index / free q */
    uint8_t             md[20]; /* sha1 */
    uint32_t            sid;    /* owner slab id */
    uint32_t            offset; /* item offset from owner slab base */
    uint64_t            cas;    /* cas */
} __attribute__ ((__packed__));

struct slab {
    uint32_t  magic;     /* slab magic (const) */
    uint32_t  sid;       /* slab id */
    uint8_t   cid;       /* slab class id */
    uint8_t   unused[3]; /* unused */
    uint8_t   data[1];   /* opaque data */
};
&lt;/pre&gt;
&lt;div class="section" id="fc-request-c"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fc_request.c 中的请求处理&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
static void
req_process_get(struct context *ctx, struct conn *conn, struct msg *msg)
{
    struct itemx *itx;
    struct item *it;

    itx = itemx_getx(msg-&amp;gt;hash, msg-&amp;gt;md);
    if (itx == NULL) {
        msg_type_t type;

        /*
         * On a miss, we send a &amp;quot;END\r\n&amp;quot; response, unless the request
         * is an intermediate fragment in a fragmented request.
         */
        if (msg-&amp;gt;frag_id == 0 || msg-&amp;gt;last_fragment) {
            type = MSG_RSP_END;
        } else {
            type = MSG_EMPTY;
        }

        rsp_send_status(ctx, conn, msg, type);
        return;
    }

    /*
     * On a hit, we read the item with address [sid, offset] and respond
     * with item value if the item hasn't expired yet.
     */
    it = slab_read_item(itx-&amp;gt;sid, itx-&amp;gt;offset);
    if (it == NULL) {
        rsp_send_error(ctx, conn, msg, MSG_RSP_SERVER_ERROR, errno);
        return;
    }
    if (item_expired(it)) {
        rsp_send_status(ctx, conn, msg, MSG_RSP_NOT_FOUND);
        return;
    }

    rsp_send_value(ctx, conn, msg, it, itx-&amp;gt;cas);
}

static void
req_process_set(struct context *ctx, struct conn *conn, struct msg *msg)
{
    uint8_t *key, nkey, cid;
    struct item *it;

    key = msg-&amp;gt;key_start;
    nkey = (uint8_t)(msg-&amp;gt;key_end - msg-&amp;gt;key_start);

    cid = item_slabcid(nkey, msg-&amp;gt;vlen);
    if (cid == SLABCLASS_INVALID_ID) {
        rsp_send_error(ctx, conn, msg, MSG_RSP_CLIENT_ERROR, EINVAL);
        return;
    }

    itemx_removex(msg-&amp;gt;hash, msg-&amp;gt;md);

    it = item_get(key, nkey, cid, msg-&amp;gt;vlen, time_reltime(msg-&amp;gt;expiry),
                  msg-&amp;gt;flags, msg-&amp;gt;md, msg-&amp;gt;hash);
    if (it == NULL) {
        rsp_send_error(ctx, conn, msg, MSG_RSP_SERVER_ERROR, ENOMEM);
        return;
    }

    mbuf_copy_to(&amp;amp;msg-&amp;gt;mhdr, msg-&amp;gt;value, item_data(it), msg-&amp;gt;vlen);

    rsp_send_status(ctx, conn, msg, MSG_RSP_STORED);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="mmap-map-anonymous"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mmap 的和 MAP_ANONYMOUS&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;代码中看到下面这种用法, 不理解是什么意思, 于是查了一下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void *
_fc_mmap(size_t size, const char *name, int line)
{
    p = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS,
             -1, 0);
}
&lt;/pre&gt;
&lt;p&gt;man:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
MAP_ANONYMOUS
  The mapping is not backed by any file; its contents are initialized to zero.  The fd and offset arguments are ignored; however, some implementations require fd to be  -1  if  MAP_ANONYMOUS
  (or MAP_ANON) is specified, and portable applications should ensure this.  The use of MAP_ANONYMOUS in conjunction with MAP_SHARED is only supported on Linux since kernel 2.4.
&lt;/pre&gt;
&lt;p&gt;mmap 的 &lt;tt class="docutils literal"&gt;MAP_ANONYMOUS&lt;/tt&gt; 相当于malloc一片内存:&lt;/p&gt;
&lt;p&gt;MAP_ANONYMOUS is commonly used for two things on systems that implement it:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;To share a memory region between a parent and a child, as you said.  However, it requires that the child does not execve(), since it must have the pointer to the mmap()ed address.&lt;/li&gt;
&lt;li&gt;To simply get memory pages from the kernel. That's how most malloc() implementations work nowadays. (The glibc malloc() uses brk() for small allocations and mmap() with MAP_ANONYMOUS for big ones.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
itemx_init:
    /* init item index memory */
    itx = fc_mmap(settings.max_index_memory);
    if (itx == NULL) {
        return FC_ENOMEM;
    }
    istart = itx;
    iend = itx + n;

slab_init:
    /* init nmslab, mstart and mend */
    nmslab = MAX(nctable, settings.max_slab_memory / settings.slab_size);
    mspace = nmslab * settings.slab_size;
    mstart = fc_mmap(mspace);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="device-size"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id12"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;如何获取device_size&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
fc_device_size(const char *path, size_t *size)
{
    fd = open(path, O_RDONLY, 0644);
    status = ioctl(fd, BLKGETSIZE64, size);
    return FC_OK;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="slab"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;slab逻辑&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;fatcache 有两种slab: &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;mem-slab&lt;/span&gt;&lt;/tt&gt; 和 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;disk-slab&lt;/span&gt;&lt;/tt&gt;, 大小相同,&lt;/p&gt;
&lt;p&gt;mem-slab作为disk-slab的写buffer.&lt;/p&gt;
&lt;p&gt;一个slab里面可以包含多个item. 写操作都是写到mem-slab, 写满一个, 就交换到disk-slab, 能做到顺序写, 随机读, 从而最大化ssd利用率.&lt;/p&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;启动&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
struct settings {
    size_t   max_slab_memory;              /* maximum memory allowed for slabs in bytes */
    size_t   max_index_memory;             /* maximum memory allowed for in bytes */
    size_t   slab_size;                    /* slab size */

    size_t   chunk_size;                   /* minimum item chunk size */
    size_t   max_chunk_size;               /* maximum item chunk size */
    double   factor;                       /* item chunk size growth factor */
};
&lt;/pre&gt;
&lt;p&gt;启动后, 先从配置中获得slab_size, 根据配置的mem-slab大小和磁盘大小, 计算总共有多少个slab, 分别初始化 ctable和stable:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slab_init(void)
{

    status = slab_init_ctable();                //根据factor, 初始化一系列slab-class, 每个slab-class的item-size呈递增关系.

    //计算有多少个mem-slab
    nmslab = MAX(nctable, settings.max_slab_memory / settings.slab_size);

    //计算有多少个disk-slab
    status = fc_device_size(settings.ssd_device, &amp;amp;size);
    ndchunk = size / settings.slab_size;        //整个device能放多少个slab?
    ASSERT(settings.server_n &amp;lt;= ndchunk);
    ndslab = ndchunk / settings.server_n;

    status = slab_init_stable();
}
&lt;/pre&gt;
&lt;p&gt;slab的总个数就是nmslab+ndslab.  slab总数, mslab, dslab 的个数都是不会变的.&lt;/p&gt;
&lt;p&gt;初始化完成后, 所有的mem-slab和disk-slab都被标记为free(放到free_xxx_q里面)&lt;/p&gt;
&lt;p&gt;初始化完成后, 如下图所示:&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-001.png" style="width: 800px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;启动日志如下&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
$ ./src/fatcache -D /dev/sdb -p 11211 -s 0/8
[Wed May 21 21:51:51 2014] fc.c:683 fatcache-0.1.1 started on pid 1721
[Wed May 21 21:51:51 2014] fc.c:688 configured with debug logs disabled, asserts disabled, panic disabled
[Wed May 21 21:51:51 2014] fc_slab.c:85 slab size 1048576, slab hdr size 12, item hdr size 52, item chunk size 88
[Wed May 21 21:51:51 2014] fc_slab.c:88 index memory 0, slab memory 67108864, disk space 239498952704
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   0: items   11915  size      88  data      36  slack      44
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   1: items    9362  size     112  data      60  slack      20
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   2: items    7281  size     144  data      92  slack     100
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   3: items    5698  size     184  data     132  slack     132
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   4: items    4519  size     232  data     180  slack     156
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   5: items    3542  size     296  data     244  slack     132
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   6: items    2788  size     376  data     324  slack     276
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   7: items    2221  size     472  data     420  slack     252
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   8: items    1771  size     592  data     540  slack     132
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   9: items    1409  size     744  data     692  slack     268
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  10: items    1120  size     936  data     884  slack     244
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  11: items     891  size    1176  data    1124  slack     748
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  12: items     712  size    1472  data    1420  slack     500
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  13: items     569  size    1840  data    1788  slack    1604
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  14: items     455  size    2304  data    2252  slack     244
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  15: items     364  size    2880  data    2828  slack     244
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  16: items     291  size    3600  data    3548  slack     964
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  17: items     232  size    4504  data    4452  slack    3636
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  18: items     186  size    5632  data    5580  slack    1012
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  19: items     148  size    7040  data    6988  slack    6644
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  20: items     119  size    8800  data    8748  slack    1364
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  21: items      95  size   11000  data   10948  slack    3564
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  22: items      76  size   13752  data   13700  slack    3412
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  23: items      60  size   17192  data   17140  slack   17044
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  24: items      48  size   21496  data   21444  slack   16756
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  25: items      39  size   26872  data   26820  slack     556
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  26: items      31  size   33592  data   33540  slack    7212
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  27: items      24  size   41992  data   41940  slack   40756
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  28: items      19  size   52496  data   52444  slack   51140
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  29: items      15  size   65624  data   65572  slack   64204
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  30: items      12  size   82032  data   81980  slack   64180
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  31: items      10  size  102544  data  102492  slack   23124
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  32: items       8  size  128184  data  128132  slack   23092
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  33: items       6  size  160232  data  160180  slack   87172
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  34: items       5  size  200296  data  200244  slack   47084
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  35: items       4  size  250376  data  250324  slack   47060
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  36: items       3  size  312976  data  312924  slack  109636
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  37: items       2  size  391224  data  391172  slack  266116
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  38: items       2  size  489032  data  488980  slack   70500
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  40: items       1  size  764120  data  764068  slack  284444
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  41: items       1  size  955152  data  955100  slack   93412
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  42: items       1  size 1048564  data 1048512  slack       0
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id16"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;写操作过程中对slab的使用&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
req_process_set
    cid = item_slabcid(nkey, msg-&amp;gt;vlen)     //计算需要一个多大的item
    itemx_removex(msg-&amp;gt;hash, msg-&amp;gt;md);      //如果索引里面已有, 删掉
    item_get                                //获得一个klen+vlen大小的item.
        slab_get_item
            1. 尝试从ctable[cid]-&amp;gt;partial_msinfoq 里面获取.  如果获取到则返回
            2. 尝试从free_msinfoq中获取一个free的mslab挂到 ctable[cid]-&amp;gt;partial_msinfoq, to 1.
            3. 如果上面两步都失败, 则 slab_drain()
                如果还有空闲的dslab, 直接把这个mslab刷到dslab.
                如果没有:
                slab_evict //先回收一块磁盘上的空间. (这会导致写操作的时候有读)
                _slab_drain //把一个写满的mem_slab刷盘.
                    - pwrite
&lt;/pre&gt;
&lt;p&gt;这里我主要分析mem-slab和disk-slab交换的过程, 在如下时刻都是转折点:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;启动后第一个插入操作.&lt;/li&gt;
&lt;li&gt;mem-slab用光, 开始启用第一个disk-slab&lt;/li&gt;
&lt;li&gt;disk-slab用光, 开始会对disk-slab做回收.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面举例:&lt;/p&gt;
&lt;p&gt;在获取slab的过程中, 我们假设 假设每次写操作都希望获得一个size为100的item, 这样就只会涉及到一个slab class.( &lt;tt class="docutils literal"&gt;ctable[1]&lt;/tt&gt; )&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;第一次写, 发现 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ctable[1]-&amp;gt;partial_msinfoq&lt;/span&gt;&lt;/tt&gt; 为空, 于是从 &lt;tt class="docutils literal"&gt;free_msinfoq&lt;/tt&gt; 中拿一个挂到 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ctable[cid]-&amp;gt;partial_msinfoq&lt;/span&gt;&lt;/tt&gt; , 并从这个slab中分配一个item, 写入数据,
这样一直写, 直到这个slab写满, 就把它移到full_msinfoq, 并获取下一个free_msinfoq&lt;/p&gt;
&lt;p&gt;这个过程如下图:&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-002.png" style="width: 500px;" /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;当mem-slab用光后, 就会开始使用disk-slab, 这是通过一次drain实现的, drain 会找到一个free 的disk-slab, 把它刷到这个disk-slab对应的磁盘上,
这样就产生了一个free-mem-slab 和一个full-disk-slab.&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-003.png" style="width: 500px;" /&gt;
&lt;p&gt;此后full_msinfoq 就一直处于空的状态, 每次需要一个slab, 都发生一次drain, 每次drain都会消耗一个disk-slab, 如下图:&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-004.png" style="width: 500px;" /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;再过了一段时间, disk-slab用光, 此时mem-slab 和disk-slab都full,
此时为了获得一个disk-slab, 就会发生一次 evict, 驱逐掉一个disk-slab中的数据(最老的) 获得一个free-disk-slab, 然后回到2, 获得一个free-mem-slab&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;这里是一种fifo的淘汰, 比较悲剧?&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;img alt="" src="/imgs/fatcache-005.png" style="width: 500px;" /&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;性能测试&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;我的性能测试, 先set 10亿条100字节的数据, 再来get:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
num = 1000000000 #10亿
cmd = 'mc-benchmark  -p 11211 -n %s -r %s -d 100' % (num, num)
&lt;/pre&gt;
&lt;p&gt;发现, fatcache始终能维持5w+的 写入和读取, 但是问题是, 读压力的时候, 磁盘的read-iops才不到100, 这很不合理. 具体原因没有仔细追查.&lt;/p&gt;
&lt;p&gt;因为 -n 1000000000 -r 100000000000 的话, 命中率只有1%. 很多查询通过内存就能发现key不存在, 根本不需要访问ssd.&lt;/p&gt;
&lt;p&gt;benchmark的结果(图中前半段是写入, 后半段是读取, 读取时的r/s很低, 不能解释):&lt;/p&gt;
&lt;img alt="" src="/imgs/stat_ssd_fat_1.log.png" style="width: 800px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id18"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;限制: item (key+value必须小于一个slab)&lt;/li&gt;
&lt;li&gt;disk-slab的回收是fifo, 这不好.&lt;/li&gt;
&lt;li&gt;裸写设备的方法, 虽然能更好的利用磁盘的iops, 但是我不太喜欢.&lt;/li&gt;
&lt;li&gt;fc 不会持久化, 虽然它写磁盘, 但是它重启的时候, 是默认把所有slab都标记为free.&lt;/li&gt;
&lt;li&gt;用 &lt;tt class="docutils literal"&gt;sha1&lt;/tt&gt; 做index里面的key, 也是一个不好的地方&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="todo"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id19"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;TODO&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;问题:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;从代码看, 应该是现有twemproxy, 后有fatcache.&lt;/li&gt;
&lt;li&gt;如何处理expire, 参看 req_process_get&lt;/li&gt;
&lt;li&gt;目测get的时候一个kv, 只能放在一个mbuf里面 rsp_send_value?&lt;/li&gt;
&lt;li&gt;没有主从同步等机制.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;小结:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;自己管理实现存储引擎, 需要关注空间分配, 回收, 索引等, 略复杂, 用levelDB是比较好的方案. 不用关注这一层的细节.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>ssd-cache</title><link href="/ssd-cache.html" rel="alternate"></link><updated>2014-05-13T06:56:03+08:00</updated><author><name>ning</name></author><id>tag:,2014-05-13:ssd-cache.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id25"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;需求&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#why" id="id26"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;why&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id27"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;具体需求&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#index" id="id28"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;index&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ssd" id="id29"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 特性&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id30"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;成本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id31"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;接口&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id32"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;比较典型的ssd参数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id33"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id34"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;现有系统调研&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis" id="id35"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基于redis修改&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-vm" id="id36"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-vm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-storage" id="id37"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id38"&gt;4.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id39"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;单机存储引擎&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#leveldb" id="id40"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#rocksdb-facebook" id="id41"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RocksDB(facebook)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#berkley-db" id="id42"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Berkley DB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#nessdb" id="id43"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;nessDB(国人开发)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id44"&gt;4.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id45"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;备选项目&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id46"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssdb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id47"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fatcache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ardb" id="id48"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;ardb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ledisdb" id="id49"&gt;4.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;ledisdb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id18" id="id50"&gt;4.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id19" id="id51"&gt;4.3.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id20" id="id52"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;成熟分布式存储系统&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#tair" id="id53"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;淘宝tair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aerospike" id="id54"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;aerospike&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#facebook-apollo" id="id55"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook Apollo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#facebook-mcdipper" id="id56"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook-McDipper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ckv" id="id57"&gt;4.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;#腾讯CKV海量分布式存储系统&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id21" id="id58"&gt;4.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id22" id="id59"&gt;4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它思路&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id23" id="id60"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id24" id="id61"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;关于目前的很多系统&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;style type="text/css"&gt;
      table {
        width: 30%
      }
&lt;/style&gt;&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id25"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;需求&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="why"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id26"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;why&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;用redis内存实在太贵了, 假设要存1T数据双副本:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;内存: 1000*2 / 64 = 32台机器.&lt;/li&gt;
&lt;li&gt;2T盘机器:  2-4台&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id27"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;具体需求&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;数据存放在ssd.&lt;/li&gt;
&lt;li&gt;性能要求: 6台机器的集群10w/s, (单机2w/s)&lt;/li&gt;
&lt;li&gt;有expire功能.&lt;/li&gt;
&lt;li&gt;使用redis协议 (twemproxy, client-lib可以复用)&lt;/li&gt;
&lt;li&gt;数据类型仅支持kv, 以后可以考虑支持hash.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其它:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;事务或script支持.&lt;/li&gt;
&lt;li&gt;主从, failover&lt;/li&gt;
&lt;li&gt;集群.&lt;/li&gt;
&lt;li&gt;redis-mgr 部署支持&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="index"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id28"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;index&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;主要涉及下面几个方面:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;ssd特性.&lt;/li&gt;
&lt;li&gt;存储引擎,  如LevelDB, RocksDB, BDB等.&lt;/li&gt;
&lt;li&gt;现有系统的调研和benchmark, 主要关注SSDB和fatcache.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文是这个调研系列的目录和结论, 相关调研:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="/coding-for-ssd.html"&gt;coding-for-ssd笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LevelDB 调研 TODO&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/cr-ssdb.html"&gt;SSDB代码阅读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/ssdb-benchmark.html"&gt;SSDB benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/fatcache-cr.html"&gt;fatcache 代码阅读&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="ssd"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id29"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 特性&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id30"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;成本&lt;/a&gt;&lt;/h3&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="11%" /&gt;
&lt;col width="18%" /&gt;
&lt;col width="56%" /&gt;
&lt;col width="15%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;--&lt;/th&gt;
&lt;th class="head"&gt;国外&lt;/th&gt;
&lt;th class="head"&gt;国内&lt;/th&gt;
&lt;th class="head"&gt;2T成本&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;ssd&lt;/td&gt;
&lt;td&gt;$0.6/GB&lt;/td&gt;
&lt;td&gt;京东价格(400元/128G=3.1元/GB)&lt;/td&gt;
&lt;td&gt;6000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hdd:&lt;/td&gt;
&lt;td&gt;$0.12/GB&lt;/td&gt;
&lt;td&gt;京东价格(400元/1T=0.4元/GB)&lt;/td&gt;
&lt;td&gt;800&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;实际上, 我们买服务器的时候, 价格会更便宜些, 不过还是这个数量级.&lt;/li&gt;
&lt;li&gt;考虑到一台1U服务器价格 在3-5w, 使用2T ssd带来的成本上升: 5200/30000 = 18%左右, 并不算太贵, 加之后续电费等消耗, 可以认为使用ssd带来的成本上升小于15%&lt;/li&gt;
&lt;li&gt;当然, 我们不能用ssd来存文件之类的大/冷的数据, 这是明显的浪费.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id31"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;接口&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;目前ssd主要2种接口:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;sata&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;pci-e, 性能更高.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;典型产品如:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Fusion-io ioScale Gen2  (w: 4w, r:5w)&lt;/li&gt;
&lt;li&gt;Fusion-io ioMemory (w: 32w, r:19w)&lt;/li&gt;
&lt;li&gt;华为ES3000 (w: 10w,  r:15w)&lt;/li&gt;
&lt;li&gt;MemblazeQ520 (w:7w, r:3w)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;sata 带宽6Gbps, pci-e 常见带宽 3.2G*8 = 24Gbps.&lt;/p&gt;
&lt;img alt="" src="/imgs/fusionio.png" style="width: 310px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id32"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;比较典型的ssd参数&lt;/a&gt;&lt;/h3&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="33%" /&gt;
&lt;col width="20%" /&gt;
&lt;col width="20%" /&gt;
&lt;col width="27%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Product&lt;/th&gt;
&lt;th class="head"&gt;Intel SSD 320&lt;/th&gt;
&lt;th class="head"&gt;Intel SSD 530&lt;/th&gt;
&lt;th class="head"&gt;ioMemory PX600&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Components&lt;/td&gt;
&lt;td&gt;MLC&lt;/td&gt;
&lt;td&gt;MLC&lt;/td&gt;
&lt;td&gt;MLC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Launch Date&lt;/td&gt;
&lt;td&gt;2011&lt;/td&gt;
&lt;td&gt;2013&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Sequential Read&lt;/td&gt;
&lt;td&gt;270 MB/s&lt;/td&gt;
&lt;td&gt;540 MB/s&lt;/td&gt;
&lt;td&gt;2700 MB/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Sequential Write&lt;/td&gt;
&lt;td&gt;220 MB/s&lt;/td&gt;
&lt;td&gt;490 MB/s&lt;/td&gt;
&lt;td&gt;1500MB/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Random Read (8GB Span)&lt;/td&gt;
&lt;td&gt;39,500 IOPS&lt;/td&gt;
&lt;td&gt;48,000 IOPS&lt;/td&gt;
&lt;td&gt;196,000 IOPS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Random Write (8GB Span)&lt;/td&gt;
&lt;td&gt;23,000 IOPS&lt;/td&gt;
&lt;td&gt;80,000 IOPS&lt;/td&gt;
&lt;td&gt;320,000 IOPS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Latency - Read&lt;/td&gt;
&lt;td&gt;75 us&lt;/td&gt;
&lt;td&gt;80 us&lt;/td&gt;
&lt;td&gt;92 us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Latency - Write&lt;/td&gt;
&lt;td&gt;90 us&lt;/td&gt;
&lt;td&gt;80 us&lt;/td&gt;
&lt;td&gt;15 us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;interface&lt;/td&gt;
&lt;td&gt;SATA 6.0 Gb/s&lt;/td&gt;
&lt;td&gt;SATA 6.0 Gb/s&lt;/td&gt;
&lt;td&gt;PCI-Express 2.0 x8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;数据来源:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Intel-SSD-320: &lt;a class="reference external" href="http://ark.intel.com/products/56569/Intel-SSD-320-Series-600GB-2_5in-SATA-3Gbs-25nm-ML"&gt;http://ark.intel.com/products/56569/Intel-SSD-320-Series-600GB-2_5in-SATA-3Gbs-25nm-ML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Intel-SSD-530: &lt;a class="reference external" href="http://ark.intel.com/products/75336/Intel-SSD-530-Series-480GB-2_5in-SATA-6Gbs-20nm-MLC"&gt;http://ark.intel.com/products/75336/Intel-SSD-530-Series-480GB-2_5in-SATA-6Gbs-20nm-MLC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fusion-io: &lt;a class="reference external" href="http://www.fusionio.com/data-sheets/iomemory-px600-atomic-series/"&gt;http://www.fusionio.com/data-sheets/iomemory-px600-atomic-series/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;这里选的 Fusion-io ioMemory系列, 写可以达到32w/s, 写延迟只有15us, 很明显写操作都是先写buffer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;对三块Intel-SSD-530 做raid0后, 用fio进行了测试, 数据和标称数据差不多:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;random-write: 5.5w/s&lt;/li&gt;
&lt;li&gt;random-read: 7.3w/s&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id33"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;随机读性能好&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;随机写性能较差&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;写放大: 写一个字节也会导致整个page的read-modify-write&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;应该尽量避免small-write&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;很多ssd会通过 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; 来做写merge. 从而减轻写放大,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这相当于把Log-Structure的一些算法在ssd控制器这一层实现了, 从而实现较高的随机写性能.&lt;/li&gt;
&lt;li&gt;但是即便有了 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt;, 也应该尽量避免small-write(因为需要多次操作映射关系表)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;ssd在大量写压力下, 性能可能恶化到8000iops.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;因为很多update, GC可能跟不上, 如果每次写操作需要做一次erase整个block, 就悲剧了.&lt;/li&gt;
&lt;li&gt;正常情况下, GC利用后台的时间, 可以完成erase工作.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;顺序读写和hdd在同一量级.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;寿命有限&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ssd可以通过下面这些方式调优:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;调整page/block的大小, 较小的擦除块可以得到较高的wqps.&lt;/li&gt;
&lt;li&gt;gc策略: 可以通过不同的算法优化, 这是ssd控制器FTL的核心技术.&lt;/li&gt;
&lt;li&gt;Flash Translation Layer (FTL) 上做 hybrid log-block mapping 优化随机写.&lt;/li&gt;
&lt;li&gt;使用 &lt;tt class="docutils literal"&gt;TRIM&lt;/tt&gt; 命令, 会有少量优化.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细参考: &lt;a class="reference external" href="/coding-for-ssd.html"&gt;coding-for-ssd笔记&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id34"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;现有系统调研&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;针对我们的需求, 调研了一些现有的系统, 主要分三类:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;基于redis的修改如redis-vm.&lt;/li&gt;
&lt;li&gt;单机引擎如Berkley DB, LevelDB.&lt;/li&gt;
&lt;li&gt;一些和我们需求接近的现有系统, 如ssdb, fatcache等.&lt;/li&gt;
&lt;li&gt;成熟产品, 如淘宝tair, aerospike 等.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="redis"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id35"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基于redis修改&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="redis-vm"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id36"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-vm&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://antirez.com/news/52"&gt;http://antirez.com/news/52&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://blog.nosqlfan.com/html/1047.html"&gt;http://blog.nosqlfan.com/html/1047.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;redis在2.2-2.4曾经做过vm功能, 来将内存扩展到磁盘, 但是不久就被废弃了, 原因主要是造成性能不稳定.&lt;/p&gt;
&lt;p&gt;存在的问题:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;slow restart: 重启太慢&lt;/li&gt;
&lt;li&gt;slow saving: 保存数据太慢&lt;/li&gt;
&lt;li&gt;slow replication: 上面两条导致 replication 太慢&lt;/li&gt;
&lt;li&gt;complex code: 代码过于复杂&lt;/li&gt;
&lt;li&gt;2.4 之后就已经从redis代码中移除了.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者的观点:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;have Redis do what it does best - very quickly serve data from RAM.&lt;/li&gt;
&lt;li&gt;估计当时的测试, 使用的磁盘都是hdd, 那当然性能糟糕, 如果换成ssd应该会好些.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-storage"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id37"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-storage&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;把leveldb嵌入到redis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;完成度较高, 新增了一些rl_开头的命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rl系列命令：(同时操作redis和leveldb系列命令)
=======string数据操作======
rl_get key            (从redis或leveldb取值, 优先顺序：redis &amp;gt; leveldb)
rl_getset key         (返回同rl_get, 当leveldb有值，redis无值时，会回写到redis)
...
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;读: 先从redis读取, 如果redis没有，则到leveldb读取。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;写: 先写到leveldb中，写成功了，再写到redis中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;问题:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;这个项目的目的是把redis的内存扩大2-5倍, 把redis作为leveldb的cache+store. 两份storage很诡异.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;作者设计的时候, 应该是考虑到兼容redis, 客户端尽量不需要改动, 冷key会自动淘汰,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;但是实际上提供了两套命令, 客户端需要根据情况, 指定只写redis/只写leveldb还是双写. 就很麻烦.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;没有expire支持, leveldb过大后, 怎么办?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;完全没有考虑到主从的设计.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/qiye/redis-storage"&gt;https://github.com/qiye/redis-storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.guangla.com/post/2014-03-17/40061277735"&gt;http://www.guangla.com/post/2014-03-17/40061277735&lt;/a&gt;  (shenzhe)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id38"&gt;4.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;基于redis的改进, 主要有这么几种:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;增加新命令&lt;/li&gt;
&lt;li&gt;在key被淘汰时写磁盘&lt;/li&gt;
&lt;li&gt;key一直在内存, 把某些value放磁盘(redis-vm的实现方案)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果基于redis来实现, 存在下面一些问题:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;主从同步很可能被破坏(现有全量同步机制需要重新改写)&lt;/li&gt;
&lt;li&gt;重启时加载数据的机制.&lt;/li&gt;
&lt;li&gt;不能支持全部命令, 容易造成混淆.&lt;/li&gt;
&lt;li&gt;不能被主流所接受&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果不基于redis代码来做:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;主从同步需要重做&lt;/li&gt;
&lt;li&gt;sentinel机制需要重做.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id39"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;单机存储引擎&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="leveldb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id40"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;LevelDB是BigTable的单机存储, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;LSM-Tree&lt;/span&gt;&lt;/tt&gt; 思想, 写操作都转化为顺序写.&lt;/p&gt;
&lt;p&gt;特点:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;KV引擎&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持SCAN(iteration)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Snappy压缩&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;随机读写能达到 10w/s 的性能&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这里性能是小数据量下, 还不刷盘的情况&lt;/li&gt;
&lt;li&gt;实际写能到10w, 读取决于存储介质.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Bloom Filter, 能在一定程度上优化读性能.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="rocksdb-facebook"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id41"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RocksDB(facebook)&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;基于LevelDB改进&lt;/li&gt;
&lt;li&gt;更好的利用多核等&lt;/li&gt;
&lt;li&gt;代码包比LevelDB复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="berkley-db"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id42"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Berkley DB&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;历史悠久的嵌入式数据库&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持事务, 细粒度锁.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;支持多种算法&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;B+树&lt;/li&gt;
&lt;li&gt;Hash&lt;/li&gt;
&lt;li&gt;Heap(更节约空间)&lt;/li&gt;
&lt;li&gt;Recno&lt;/li&gt;
&lt;li&gt;Queue(定长record)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;对一些老的UNIX数据库, 如dbm, ndbm接口兼容.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="http://docs.oracle.com/cd/E17076_02/html/programmer_reference/am_conf.html"&gt;http://docs.oracle.com/cd/E17076_02/html/programmer_reference/am_conf.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nessdb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id43"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;nessDB(国人开发)&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;支持事务 &lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;自己实现存储引擎, 不是基于LevelDB&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;3.0 提供 Buffered-Tree index (Toku的FT-Tree)&lt;/li&gt;
&lt;li&gt;作者是TokuDB的贡献者.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;2011-2014持续开发, 目测代码质量很高.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;本身是一个库.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;还提供一个服务端，支持Redis的 PING, SET, MSET, GET, MGET, DEL, EXISTS, INFO, SHUTDOWN 命令，&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;现在已经专注于实现引擎, 不提供server功能了.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;整个引擎基于LSM-Tree思想开发，对随机写非常友好。为提高随机读，nessDB使用了Level LRU和Bloom Filter策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;引擎是自己开发的, 还需要时间验证.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id44"&gt;4.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;较老的存储引擎都基于B+树或Hash实现, 写性能差.&lt;/li&gt;
&lt;li&gt;较新的存储引擎基于LSM-Tree, Log Structed Hash, FT-Tree之类新的数据结构, 针对写进行优化, 写性能能得到很大改善&lt;/li&gt;
&lt;li&gt;读操作主要取决于底层磁盘能提供的 &lt;strong&gt;随机读IOPS&lt;/strong&gt; , 通过Bloom Filter等能有一定的优化.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id45"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;备选项目&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id13"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id46"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssdb&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;ssdb 是一个基于leveldb的kv存储, 提供兼容redis的协议&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持String, Hash, Zset, Queue几种数据结构.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Expire和主从同步&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;ssd上写性能稳定在3.8wqps, 不会随着写数据增多而变差, 和hdd差不多,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;读性能稳定在5000qps, 不能充分发挥硬件性能, 这主要是由于读操作是单线程顺序执行.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;主要问题:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;读性能问题(多线程可达到15000)&lt;/li&gt;
&lt;li&gt;所有expire的key记录在内存&lt;/li&gt;
&lt;li&gt;兼容问题(expire/ttl/del都有问题, scan类设计上和redis不同)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细参考:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="/cr-ssdb.html"&gt;SSDB代码阅读笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/ssdb-benchmark.html"&gt;SSDB benchmark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id47"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fatcache&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Memcache on SSD&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Log-Structure Hash结构.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;不能持久化(元数据不落盘, 重启后数据丢失)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;性能不错, Initial performance results with fatcache 100K sets/sec, 40K gets/sec on a single SSD&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;读不命中时效率高(所有key记录在内存中)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;写裸盘. 需要root.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;主要问题:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;不持久化&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;key都放在内存, 如果10亿条的话, 每条key 32字节, 就需要32G. 此时存的数据(100字节/kv) 大约100G.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;所以这适合value较大的情况, 比如1K, 这样32G内存就能管理1T数据.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细参考: &lt;a class="reference external" href="/fatcache-cr.html"&gt;fatcache代码阅读笔记&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ardb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id48"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;ardb&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/yinqiwen/ardb"&gt;https://github.com/yinqiwen/ardb&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Full redis-protocol compatible&lt;/li&gt;
&lt;li&gt;Most redis commands supported, and a few new commands&lt;/li&gt;
&lt;li&gt;Replication compatible with Redis 2.6/2.8&lt;/li&gt;
&lt;li&gt;Auto failover support by redis-sentinel&lt;/li&gt;
&lt;li&gt;存储引擎支持  LevelDB/LMDB/RocksDB&lt;/li&gt;
&lt;li&gt;空间索引.&lt;/li&gt;
&lt;li&gt;代码量5w, 很难想象是一个人的作品. (HUST)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看上去很不错, c++实现.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ledisdb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id49"&gt;4.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;ledisdb&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;go 实现(金山 siddontang)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/siddontang/ledisdb"&gt;https://github.com/siddontang/ledisdb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;支持多种引擎: LevelDB, goleveldb, LMDB, RocksDB, BoltDB.&lt;/li&gt;
&lt;li&gt;支持expiration&lt;/li&gt;
&lt;li&gt;比GoRedis完善&lt;/li&gt;
&lt;li&gt;写的很细心&lt;/li&gt;
&lt;li&gt;lua&lt;/li&gt;
&lt;li&gt;redis 协议 +rest协议&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;设计:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://siddontang.com/2014/05/10/ledisdb-introduction/"&gt;http://siddontang.com/2014/05/10/ledisdb-introduction/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://siddontang.com/2014/05/30/ledisdb-design-1/"&gt;http://siddontang.com/2014/05/30/ledisdb-design-1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://siddontang.com/2014/06/14/ledisdb-design-2/"&gt;http://siddontang.com/2014/06/14/ledisdb-design-2/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id18"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id50"&gt;4.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;memcachedb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://gitorious.org/mdb/memcachedb/source/9f2e5415e4d9017889caf61c100a9b8652825319"&gt;https://gitorious.org/mdb/memcachedb/source/9f2e5415e4d9017889caf61c100a9b8652825319&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;redis-leveldb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不是基于redis的代码,&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/KDr2/redis-leveldb"&gt;https://github.com/KDr2/redis-leveldb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;redis-protocol compatible&lt;/li&gt;
&lt;li&gt;libev, cpp实现.&lt;/li&gt;
&lt;li&gt;2000行代码, 简单实现的玩具, 代码中各种printf直接输出到终端. 代码质量差&lt;/li&gt;
&lt;li&gt;没有expire, 主从同步,&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;seqdb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;提供sql接口的kv.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;GoRedis&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;go实现, (陌陌)&lt;/li&gt;
&lt;li&gt;存储引擎使用RocksDB, redis接口.&lt;/li&gt;
&lt;li&gt;不支持expire&lt;/li&gt;
&lt;li&gt;slaveof-proxy为两个redis建立自定义的主从同步，包含限速、断线重试等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;rdisk 是一个hackathon项目, 提供兼容redis的协议.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;libuv做服务&lt;/li&gt;
&lt;li&gt;rangel 解析&lt;/li&gt;
&lt;li&gt;tokyocabinet 作为存储引擎(作为.so嵌入)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/Moodstocks/redisk"&gt;https://github.com/Moodstocks/redisk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;是一个不错的开始&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;lycadb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;An experiment with InnoDB storage for a Redis-like key/value store&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;redis-land-go&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/xjdrew/redis-land-go"&gt;https://github.com/xjdrew/redis-land-go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;旁路监听，把redis数据存盘到leveldb&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id19"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id51"&gt;4.3.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;有很多尝试做兼容redis的磁盘存储的项目,&lt;/li&gt;
&lt;li&gt;在设计实现上都存在或多或少的问题.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id20"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id52"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;成熟分布式存储系统&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="tair"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id53"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;淘宝tair&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;淘宝开发的分布式 key/value 存储系统&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;模块&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;config-server (master+slave)&lt;/li&gt;
&lt;li&gt;data server (存储节点)&lt;/li&gt;
&lt;li&gt;客户端保存路由表, 有local cache&lt;/li&gt;
&lt;li&gt;一致性hash+数据迁移&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;存储引擎&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;mdb: 缓存, 支持kv,&lt;/li&gt;
&lt;li&gt;rdb: redis内存结构, kv, list, set, zset.&lt;/li&gt;
&lt;li&gt;ldb: 基于leveldb.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;需要专用的 client lib.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持多副本, 多版本.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;规模(2011):&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;共有20多个集群，400多台的服务器，其中300多台是cache的，每台提供22G的内存。其他的是持久化的Tair集群。&lt;/li&gt;
&lt;li&gt;存放了数百亿条记录，每秒百万级别的请求数。&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="http://code.taobao.org/p/tair/wiki/intro/"&gt;http://code.taobao.org/p/tair/wiki/intro/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="aerospike"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id54"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;aerospike&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;商业产品, 开源.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;三层:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;client 感知数据存在哪里&lt;/li&gt;
&lt;li&gt;Distribution Layer&lt;/li&gt;
&lt;li&gt;Data Storage Layer: 单机引擎.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;API形式: 不是简单的key/value, 每个key需要指定 (namespace, set, key), 应该是为了控制锁粒度.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Indexes are always stored in RAM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;数据类型: map, list, integer, string, blob.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可配 expire&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持lua.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Secondary indexes, 不是简单kv, 更像mongo&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Hot Analytics (distributed aggregations or indexed map-reduce)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/aerospike/aerospike-server"&gt;https://github.com/aerospike/aerospike-server&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="facebook-apollo"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id55"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook Apollo&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.infoq.com/news/2014/06/facebook-apollo"&gt;http://www.infoq.com/news/2014/06/facebook-apollo&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Paxos-like NoSQL database&lt;/li&gt;
&lt;li&gt;C++&lt;/li&gt;
&lt;li&gt;低延迟, 特别是Flash and in-memory&lt;/li&gt;
&lt;li&gt;不是简单kv, 支持数据结构:  maps, queues, trees&lt;/li&gt;
&lt;li&gt;分布式, 有shard概念, 每个shard内基于RocksDB.&lt;/li&gt;
&lt;li&gt;Apollo isn't currently being used in production at Facebook&lt;/li&gt;
&lt;li&gt;The company is also looking at using Apollo as a reliable queuing system&lt;/li&gt;
&lt;li&gt;是分布式的ssdb&lt;/li&gt;
&lt;li&gt;还没开源.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="facebook-mcdipper"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id56"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook-McDipper&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.facebook.com/notes/facebook-engineering/mcdipper-a-key-value-cache-for-flash-storage/10151347090423920"&gt;https://www.facebook.com/notes/facebook-engineering/mcdipper-a-key-value-cache-for-flash-storage/10151347090423920&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Compared with memory, flash provides up to 20 times the capacity per server and still supports tens of thousands of operations per second,&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;大约12年5月上线.&lt;/li&gt;
&lt;li&gt;cache替换策略: LRU或者FIFO&lt;/li&gt;
&lt;li&gt;you can enable bloom filters to avoid unnecessary reads&lt;/li&gt;
&lt;li&gt;主要用于图片服务器的缓存(cdn上) 后端是HayStack.&lt;/li&gt;
&lt;li&gt;We serve over 150 Gb/s from McDipper forward caches in our CDN.&lt;/li&gt;
&lt;li&gt;是一个cdn用的cache存储. memcache协议.&lt;/li&gt;
&lt;li&gt;不开源.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="ckv"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id57"&gt;4.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;#腾讯CKV海量分布式存储系统&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;(闭源, 这里参考一个ppt)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.csdn.net/article/2014-03-11/2818723"&gt;http://www.csdn.net/article/2014-03-11/2818723&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;高性能、低延时、持久化、分布式KV存储服务, 日请求数: 超过万亿次 (那得看多少套集群)&lt;/p&gt;
&lt;p&gt;与Memcached和Redis等开源NoSQL相比，CKV具有以下优点.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;内存+SSD, 99%命中率(取决于应用)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可以扩展到1PB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;单表 千万qps&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;单台Cache服务器千兆网络环境支持50万/秒的访问，万兆网络环境支持超过100万/秒的访问 &amp;lt;redis也10个实例, 也可以做到&amp;gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;双机热备，主备切换对业务透明. redis一样.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;扩容: 需要停写&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;扩容过程如下：Master将禁止shard2数据写访问命令发送给Access&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;规模: 近万台服务器&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;万台, 每天万亿请求, 那就是说1亿/台, 每台只相当于1000qps.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id21"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id58"&gt;4.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;这里的几个系统, 都是类似GFS的架构, config-server + data server + 智能client&lt;/li&gt;
&lt;li&gt;支持动态数据迁移和路由更新.&lt;/li&gt;
&lt;li&gt;它们都有各自的接口, 相对来说比较复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id22"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id59"&gt;4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它思路&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;HBase/Cassendra/MySQL on ssd?&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;可以利用现有hbase等系统良好的扩展性, 性能上也能有所保证&lt;/li&gt;
&lt;li&gt;接口不兼容.&lt;/li&gt;
&lt;li&gt;过于复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id23"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id60"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;为了避免随机写, 现在很多存储引擎都是Write-optimized的, 基于LSM的思想来开发, 比如:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;fatcache/Riak: Log-Structure Hash table&lt;/li&gt;
&lt;li&gt;RethinkDB: Log-Structure B-tree&lt;/li&gt;
&lt;li&gt;LevelDB, Cassendra, HBase: Log-Structure merge tree.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;LevelDB 平均每次读大约需要1.3-1.5次IO, Log-Structure Hash 只需要1次, 但是不能scan.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;ssdb/ardb/nessDB/ledisdb 都是国人做的, 很赞, 值得持续关注.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可以否决基于redis做的改造.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;基于LevelDB或者RocksDB封装提供redis协议比较简单, 难点主要是expire/replication/failover的实现.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id24"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id61"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;关于目前的很多系统&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;无论对redis改造或者是重新实现, 在数据结构/expire/主从同步上, 都延用了redis的做法, 比如:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;支持富数据结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;expire信息放在内存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;主从断掉全量同步.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;依然有rdb, 整个库占了1T磁盘, rdb出来也占1T =&amp;gt; 这些设计可能没考虑1T这个数据量级, 只考虑100G这个量级.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;比如ardb依然使用rdb做同步.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;甚至有的还会把磁盘操作计入aof, 再加上aof_rewrite,&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于数据规模变大(60G=&amp;gt;600G的级别) 这些设计就存在问题.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="2%" /&gt;
&lt;col width="11%" /&gt;
&lt;col width="4%" /&gt;
&lt;col width="16%" /&gt;
&lt;col width="17%" /&gt;
&lt;col width="24%" /&gt;
&lt;col width="25%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class="head"&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class="head"&gt;代码&lt;/th&gt;
&lt;th class="head"&gt;特点&lt;/th&gt;
&lt;th class="head"&gt;expire&lt;/th&gt;
&lt;th class="head"&gt;repl&lt;/th&gt;
&lt;th class="head"&gt;其它&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;redis-storage&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;redis+特定命令&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;专注于使内存成为磁盘的cache&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;ssdb&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;单独key存储&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;ardb&lt;/td&gt;
&lt;td&gt;5w&lt;/td&gt;
&lt;td&gt;cpp, 复杂, 地理索引&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;存储:&lt;/li&gt;
&lt;li&gt;同步: ?&lt;/li&gt;
&lt;li&gt;切换: ?&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td&gt;兼容性好, 沿用redis, 依然支持rdb&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;ledisdb(go)
金山&lt;/td&gt;
&lt;td&gt;2w&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;单独key存储, 定期elim&lt;/td&gt;
&lt;td&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;存储: 自定义binlog,fid+offset&lt;/li&gt;
&lt;li&gt;同步: 从拉,全量+增量&lt;/li&gt;
&lt;li&gt;切换: 全量同步&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;GoRedis&lt;/td&gt;
&lt;td&gt;2w&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-aof-replay</title><link href="/redis-aof-replay.html" rel="alternate"></link><updated>2014-02-27T09:44:50+08:00</updated><author><name>ning</name></author><id>tag:,2014-02-27:redis-aof-replay.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof" id="id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;简单的重放aof&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aofredis" id="id14"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到redis实例&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aoftwemproxy" id="id15"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到twemproxy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id16"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;各种命令的aof格式&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mset" id="id17"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;mset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#del-key" id="id18"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;del 删除多个key&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id19"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id20"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;aof解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof-replay" id="id21"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现aof-replay&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id22"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;功能和注意&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#tail-f" id="id23"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fdselect" id="id24"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试在fd上做select&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#poll" id="id25"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;用poll 呢?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id26"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f 怎么做的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id27"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#twemproxypipeline" id="id28"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;twemproxy对pipeline支持不好和性能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#safe" id="id29"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;safe模式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id30"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;测试几种方式的性能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#bench" id="id31"&gt;4.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞式简单bench&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#gprof" id="id32"&gt;4.3.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;gprof结果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#write-read" id="id33"&gt;4.3.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞改为直接write/read&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#pipeline" id="id34"&gt;4.3.2.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;改成pipeline:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id35"&gt;4.3.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;异步bench&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-benchmark" id="id36"&gt;4.3.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-benchmark 的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id37"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id38"&gt;4.3.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;具体实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#update-2014-03-13-10-13-19" id="id39"&gt;4.3.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;update &amp;#64;2014-03-13 10:13:19&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id40"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#clean" id="id41"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;clean脚本&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id42"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="aof"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;简单的重放aof&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="aofredis"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到redis实例&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;aof 文件有个优势:&lt;/p&gt;
&lt;p&gt;因为它的格式是和协议一致, 重放非常简单, 直接用如下命令即可:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cat data/appendonly.aof | nc localhost 22003
+OK
+OK
+OK
+OK
+OK
+OK
+OK
+OK
&lt;/pre&gt;
&lt;p&gt;或者用 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-cli&lt;/span&gt;&lt;/tt&gt; 提供的pipe功能:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat data/appendonly.aof | redis-cli --pipe  -h 127.0.0.5 -p 22003
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 115
&lt;/pre&gt;
&lt;p&gt;时间消耗, 在我的pc上 300M需要 120s, 速度大约2M/s, (6w条/s), 每天单进程可以重放156G(5亿条):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis-mgr$ ll /home/ning/Desktop/t/appendonly.aof
787171 -rw-r--r-- 1 ning ning 371M 2014-02-26 22:56 /home/ning/Desktop/t/appendonly.aof

ning&amp;#64;ning-laptop:~/idning-github/redis-mgr$ time cat /home/ning/Desktop/t/appendonly.aof | redis-cli --pipe -h 127.0.0.5 -p 22003
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 7339651

real    1m58.729s
user    0m8.700s
sys 0m1.780s
&lt;/pre&gt;
&lt;p&gt;实现: pipe功能就是简单的 把STDIN 的内容写到soket:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssize_t nread = read(STDIN_FILENO,obuf,sizeof(obuf));
ssize_t nwritten = write(fd,obuf+obuf_pos,obuf_len);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="aoftwemproxy"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到twemproxy&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;上面的方法不能通过twemproxy重放:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:/tmp/r/redis-22001$ cat data/appendonly.aof | redis-cli --pipe  -h 127.0.0.5 -p 24000
All data transferred. Waiting for the last reply...

No replies for 30 seconds: exiting.
errors: 1, replies: 0
&lt;/pre&gt;
&lt;p&gt;原因:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;proxy does not support mset/select ....&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了把它变成一个迁移工具, pipe工具性能已经满足要求, 功能上需要增加支持:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;兼容proxy(去掉select, 处理mset)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--filter&lt;/span&gt;&lt;/tt&gt; : key filter (这里需要解析命令)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--rewrite&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--tail&lt;/span&gt;&lt;/tt&gt; 支持 &lt;tt class="docutils literal"&gt;tail &lt;span class="pre"&gt;-f&lt;/span&gt;&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;最后发的echo命令要去掉&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ol class="arabic simple" start="6"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--check&lt;/span&gt;&lt;/tt&gt; check any command not supported&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id16"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;各种命令的aof格式&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#key-value
redis-cli -h 127.0.0.5 -p 22001 SET key0 v0
redis-cli -h 127.0.0.5 -p 22001 GETSET key0 v0
redis-cli -h 127.0.0.5 -p 22001 APPEND key0 v_a
redis-cli -h 127.0.0.5 -p 22001 STRLEN key0
#expire
redis-cli -h 127.0.0.5 -p 22001 EXPIRE key0 5
sleep 6
redis-cli -h 127.0.0.5 -p 22001 SETEX key0 5 v_a
sleep 6
#counter
redis-cli -h 127.0.0.5 -p 22001 INCR key1
#hash
redis-cli -h 127.0.0.5 -p 22001 HSET key3 h3 val3
#list
redis-cli -h 127.0.0.5 -p 22001 LPUSH key4 v4
redis-cli -h 127.0.0.5 -p 22001 LPOP key4
#set
redis-cli -h 127.0.0.5 -p 22001 SADD key5 v5
&lt;/pre&gt;
&lt;p&gt;对应关系如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
----------------------------------------------------------------------------------------------------------------

#key-value
redis-cli -h 127.0.0.5 -p 22001 SET key0 v0
                                                        *3
                                                        $3
                                                        SET
                                                        $4
                                                        key0
                                                        $2
                                                        v0

redis-cli -h 127.0.0.5 -p 22001 GETSET key0 v0
                                                        *3
                                                        $6
                                                        GETSET
                                                        $4
                                                        key0
                                                        $2
                                                        v0

redis-cli -h 127.0.0.5 -p 22001 APPEND key0 v_a
                                                        *3
                                                        $6
                                                        APPEND
                                                        $4
                                                        key0
                                                        $3
                                                        v_a

redis-cli -h 127.0.0.5 -p 22001 STRLEN key0 &amp;lt;nothing&amp;gt;

redis-cli -h 127.0.0.5 -p 22001 EXPIRE key0 5           (转变为PEXPIREAT)

                                                        *3
                                                        $9
                                                        PEXPIREAT
                                                        $4
                                                        key0
                                                        $13
                                                        1393467438683

sleep 6                                                 (5s后被删除)

                                                        *2
                                                        $3
                                                        DEL
                                                        $4
                                                        key0

redis-cli -h 127.0.0.5 -p 22001 SETEX key0 5 v_a        (SETEX转成两个命令)
                                                        *3
                                                        $3
                                                        SET
                                                        $4
                                                        key0
                                                        $3
                                                        v_a

                                                        *3
                                                        $9
                                                        PEXPIREAT
                                                        $4
                                                        key0
                                                        $13
                                                        1393467444711

sleep 6
                                                        *2
                                                        $3
                                                        DEL
                                                        $4
                                                        key0

redis-cli -h 127.0.0.5 -p 22001 INCR key1               &amp;lt;INCR记录的是变化, 不是结果&amp;gt;
                                                        *2
                                                        $4
                                                        INCR
                                                        $4
                                                        key1

redis-cli -h 127.0.0.5 -p 22001 HSET key3 h3 val3
                                                        *4
                                                        $4
                                                        HSET
                                                        $4
                                                        key3
                                                        $2
                                                        h3
                                                        $4
                                                        val3

redis-cli -h 127.0.0.5 -p 22001 LPUSH key4 v4
                                                        *3
                                                        $5
                                                        LPUSH
                                                        $4
                                                        key4
                                                        $2
                                                        v4

redis-cli -h 127.0.0.5 -p 22001 LPOP key4
                                                        *2
                                                        $4
                                                        LPOP
                                                        $4
                                                        key4

redis-cli -h 127.0.0.5 -p 22001 SADD key5 v5
                                                        *3
                                                        $4
                                                        SADD
                                                        $4
                                                        key5
                                                        $2
                                                        v5
&lt;/pre&gt;
&lt;div class="section" id="mset"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;mset&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
$redis-cli -h 127.0.0.5 -p 22000 mset k1 v1 k2 v2

                                                            mset
                                                            $2
                                                            k1
                                                            $2
                                                            v1
                                                            $2
                                                            k2
                                                            $2
                                                            v2
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="del-key"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;del 删除多个key&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;不是记录3个del命令, 而是记录一个命令&lt;/li&gt;
&lt;li&gt;只要del生效(能删掉任何一条记录), 就会记录对命令中所有key的删除.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
$ redis-cli -h 127.0.0.5 -p 22001 set key1 3
OK
                                                                        *3
                                                                        $3
                                                                        set
                                                                        $4
                                                                        key1
                                                                        $1
                                                                        3

$ redis-cli -h 127.0.0.5 -p 22001 set key2 3
OK

                                                                        *3
                                                                        $3
                                                                        set
                                                                        $4
                                                                        key2
                                                                        $1
                                                                        3

#注意这里删除3个key, 只有2个key存在的情况下, 记录的aof是在一个del命令中删除3个key
$ redis-cli -h 127.0.0.5 -p 22001 del key1 key2 key3
(integer) 2
                                                                        *4
                                                                        $3
                                                                        del
                                                                        $4
                                                                        key1
                                                                        $4
                                                                        key2
                                                                        $4
                                                                        key3

$ redis-cli -h 127.0.0.5 -p 22001 del key1 key2 key3
(integer) 0
$ redis-cli -h 127.0.0.5 -p 22001 del key1 key2 key3
(integer) 0
                                                                        这里没有对应的aof
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;aof 中记录的命令可能是大写/小写. 用户怎么用就是怎么记录.&lt;/li&gt;
&lt;li&gt;mset, del比较记录的也是原始操作.&lt;/li&gt;
&lt;li&gt;incr等, 也是记录操作, 而不是记录结果.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id20"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;aof解析&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;aof解析非常简单, 从 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-check-aof&lt;/span&gt;&lt;/tt&gt; 中就可以看出来:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
off_t process(FILE *fp) {
    long argc;
    off_t pos = 0;
    int i, multi = 0;
    char *str;

    while(1) {
        if (!multi) pos = ftello(fp);
        if (!readArgc(fp, &amp;amp;argc)) break;

        for (i = 0; i &amp;lt; argc; i++) {
            readString(fp,&amp;amp;str);
        }
    }
}
&lt;/pre&gt;
&lt;p&gt;redis中解析, load aof 是这个函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* Replay the append log file. On error REDIS_OK is returned. On non fatal
 * error (the append only file is zero-length) REDIS_ERR is returned. On
 * fatal error an error Message is logged and the program exists. */
int loadAppendOnlyFile(char *filename) {
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="aof-replay"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id21"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现aof-replay&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;功能和注意&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;points:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;remove all &lt;tt class="docutils literal"&gt;select&lt;/tt&gt; / &lt;tt class="docutils literal"&gt;multi&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;change &lt;tt class="docutils literal"&gt;MSET/MSETNX/DEL&lt;/tt&gt; to many &lt;tt class="docutils literal"&gt;SET/SETNX/DEL&lt;/tt&gt; cmd;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--filter&lt;/span&gt;&lt;/tt&gt; : filter key by prefix&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--orig&lt;/span&gt;&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--rewrite&lt;/span&gt;&lt;/tt&gt;, rewrite key.&lt;/li&gt;
&lt;li&gt;follow aof modification like &lt;tt class="docutils literal"&gt;tail &lt;span class="pre"&gt;-f&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--check&lt;/span&gt;&lt;/tt&gt; check any command not supported&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;问题:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;如果解析到multi(后面可能有一个回滚, 不能简单丢弃multi)&lt;/li&gt;
&lt;li&gt;测试可以通过回回放一个现有库, 然后对比&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="tail-f"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id23"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这里要实现tail -f 的功能, 需要一个readline 的功能(因为fgets在EOF的时候直接返回, 不能用fgets)&lt;/p&gt;
&lt;p&gt;对 &lt;tt class="docutils literal"&gt;read&lt;/tt&gt; 做了几个测试, 发现:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;如果fd是文件, 文件在变化的情况下, 用read() 系统调用, 如果到达文件尾, 会直接返回, 而不会等待.&lt;/li&gt;
&lt;li&gt;如果fd是网络, read() 如果没有可读, 就会阻塞.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="fdselect"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id24"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试在fd上做select&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;tail -f 有这样的逻辑, 但是我试了, select 就算在文件尾也总是返回可读. 查了一下:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://stackoverflow.com/questions/11901884/how-can-select-wait-on-regular-file-descriptors-non-sockets"&gt;http://stackoverflow.com/questions/11901884/how-can-select-wait-on-regular-file-descriptors-non-sockets&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Disk files are always ready to read (but the read might return 0 bytes if you're already at the end of the file), so you can't use select() on a disk file to find out when new data is added to the file.
&lt;/pre&gt;
&lt;p&gt;POSIX says:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
File descriptors associated with regular files shall always select true for ready to read, ready to write, and error conditions.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="poll"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id25"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;用poll 呢?&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;这里有一个详细的测试: &lt;a class="reference external" href="http://www.greenend.org.uk/rjk/tech/poll.html"&gt;http://www.greenend.org.uk/rjk/tech/poll.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;依然显示 对于regular file, 在到达EOF时, poll总是返回POLLIN.&lt;/p&gt;
&lt;p&gt;这就是说, select/poll 只对 pipes/sockets 这样会发生阻塞读写的介质有效.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id26"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f 怎么做的&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;看源码:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;coreutils-8.12/src/tail.c 用了 &lt;tt class="docutils literal"&gt;inotify&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;coreutils-8.12/src/tail.c 在用pipe方式 的时候(作为另一个程序的输出的下游), 用了 &lt;tt class="docutils literal"&gt;select&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;比较老的版本(7.4) 用sleep&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用sleep的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning/langtest/c$ tail --version
tail (GNU coreutils) 7.4

ning&amp;#64;ning-laptop:~/idning/langtest/c$ strace tail -f common.h
execve(&amp;quot;/usr/bin/tail&amp;quot;, [&amp;quot;tail&amp;quot;, &amp;quot;-f&amp;quot;, &amp;quot;common.h&amp;quot;], [/* 69 vars */]) = 0
brk(0)                                  = 0xd1a000
...
nanosleep({1, 0}, NULL)                 = 0
fstat(3, {st_mode=S_IFREG|0644, st_size=635, ...}) = 0
nanosleep({1, 0}, NULL)                 = 0
fstat(3, {st_mode=S_IFREG|0644, st_size=635, ...}) = 0
nanosleep({1, 0}, NULL)                 = 0
fstat(3, {st_mode=S_IFREG|0644, st_size=635, ...}) = 0
&lt;/pre&gt;
&lt;p&gt;用sleep的代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* Tail NFILES files forever, or until killed.
   The pertinent information for each file is stored in an entry of F.
   Loop over each of them, doing an fstat to see if they have changed size,
   and an occasional open/fstat to see if any dev/ino pair has changed.
   If none of them have changed size in one iteration, sleep for a
   while and try again.  Continue until the user interrupts us.  */


static void tail_forever (struct File_spec *f, int nfiles, double sleep_interval)
{

    ...

    if (fstat (fd, &amp;amp;stats) != 0)
    {
      f[i].fd = -1;
      f[i].errnum = errno;
      error (0, errno, &amp;quot;%s&amp;quot;, name);
      continue;
    }

      if (f[i].mode == stats.st_mode
      &amp;amp;&amp;amp; (! S_ISREG (stats.st_mode) || f[i].size == stats.st_size)
      &amp;amp;&amp;amp; timespec_cmp (f[i].mtime, get_stat_mtime (&amp;amp;stats)) == 0)
    {
        //not change
    }
    change
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id27"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;通过sleep实现tail -f&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="twemproxypipeline"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id28"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;twemproxy对pipeline支持不好和性能&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-cli&lt;/span&gt; &lt;span class="pre"&gt;--pipe&lt;/span&gt;&lt;/tt&gt; 是使用pipeline 模式的, 只要server端可写, 就会不停的写,&lt;/p&gt;
&lt;p&gt;但是twemproxy总是尽最大能力的读, 把消息放在内存中, 这样消息都会堆在twemproxy, 并且超时.&lt;/p&gt;
&lt;p&gt;这个问题的讨论见: &lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/203"&gt;https://github.com/twitter/twemproxy/issues/203&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;解决方法:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;safe模式, 一条一条写，写成功再写下一条.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;batch模式, 为了保证尽量写成功, 此时需要&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;加大twemproxy 的timeout.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;有某种block机制, 确保不会有大量请求堆在twemproxy.&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first last"&gt;比如客户端计数, 发出的req - 收到的resp &amp;lt; 1024&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="safe"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id29"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;safe模式&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;用redisCommandArgv:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
while(1){
    msg = readMsg(fp);
    reply = redisCommandArgv(context, msg-&amp;gt;argc, (const char **)msg-&amp;gt;argv, msg-&amp;gt;argvlen);
    freeReplyObject(reply);
    freeMsg(msg);
}
&lt;/pre&gt;
&lt;p&gt;发现性能不好: 后端为twemproxy时大约7000/s, 后端为redis大约10000/s.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id30"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;测试几种方式的性能&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="bench"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id31"&gt;4.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞式简单bench&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;直接调用redisCommand 性能如何:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat bench1.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;

#include &amp;quot;hiredis.h&amp;quot;

int main(void) {
    unsigned int i;
    redisContext *c;
    redisReply *reply;

    struct timeval timeout = { 1, 500000 }; // 1.5 seconds
    c = redisConnectWithTimeout((char*)&amp;quot;127.0.0.5&amp;quot;, 22000, timeout);
    if (c-&amp;gt;err) {
        printf(&amp;quot;Connection error: %s\n&amp;quot;, c-&amp;gt;errstr);
        exit(1);
    }
    for(i=0; i&amp;lt;100*1000; i++){
        reply = redisCommand(c,&amp;quot;SET %s %s&amp;quot;, &amp;quot;foo&amp;quot;, &amp;quot;hello world&amp;quot;);
        freeReplyObject(reply);
    }
    return 0;
}
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cc bench1.c -I ./ -L ./ -l hiredis   (或cc bench1.c libhiredis.a)
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ time ./a.out

real        0m6.945s
user        0m0.710s
sys 0m1.710s
&lt;/pre&gt;
&lt;p&gt;100*1000/6.9 = 1.4w/s&lt;/p&gt;
&lt;div class="section" id="gprof"&gt;
&lt;h6&gt;&lt;a class="toc-backref" href="#id32"&gt;4.3.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;gprof结果&lt;/a&gt;&lt;/h6&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cc bench1.c libhiredis.a -pg
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ ./a.out
$ gprof  ./a.out ./gmon.out  | vim -

Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total
 time   seconds   seconds    calls  Ts/call  Ts/call  name
 22.23      0.04     0.04                             redisReaderGetReply
 16.67      0.07     0.03                             redisvFormatCommand
 11.12      0.09     0.02                             redisGetReply
 11.12      0.11     0.02                             sdscatlen
  5.56      0.12     0.01                             main
  5.56      0.13     0.01                             redisBufferRead
  5.56      0.14     0.01                             redisBufferWrite
  5.56      0.15     0.01                             sdsIncrLen
  5.56      0.16     0.01                             sdsempty
  5.56      0.17     0.01                             sdsnewlen
  2.78      0.18     0.01                             sdsMakeRoomFor
  2.78      0.18     0.01                             sdsRemoveFreeSpace
&lt;/pre&gt;
&lt;p&gt;总共7s, 为啥self seconds 加起来不是7s&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="write-read"&gt;
&lt;h6&gt;&lt;a class="toc-backref" href="#id33"&gt;4.3.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞改为直接write/read&lt;/a&gt;&lt;/h6&gt;
&lt;p&gt;依然很慢:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cat bench3.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;

#include &amp;quot;hiredis.h&amp;quot;

int main(void) {
    unsigned int i;
    redisContext *c;
    redisReply *reply;
    int ret;

    struct timeval timeout = { 1, 500000 }; // 1.5 seconds
    c = redisConnectWithTimeout((char*)&amp;quot;127.0.0.5&amp;quot;, 22000, timeout);
    if (c-&amp;gt;err) {
        printf(&amp;quot;Connection error: %s\n&amp;quot;, c-&amp;gt;errstr);
        exit(1);
    }

    char *cmd = &amp;quot;*3\r\n$3\r\nSET\r\n$3\r\nfoo\r\n$9\r\nbarbarbar\r\n&amp;quot;;
    int len = strlen(cmd);

    char buf[1024];
    for(i=0; i&amp;lt;100*1000; i++){
        ret = write(c-&amp;gt;fd, cmd, len);
        assert(len == ret);

        /*fprintf(stderr, &amp;quot;read\n&amp;quot;);*/
        ret = read(c-&amp;gt;fd, buf, 5);
        assert(5 == ret);

        buf[5] = 0;
        /*fprintf(stderr, &amp;quot;%d: %s\n&amp;quot;, i, buf);*/
        /*assert(0 == strcmp(buf, &amp;quot;+OK\r\n&amp;quot;));*/
    }
    return 0;
}
&lt;/pre&gt;
&lt;p&gt;还是要5s. (2w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pipeline"&gt;
&lt;h6&gt;&lt;a class="toc-backref" href="#id34"&gt;4.3.2.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;改成pipeline:&lt;/a&gt;&lt;/h6&gt;
&lt;pre class="literal-block"&gt;
for(i=0; i&amp;lt;100*1000; i++){
    ret = twrite(c-&amp;gt;fd, cmd, len);
    assert(len == ret);

}
for(i=0; i&amp;lt;100*1000; i++){
    ret = tread(c-&amp;gt;fd, buf, 5);
    assert(5 == ret);
}
&lt;/pre&gt;
&lt;p&gt;只需要0.4s&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id35"&gt;4.3.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;异步bench&lt;/a&gt;&lt;/h5&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cat bench2.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;quot;hiredis.h&amp;quot;
#include &amp;quot;async.h&amp;quot;
#include &amp;quot;adapters/ae.h&amp;quot;

/* Put event loop in the global scope, so it can be explicitly stopped */
static aeEventLoop *loop;

void setCallback(redisAsyncContext *c, void *r, void *privdata) {
    redisReply *reply = r;
    if (reply == NULL) return;
    int * pi = (int*) privdata;

    printf(&amp;quot;argv[%d]: %s\n&amp;quot;, *pi, reply-&amp;gt;str);

    (*pi)++;
    if (*pi &amp;gt; 100*1000)
        exit(0);

    redisAsyncCommand(c, setCallback, (char*)pi, &amp;quot;SET thekey %s&amp;quot;, &amp;quot;xxxxxxxxxxxxxx&amp;quot;);
}

void connectCallback(const redisAsyncContext *c, int status) {
    if (status != REDIS_OK) {
        printf(&amp;quot;Error: %s\n&amp;quot;, c-&amp;gt;errstr);
        return;
    }
    printf(&amp;quot;Connected...\n&amp;quot;);
}
void disconnectCallback(const redisAsyncContext *c, int status) {
    if (status != REDIS_OK) {
        printf(&amp;quot;Error: %s\n&amp;quot;, c-&amp;gt;errstr);
        return;
    }
    printf(&amp;quot;Disconnected...\n&amp;quot;);
}

int main() {
    signal(SIGPIPE, SIG_IGN);

    redisAsyncContext *c = redisAsyncConnect(&amp;quot;127.0.0.1&amp;quot;, 6379);
    if (c-&amp;gt;err) {
        /* Let *c leak for now... */
        printf(&amp;quot;Error: %s\n&amp;quot;, c-&amp;gt;errstr);
        return 1;
    }

    loop = aeCreateEventLoop(1000);
    redisAeAttach(loop, c);
    redisAsyncSetConnectCallback(c,connectCallback);
    redisAsyncSetDisconnectCallback(c,disconnectCallback);

    int i = 0;
    redisAsyncCommand(c, setCallback, (char*)&amp;amp;i, &amp;quot;SET thekey %s&amp;quot;, &amp;quot;xxxxxxxxxxxxxx&amp;quot;);
    aeMain(loop);
    return 0;
}
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cc -I../../src ../../src/ae.o ../../src/zmalloc.o bench2.c libhiredis.a ../jemalloc/lib/libjemalloc.a -lpthread
&lt;/pre&gt;
&lt;p&gt;still 6s.(差不多还是2w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-benchmark"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id36"&gt;4.3.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-benchmark 的实现&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;异步.&lt;/p&gt;
&lt;p&gt;创建一些client, 每个client注册如下事件:&lt;/p&gt;
&lt;blockquote&gt;
aeCreateFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_WRITABLE,writeHandler,c);&lt;/blockquote&gt;
&lt;p&gt;writeHandler:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void writeHandler(aeEventLoop *el, int fd, void *privdata, int mask) {
    client c = privdata;
    REDIS_NOTUSED(el);
    REDIS_NOTUSED(fd);
    REDIS_NOTUSED(mask);

    /* Initialize request when nothing was written. */
    if (c-&amp;gt;written == 0) {
        /* Enforce upper bound to number of requests. */
        if (config.requests_issued++ &amp;gt;= config.requests) {
            freeClient(c);
            return;
        }

        /* Really initialize: randomize keys and set start time. */
        if (config.randomkeys) randomizeClientKey(c);
        c-&amp;gt;start = ustime();
        c-&amp;gt;latency = -1;
    }

    if (sdslen(c-&amp;gt;obuf) &amp;gt; c-&amp;gt;written) {
        void *ptr = c-&amp;gt;obuf+c-&amp;gt;written;
        int nwritten = write(c-&amp;gt;context-&amp;gt;fd,ptr,sdslen(c-&amp;gt;obuf)-c-&amp;gt;written);
        if (nwritten == -1) {
            if (errno != EPIPE)
                fprintf(stderr, &amp;quot;Writing to socket: %s\n&amp;quot;, strerror(errno));
            freeClient(c);
            return;
        }
        c-&amp;gt;written += nwritten;
        if (sdslen(c-&amp;gt;obuf) == c-&amp;gt;written) {
            aeDeleteFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_WRITABLE);
            aeCreateFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_READABLE,readHandler,c);
        }
    }
}
&lt;/pre&gt;
&lt;p&gt;每写成功一个消息, 去掉AE_WRITABLE, 加上AE_READABLE:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void writeHandler(aeEventLoop *el, int fd, void *privdata, int mask) {
    if (sdslen(c-&amp;gt;obuf) == c-&amp;gt;written) {
        aeDeleteFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_WRITABLE);
        aeCreateFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_READABLE,readHandler,c);
    }
}
&lt;/pre&gt;
&lt;p&gt;在read完之后, 重新用激活可写事件:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if (c-&amp;gt;pending == 0) {
    clientDone(c); //里面会加AE_WRITABLE
    break;
}
&lt;/pre&gt;
&lt;p&gt;redis-benchmark 默认是不用pipeline 的. 写一个, 读一个, 但是是用异步api.&lt;/p&gt;
&lt;p&gt;如果pipeline模式benchmark, 它在准备数据的时候就一次性把多个命令写道obuf里面去:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
for (j = 0; j &amp;lt; config.pipeline; j++)
    c-&amp;gt;obuf = sdscatlen(c-&amp;gt;obuf,cmd,len);
c-&amp;gt;pending = config.pipeline;
&lt;/pre&gt;
&lt;p&gt;发现用redis-benchmark性能能达到5w左右, 后来发现是因为redis-benchmark默认-c 50, 就是50个client并发, 如果用-c 1的话, 性能还是比较差:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/src$ time redis-benchmark -h 127.0.0.5 -p 22000 -c 1 -t set -n 100000
====== SET ======
  100000 requests completed in 8.64 seconds
  1 parallel clients
  3 bytes payload
  keep alive: 1

99.99% &amp;lt;= 1 milliseconds
100.00% &amp;lt;= 2 milliseconds
100.00% &amp;lt;= 3 milliseconds
100.00% &amp;lt;= 7 milliseconds
11579.44 requests per second



real        0m8.651s
user        0m0.570s
sys 0m2.390s
&lt;/pre&gt;
&lt;p&gt;大约8s, (1.2w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id37"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;为什么这里的非阻塞调用benchmark性能很差?&lt;/li&gt;
&lt;li&gt;问什么redis-benmark的写法, 性能好?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;三种方式:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;阻塞: 慢&lt;/li&gt;
&lt;li&gt;自己的非阻塞写法: 慢&lt;/li&gt;
&lt;li&gt;redis-benchmark写法: 慢&lt;/li&gt;
&lt;li&gt;redis-cli的pipe写法: 快&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;TODO: &lt;strong&gt;这里的原因, 还是不清楚..&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;难道是, 如果read系统调用时, 数据准备好, 则很快, 没准备好, 则很慢.&lt;/p&gt;
&lt;p&gt;同样都是发送, 等待响应, 解析响应.&lt;/p&gt;
&lt;p&gt;貌似只能理解为用阻塞方式等待响应很耗时.&lt;/p&gt;
&lt;p&gt;这个问题, 可以把服务器抽象为一个简单的echo-server, 此时客户端一问一答的形式, 最大能达到多大的qps.&lt;/p&gt;
&lt;p&gt;用strace发现一个共同点: 2,3都是用epoll异步, 一次epoll_wait 做一次write, 在epoll_wait, 再一次read:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
epoll_ctl(3, EPOLL_CTL_MOD, 4, {EPOLLIN, {u32=4, u64=4}}) = 0
epoll_ctl(3, EPOLL_CTL_DEL, 4, {0, {u32=4, u64=4}}) = 0
epoll_ctl(3, EPOLL_CTL_ADD, 4, {EPOLLOUT, {u32=4, u64=4}}) = 0
epoll_wait(3, {{EPOLLOUT, {u32=4, u64=4}}}, 10240, 240) = 1
write(4, &amp;quot;*3\r\n$3\r\nSET\r\n$16\r\nkey:__rand_int&amp;quot;..., 45) = 45
epoll_ctl(3, EPOLL_CTL_DEL, 4, {0, {u32=4, u64=4}}) = 0
epoll_ctl(3, EPOLL_CTL_ADD, 4, {EPOLLIN, {u32=4, u64=4}}) = 0
epoll_wait(3, {{EPOLLIN, {u32=4, u64=4}}}, 10240, 239) = 1
read(4, &amp;quot;+OK\r\n&amp;quot;, 16384)               = 5
&lt;/pre&gt;
&lt;p&gt;4是用pool, 而且一个pool就能做一次read, 一次write:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/src$ strace ./redis-cli  -h 127.0.0.5 -p 22000 --replay ~/Desktop/t/appendonly.aof
poll([{fd=3, events=POLLIN|POLLOUT}], 1, 1000) = 1 ([{fd=3, revents=POLLIN|POLLOUT}])
read(3, &amp;quot;+OK\r\n&amp;quot;, 16384)               = 5
read(3, 0x7fff7d548f10, 16384)          = -1 EAGAIN (Resource temporarily unavailable)
write(3, &amp;quot;*3\r\n$3\r\nSET\r\n$13\r\nkkk-100000756\r&amp;quot;..., 53) = 53
poll([{fd=3, events=POLLIN|POLLOUT}], 1, 1000) = 1 ([{fd=3, revents=POLLIN|POLLOUT}])
read(3, &amp;quot;+OK\r\n&amp;quot;, 16384)               = 5
read(3, 0x7fff7d548f10, 16384)          = -1 EAGAIN (Resource temporarily unavailable)
write(3, &amp;quot;*3\r\n$3\r\nSET\r\n$13\r\nkkk-100000757\r&amp;quot;..., 53) = 53
&lt;/pre&gt;
&lt;div class="section" id="id10"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id38"&gt;4.3.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;具体实现&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;当前我的写法相当于长度为1的pipe, 本质和 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-cli&lt;/span&gt;&lt;/tt&gt; 写法一样. 性能挺好(5w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="update-2014-03-13-10-13-19"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id39"&gt;4.3.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;update &amp;#64;2014-03-13 10:13:19&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;后来发现, 我当时写的--replay 有bug, 相当于用了长度为 100左右的pipe. 所以表现的性能很好. 代码是在这个commit:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/idning/redis/commit/b122ab0c749f2a93bb514ae07ba73739690ab46e"&gt;https://github.com/idning/redis/commit/b122ab0c749f2a93bb514ae07ba73739690ab46e&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;修改了这个bug后:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/idning/redis/commit/b956e2cf92feb510f7d1a2f158a8eafe907d9ae1"&gt;https://github.com/idning/redis/commit/b956e2cf92feb510f7d1a2f158a8eafe907d9ae1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发现如果定义pipe长度是1, 性能就在1w左右. 改为10, 就在5w左右(laptop测试)&lt;/p&gt;
&lt;p&gt;如果用线上机器:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pipesize    1    10  100  1000
loclhost:   1w   4w  5w   5w
online:     0.3  1w  10w  12w
&lt;/pre&gt;
&lt;p&gt;线上pipeline为1时, 只有0.3, 原因是线上网络RTT大, (这么看每个请求3ms), 用的是压力较大的线上机器.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id40"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="clean"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id41"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;clean脚本&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;需要一个脚本, 如果重放到一半出错, 需要清除所有前缀为xxx的key&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id42"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;code:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
https://github.com/idning/redis/blob/replay/src/redis-cli.c
https://github.com/cen-li/redis/blob/redis-2.8.3_replay-aof/src/redis-replay-aof.c
&lt;/pre&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-mgr 中redis实例的迁移</title><link href="/redis-instance-migrate.html" rel="alternate"></link><updated>2014-02-11T10:29:10+08:00</updated><author><name>ning</name></author><id>tag:,2014-02-11:redis-instance-migrate.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;两种方法:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-mgr" id="id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr中如何操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;实现细节:主从同步的步骤&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;两种扩容思路:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;一个是 redis-mgr 中redis实例的迁移, 迁到一个内存大的机器&lt;/li&gt;
&lt;li&gt;另外一个是新搭建集群, 把数据迁移过去.&lt;/li&gt;
&lt;li&gt;和2类似, 把旧集群中某个业务(一定前缀)的数据迁移到新集群.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里说的是思路1&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;两种方法:&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;冷迁移&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;步骤&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;拷贝rdb/aof文件,&lt;/li&gt;
&lt;li&gt;搭建新的master-slave&lt;/li&gt;
&lt;li&gt;更新twemproxy配置 重启&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;问题&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;丢失部分到老master/slave的写&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;热迁移&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;场景:&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;集群维护(如部分机器下线)&lt;/li&gt;
&lt;li&gt;集群扩容, 如2*32 实例原来部署在16 机器上,  可以扩容到 32/64 机器上.&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;步骤, 假设老的master/slave 为m,s, 新的为n1, n2&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;搭建n1, n1 SLAVEOF m, 等待同步完成.&lt;/li&gt;
&lt;li&gt;kill s&lt;/li&gt;
&lt;li&gt;kill m, n1成为master.&lt;/li&gt;
&lt;li&gt;搭建n2, n2 SLAVEOF n1&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果服务down了, 起不来(主从都down了起不来的可能性较小), 只能使用冷迁移&lt;/p&gt;
&lt;p&gt;下面是热迁移的方法.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-mgr"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr中如何操作&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;config中写操作步骤:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cluster0 = {
    'migrate' : [
        'host1:port' =&amp;gt; 'host2:port'
    ],
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;直接修改 cluster 中redis 这一节的配置.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;通过命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./bin/deploy.py cluster0 migrate xxxx  xxx
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最后选择了3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;实现细节:主从同步的步骤&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;通过观察 现在 集群中杀掉从库重启后, 通过redis 的INFO命令观察主/从的表现:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;slave 启动, load 本地的aof文件, load完成后:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
used_memory_peak_human CHANGE FROM 2.32G to 2.33G
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;收到sentinel 发来的SLAVEOF命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
master_host CHANGE FROM  to 127.0.0.5
master_port CHANGE FROM  to 22000
master_link_status CHANGE FROM  to down
slave_repl_offset CHANGE FROM  to -1
&lt;/pre&gt;
&lt;p&gt;此时 master 这边的状态变化:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slave0 CHANGE FROM  to ip=127.0.0.5,port=23000,state=wait_bgsave,offset=0,lag=0
&lt;/pre&gt;
&lt;p&gt;master 开始做一次bgsave.  slave 等待bgsave(wait_bgsave)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;master bgsave 完成, 开始传送数据:&lt;/p&gt;
&lt;p&gt;master:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slave0 CHANGE FROM ip=127.0.0.5,port=23000,state=wait_bgsave,offset=0,lag=0 to ip=127.0.0.5,port=23000,state=send_bulk,offset=0,lag=0
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;rdb 传送完成后, slave load 获得的数据:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
master_sync_left_bytes CHANGE FROM 47165401 to 0
mem_fragmentation_ratio CHANGE FROM 1.01 to 1.21
used_memory_human CHANGE FROM 2.33G to 18.79M


开始load 新的db:
used_memory_human CHANGE FROM 18.79M to 116.79M
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;load完成:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
aof_rewrite_in_progress CHANGE FROM 0 to 1
master_link_status CHANGE FROM down to up
slave_repl_offset CHANGE FROM -1 to 995178543
used_memory_human CHANGE FROM 2.29G to 2.33G
loading CHANGE FROM 1 to 0
&lt;/pre&gt;
&lt;p&gt;此时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slave0 CHANGE FROM ip=127.0.0.5,port=23000,state=send_bulk,offset=0,lag=0 to ip=127.0.0.5,port=23000,state=online,offset=0,lag=1
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;基准数据同步完成的标志&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;master 上看对应slave的 &lt;tt class="docutils literal"&gt;status=online&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;slave 上看 &lt;tt class="docutils literal"&gt;master_link_status = up&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;实时同步跟上的标志&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;从master 上看 &lt;tt class="docutils literal"&gt;lag=0&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;master 的 &lt;tt class="docutils literal"&gt;master_repl_offset&lt;/tt&gt; : 和slave 的 &lt;tt class="docutils literal"&gt;slave_repl_offset&lt;/tt&gt;  一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;进度信息获取:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;slave 的内存/master 的内存&lt;/li&gt;
&lt;li&gt;db0:keys 在master/slave 上对比.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最终实现了下面命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
migrate src dst : migrate a redis instance to another machine
&lt;/pre&gt;
&lt;p&gt;步骤:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pre_check,
force_src_be_slave,
deploy_dst,
add_dst_as_slave,
cleanup,
sentinel_reset,
update_config,
&lt;/pre&gt;
&lt;p&gt;使用方法:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/deploy.py cluster0 migrate cluster0-22000:127.0.0.5:23000:/tmp/r/redis-23000 cluster0-22000:127.0.0.5:50015:/tmp/r/redis-50015
...
2014-02-27 19:21:58,667 [MainThread] [INFO] deploy [redis:127.0.0.5:50015]
2014-02-27 19:21:59,774 [MainThread] [INFO] [redis:127.0.0.5:50015] start ok in 0.19 seconds
2014-02-27 19:21:59,775 [MainThread] [NOTICE] add_dst_as_slave
2014-02-27 19:21:59,790 [MainThread] [INFO] [redis:127.0.0.5:50015] /home/ning/idning-github/redis/src/redis-cli -h 127.0.0.5 -p 50015 SLAVEOF 127.0.0.5 22000
OK
2014-02-27 19:21:59,801 [MainThread] [INFO] [redis:127.0.0.5:50015]: {'used_memory': '342432', 'master_link_status': 'down', 'slave_repl_offset': '-1'}
2014-02-27 19:22:00,811 [MainThread] [INFO] [redis:127.0.0.5:50015]: {'used_memory': '342464', 'master_link_status': 'down', 'slave_repl_offset': '-1'}
2014-02-27 19:22:01,820 [MainThread] [INFO] [redis:127.0.0.5:50015]: {'used_memory': '363456', 'master_link_status': 'up', 'slave_repl_offset': '5998625'}
2014-02-27 19:22:01,821 [MainThread] [NOTICE] cleanup
2014-02-27 19:22:02,156 [MainThread] [INFO] [redis:127.0.0.5:23000] stop ok in 0.11 seconds
2014-02-27 19:22:02,156 [MainThread] [NOTICE] sentinel_reset
2014-02-27 19:22:02,165 [MainThread] [NOTICE] update_config
2014-02-27 19:22:02,166 [MainThread] [INFO] AppendConfig:cluster0['migration'] = []
2014-02-27 19:22:02,166 [MainThread] [INFO] AppendConfig:cluster0['migration'].append('cluster0-22000:127.0.0.5:23000:/tmp/r/redis-23000=&amp;gt;cluster0-22000:127.0.0.5:50015:/tmp/r/redis-50015')
&lt;/pre&gt;
&lt;p&gt;它会修改conf.py, 在末尾增加替换信息:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cluster0['migration'] = []
cluster0['migration'].append('cluster0-22000:127.0.0.5:23000:/tmp/r/redis-23000=&amp;gt;cluster0-22000:127.0.0.5:50015:/tmp/r/redis-50015')
&lt;/pre&gt;
&lt;p&gt;当下一次用redis-mgr操作这个集群时, 老的instace信息就会被新instance替代:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/deploy.py cluster0 status
2014-02-27 19:24:24,815 [MainThread] [NOTICE] start running: ./bin/deploy.py -v cluster0 status
2014-02-27 19:24:24,820 [MainThread] [NOTICE] status redis
2014-02-27 19:24:24,825 [MainThread] [INFO] [redis:127.0.0.5:22000] uptime 29815 seconds
2014-02-27 19:24:24,831 [MainThread] [INFO] [redis:127.0.0.5:50015] uptime 145 seconds
...
2014-02-27 19:24:24,893 [MainThread] [NOTICE] status master-slave
cluster0-22000 [redis:127.0.0.5:22000] &amp;lt;- 127.0.0.5:50015
cluster0-22001 [redis:127.0.0.5:22001] &amp;lt;- 127.0.0.5:23001
cluster0-22002 [redis:127.0.0.5:22002] &amp;lt;- 127.0.0.5:23002
cluster0-22003 [redis:127.0.0.5:22003] &amp;lt;- 127.0.0.5:23003
&lt;/pre&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry></feed>