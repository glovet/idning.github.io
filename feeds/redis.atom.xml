<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>ning</title><link href="/" rel="alternate"></link><link href="http://idning.github.io/feeds/redis.atom.xml" rel="self"></link><id>/</id><updated>2015-05-01T07:27:51+08:00</updated><entry><title>codis-notes</title><link href="/codis.html" rel="alternate"></link><updated>2015-05-01T07:27:51+08:00</updated><author><name>ning</name></author><id>tag:,2015-05-01:codis.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id17"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;概况&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id18"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;设计特点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-clueter" id="id19"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;和redis-clueter对比&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#why-not-twemproxy" id="id20"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Why not Twemproxy &amp;amp; 我的反驳&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id21"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;迁移&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id22"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;优点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id23"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id24"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;使用&amp;amp;部署&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#zk" id="id25"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;zk 设计&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id26"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis" id="id27"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis改动&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hash-slots" id="id28"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;增加hash_slots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id29"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞迁移&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id30"&gt;4.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#proxy" id="id31"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;proxy&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#actions" id="id32"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#router-go" id="id33"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;router.go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id34"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;更新路由&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#pipeline" id="id35"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mget" id="id36"&gt;4.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;mget&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id37"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;几个问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slot" id="id38"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;slot内存&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#value" id="id39"&gt;5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞迁移大value&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id40"&gt;5.3&amp;nbsp;&amp;nbsp;&amp;nbsp;pipeline 性能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id41"&gt;5.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;性能问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id14" id="id42"&gt;5.4&amp;nbsp;&amp;nbsp;&amp;nbsp;使用时遇到的其它小问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-port" id="id43"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-port&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id15" id="id44"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;参考&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id45"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;概况&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;设计特点&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;分1024个slot&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;zk保存拓扑.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;go实现proxy, 无状态.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;预分配: 1024个slot (单实例5G, 大约可以支撑5-10T规模)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;平滑扩容.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;5个组件:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;ZooKeeper&lt;/li&gt;
&lt;li&gt;Codis Redis   (codis-server)  修改后的redis.&lt;/li&gt;
&lt;li&gt;Codis Proxy   (codis-proxy)   实现proxy逻辑&lt;/li&gt;
&lt;li&gt;Dashboard                     需要作为服务运行&lt;/li&gt;
&lt;li&gt;Codis Manager (codis-config)  作为工具运行, 调用dashboard api修改配置.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-clueter"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;和redis-clueter对比&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;在以下方面很像&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;分slot&lt;/li&gt;
&lt;li&gt;redis单机引擎知道slot逻辑.&lt;/li&gt;
&lt;li&gt;阻塞迁移&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;不同:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;使用中心存储 保存路由, 而不是goisp协议.&lt;/li&gt;
&lt;li&gt;使用proxy而不是客户端lib&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="why-not-twemproxy"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id20"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Why not Twemproxy &amp;amp; 我的反驳&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;最大痛点：无法平滑的扩/缩容（Scale!!!!）&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;实际上, 可以通过迁移redis实例来做( &lt;strong&gt;不过确实很痛苦, 我们一般直接迁移整个集群&lt;/strong&gt; )&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;没有HA机制，没有容错能力&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;实际上, 通过外部工具来做, 效果不错.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;修改配置需要重启服务&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;实际上, 在作出修改配置决定前, 服务已经出问题至少30s了, 重启花1s并没有问题.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id21"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;迁移&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;把一个slot标记为pre-migrate&lt;/li&gt;
&lt;li&gt;等待所有proxy确认&lt;/li&gt;
&lt;li&gt;标记slot状态为migrating&lt;/li&gt;
&lt;li&gt;外部工具不断发送slotmigrate给源redis, 每次一个key, 把这个slot中所有key迁移走&lt;/li&gt;
&lt;li&gt;标记slot状态为online&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;一次迁移一个key, 原子, 阻塞(有的文档说: 我们每次只原子的迁走一个 key，不会把主线程 block 住, 这是不对的)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这里为了实现一致性, 降低了可用性(根据CAP, 在分布式系统中, 选择了C, A就会降低)&lt;/li&gt;
&lt;li&gt;为什么说放弃了可用性呢? 假设我们在迁移, 迁移1个key需要0.1ms(同机柜), 那么这个分片的qps就会降到10000qps以下了.&lt;/li&gt;
&lt;li&gt;如果是不同机房, rtt在1ms 左右, 迁移1个key需要1ms, 那么这个qps就降到1000qps以下了.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;proxy 也可能发起迁移命令.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;迁移某个slot的过程中, proxy 会提前要求迁移这个key到目标分片.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;必须保证不能同时有多个 slots 处于迁移状态 =&amp;gt; 决定了很慢, 不能扩展到很大的集群(不过够用了)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;优点&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;给redis一个扩容方案.&lt;/li&gt;
&lt;li&gt;proxy能利用多核, 单机性能比Twemproxy好.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id23"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;redis中每个key会多存一份(slots hash表), 如果key比较大, 很浪费redis内存( &lt;strong&gt;大约1.5倍&lt;/strong&gt; ).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;阻塞式迁移, 为了一致性降低可用性.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;对大set, 大list等大value不友好, 可能导致redis &lt;strong&gt;阻塞1-2s&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;主从切换不是自动, 需要手动操作(建议自动操作, 操作后人工后验检查)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;不能并发迁移，扩容会很慢, 影响集群规模.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;直接把redis代码包进来了, 对redis的后续升级, bugfix等难以merge.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;使用crc32做sharding, 不是很均匀, 不过分了slot, 所以没关系了.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;proxy&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;pipeline 性能差(后面优化了, 尚未测试)&lt;/li&gt;
&lt;li&gt;mget/mset 都是串行执行, 性能较差.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;需要一个部署工具.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id24"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;使用&amp;amp;部署&lt;/a&gt;&lt;/h2&gt;
&lt;pre class="literal-block"&gt;
DATE=`date +'%Y%m%d%H%M'`
DIR=&amp;quot;$( cd &amp;quot;$( dirname &amp;quot;${BASH_SOURCE[0]}&amp;quot; )&amp;quot; &amp;amp;&amp;amp; pwd )&amp;quot;

# clean &amp;amp; start zk
cd ~/xredis/zookeeper-3.4.6 &amp;amp;&amp;amp; ./bin/zkServer.sh stop

rm /tmp/zookeeper -rf
pkill -f codis-config

cd ~/xredis/zookeeper-3.4.6 &amp;amp;&amp;amp; ./bin/zkServer.sh start

cd $DIR

nohup ./bin/codis-config -c sample/config.ini dashboard &amp;amp;

sleep 3

echo 'dash running'

./bin/codis-config -c sample/config.ini server add 0 localhost:2000 master
./bin/codis-config -c sample/config.ini server add 0 localhost:3000 slave

./bin/codis-config -c sample/config.ini server add 1 localhost:2001 master
./bin/codis-config -c sample/config.ini server add 1 localhost:3001 slave

./bin/codis-config -c sample/config.ini server add 2 localhost:2002 master
./bin/codis-config -c sample/config.ini server add 2 localhost:3002 slave

./bin/codis-config -c sample/config.ini server add 3 localhost:2003 master
./bin/codis-config -c sample/config.ini server add 3 localhost:3003 slave

./bin/codis-config -c sample/config.ini slot init
./bin/codis-config -c sample/config.ini slot range-set 0 511    0 online
./bin/codis-config -c sample/config.ini slot range-set 512 1023 1 online

./bin/codis-proxy -c sample/config.ini -L ./log/proxy.log  --cpu=8 --addr=0.0.0.0:19000 --http-addr=0.0.0.0:11000
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="zk"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id25"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;zk 设计&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;zk 设计:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/codis/db_{xx}
{xx} means 产品名， 如: /codis/db_sync , /codis/db_applist
/codis/db_{xx}/servers/group_{N}/{ server addr (e.g. 127.0.0.1:6379) }
存储真实的 redis 组 (主master、从slave), N为一个自定义的整数编号, in JSON, 内容包括服务器地址，
角色（master or slave）等信息

/codis/db_{xx}/slots/slot_{N}
&lt;/pre&gt;
&lt;p&gt;举例, zk中存储的数据如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ zk-shell 127.1:2181
Welcome to zk-shell (1.0.05)
(CONNECTING) /&amp;gt;
(CONNECTED) /&amp;gt; tree
├── zk
│   ├── codis
│   │   ├── db_test
│   │   │   ├── migrate_manager
│   │   │   ├── fence
│   │   │   ├── servers
│   │   │   │   ├── group_0
│   │   │   │   │   ├── localhost:2000
│   │   │   │   │   ├── localhost:3000
│   │   │   │   ├── group_1
│   │   │   │   │   ├── localhost:2001
│   │   │   │   │   ├── localhost:3001
│   │   │   ├── slots
│   │   │   │   ├── slot_0
│   │   │   │   ├── slot_1
│   │   │   │   ├── slot_2
│   │   │   │   ├── slot_3
│   │   │   │   ├── ...
│   │   │   │   ├── ...
│   │   │   │   ├── slot_1023
│   │   │   ├── proxy
|   │   │   │   ├── proxy_1
│   │   │   ├── migrate_tasks
│   │   │   ├── LOCK
│   │   │   ├── actions
│   │   │   │   ├── 0000000004
│   │   │   │   ├── 0000000010
│   │   │   │   ├── 0000000006
│   │   │   │   ├── 0000000008
│   │   │   │   ├── 0000000000
│   │   │   │   ├── 0000000002
│   │   │   ├── ActionResponse
│   │   │   │   ├── 0000000004
│   │   │   │   ├── 0000000010
│   │   │   │   ├── 0000000006
│   │   │   │   ├── 0000000008
│   │   │   │   ├── 0000000000
│   │   │   │   ├── 0000000002
&lt;/pre&gt;
&lt;p&gt;其中几种节点数据:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(CONNECTED) /&amp;gt; get zk/codis/db_test/servers/group_0/localhost:2000
{&amp;quot;type&amp;quot;:&amp;quot;master&amp;quot;,&amp;quot;group_id&amp;quot;:0,&amp;quot;addr&amp;quot;:&amp;quot;localhost:2000&amp;quot;}

(CONNECTED) /&amp;gt; get zk/codis/db_test/slots/slot_0
{&amp;quot;product_name&amp;quot;:&amp;quot;test&amp;quot;,&amp;quot;id&amp;quot;:0,&amp;quot;group_id&amp;quot;:1,&amp;quot;state&amp;quot;:{&amp;quot;status&amp;quot;:&amp;quot;online&amp;quot;,&amp;quot;migrate_status&amp;quot;:{&amp;quot;from&amp;quot;:-1,&amp;quot;to&amp;quot;:-1},&amp;quot;last_op_ts&amp;quot;:&amp;quot;0&amp;quot;}}

(CONNECTED) /&amp;gt; get zk/codis/db_test/proxy/proxy_1
{&amp;quot;id&amp;quot;:&amp;quot;proxy_1&amp;quot;,&amp;quot;addr&amp;quot;:&amp;quot;127.1:19000&amp;quot;,&amp;quot;last_event&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;last_event_ts&amp;quot;:0,&amp;quot;state&amp;quot;:&amp;quot;offline&amp;quot;,&amp;quot;description&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;debug_var_addr&amp;quot;:&amp;quot;127.1:11000&amp;quot;,&amp;quot;pid&amp;quot;:12438,&amp;quot;start_at&amp;quot;:&amp;quot;2015-04-28 15:20:23.739459751 +0800 CST&amp;quot;}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id26"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="redis"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id27"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis改动&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;ext/redis-2.8.13/&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;每个db增加N个slot. 每个slot里面是一个hash, 用于保存每个slot有哪些个key(导致每个key多存一份)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;key是raw_key, val 是crc(key).&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;dictadd/dictDel/dictResize的时候都要在每个slot里面操作&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;增加一系列命令(slotsxxx) slots.c&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="hash-slots"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id28"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;增加hash_slots&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
typedef struct redisDb {
    dict *dict;                 /* The keyspace for this DB */
    dict *expires;              /* Timeout of keys with a timeout set */
    ...
    dict *hash_slots[HASH_SLOTS_SIZE];
} redisDb;

initServer() {
    for (i = 0; i &amp;lt; HASH_SLOTS_SIZE; i ++) {
        server.db[j].hash_slots[i] = dictCreate(&amp;amp;hashSlotType, NULL);
    }
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
void dbAdd(redisDb *db, robj *key, robj *val) {
    sds copy = sdsdup(key-&amp;gt;ptr);

    int retval = dictAdd(db-&amp;gt;dict, copy, val);

    do {
        uint32_t crc;
        int slot = slots_num(key-&amp;gt;ptr, &amp;amp;crc);
        dictAdd(db-&amp;gt;hash_slots[slot], sdsdup(key-&amp;gt;ptr), (void *)(long)crc);
    } while (0);
    ...
}
&lt;/pre&gt;
&lt;p&gt;增加了一些命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{&amp;quot;slotsinfo&amp;quot;,slotsinfoCommand,-1,&amp;quot;rF&amp;quot;,0,NULL,0,0,0,0,0},
{&amp;quot;slotsdel&amp;quot;,slotsdelCommand,-2,&amp;quot;w&amp;quot;,0,NULL,1,-1,1,0,0},
{&amp;quot;slotsmgrtslot&amp;quot;,slotsmgrtslotCommand,5,&amp;quot;aw&amp;quot;,0,NULL,0,0,0,0,0},
{&amp;quot;slotsmgrtone&amp;quot;,slotsmgrtoneCommand,5,&amp;quot;aw&amp;quot;,0,NULL,0,0,0,0,0},
{&amp;quot;slotsmgrttagslot&amp;quot;,slotsmgrttagslotCommand,5,&amp;quot;aw&amp;quot;,0,NULL,0,0,0,0,0},
{&amp;quot;slotsmgrttagone&amp;quot;,slotsmgrttagoneCommand,5,&amp;quot;aw&amp;quot;,0,NULL,0,0,0,0,0},
{&amp;quot;slotshashkey&amp;quot;,slotshashkeyCommand,-1,&amp;quot;rF&amp;quot;,0,NULL,0,0,0,0,0},
{&amp;quot;slotscheck&amp;quot;,slotscheckCommand,0,&amp;quot;r&amp;quot;,0,NULL,0,0,0,0,0},
{&amp;quot;slotsrestore&amp;quot;,slotsrestoreCommand,-4,&amp;quot;awm&amp;quot;,0,NULL,1,1,1,0,0},
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id29"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞迁移&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
static int
slotsmgrt(redisClient *c, sds host, sds port, int fd, int dbid, int timeout, robj *keys[], robj *vals[], int n) {
    ...
    syncWrite(fd, buf + pos, towrite, timeout);
    syncReadLine(fd, buf1, sizeof(buf1), timeout)
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id30"&gt;4.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h4&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;它会记录每个slot有哪些key, 这就会导致key多存一份, 这在某些情况下带来的内存消耗大约是1.5倍.(详见后面测试)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;而对redis来说, 空间很珍贵, 这里可以用时间换空间, 会更好.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;阻塞迁移造成的短时拒绝服务(详见后面测试).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="proxy"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id31"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;proxy&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;代码量大约6000:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Go                              42            975            171           5113
Javascript                       7             84             99            596
HTML                             4             48             24            588
JSON                             3              0              0             52
CSS                              3              2              4             11
Bourne Shell                     2              3              0              6
-------------------------------------------------------------------------------
SUM:                            61           1112            298           6366
-------------------------------------------------------------------------------
&lt;/pre&gt;
&lt;p&gt;代码结构:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
▾ pkg/
  ▾ models/                 # 对应zk中的几个结构.
      server_group.go
      slot.go
      action.go
      proxy.go
  ▾ proxy/
    ▾ parser/
        parser.go           # 解析请求.
    ▾ redispool/
        conn.go             # 连接
        redispool.go        # 连接池
    ▾ cachepool/
        cachepool.go        # 由后端名字到连接池的map. [127.0.0.1:2000] =&amp;gt; redispool {conn1, conn2, conn3}
    ▾ group/
        group.go            # 简单包装.
    ▾ router/
      ▸ topology/           # InitZkConn, watch
        helper.go           # redis命令黑名单, isMulOp, PING, SELECT 几个命令的处理.
        mapper.go           # mapKey2Slot (crc32 % 1024)
        session.go          # 记录当前实例的ops, starttime.
        router.go           # 主要proxy逻辑.
        multioperator.go    # mget/mset/del 的实现.
&lt;/pre&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;pkg/models定义几种角色, slot, server_group, proxy 和几种动作, action, 它是zk的的数据模型.&lt;/li&gt;
&lt;li&gt;pkg/proxy 是proxy逻辑的实现.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看一个获得所有ServerGroups的代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
func ServerGroups(zkConn zkhelper.Conn, productName string) ([]ServerGroup, error) {
    var ret []ServerGroup
    root := fmt.Sprintf(&amp;quot;/zk/codis/db_%s/servers&amp;quot;, productName)
    groups, _, err := zkConn.Children(root)

    for _, group := range groups {
        groupId, err := strconv.Atoi(strings.Split(group, &amp;quot;_&amp;quot;)[1])
        g, err := GetGroup(zkConn, productName, groupId)
        ret = append(ret, *g)
    }
    return ret, nil
}
&lt;/pre&gt;
&lt;div class="section" id="actions"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id32"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;actions&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;codis 对每个topo变化的操作, 都会记录到actions, 同时对于某些action, 会要求每个proxy ack确保更新到最新拓扑.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;TODO: 如何实现确保ack&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="router-go"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id33"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;router.go&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;加载拓扑信息(一个slot指向那个group):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
//use it in lock
func (s *Server) fillSlot(i int, force bool) {
    slotInfo, groupInfo, err := s.top.GetSlotByIndex(i)             # 从zk中获取slot信息

    slot := &amp;amp;Slot{
        slotInfo:  slotInfo,
        dst:       group.NewGroup(*groupInfo),
        groupInfo: groupInfo,
    }

    s.pools.AddPool(slot.dst.Master())                              # 准备连接池

    if slot.slotInfo.State.Status == models.SLOT_STATUS_MIGRATE {   # 处理MIGRATE状态.
        //get migrate src group and fill it
        from, err := s.top.GetGroup(slot.slotInfo.State.MigrateStatus.From)
        slot.migrateFrom = group.NewGroup(*from)
        s.pools.AddPool(slot.migrateFrom.Master())
    }

    s.slots[i] = slot
}

#如果状态是migrate 的slot, 发migrate命令
func (s *Server) handleMigrateState(slotIndex int, key []byte) error {
    ...
    err = WriteMigrateKeyCmd(redisConn.(*redispool.PooledConn), shd.dst.Master(), 30*1000, key)
    ...
}
&lt;/pre&gt;
&lt;p&gt;转发逻辑, 读一个请求, 向后端转发一个:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
func (s *Server) redisTunnel(c *session) error {
    resp, err := parser.Parse(c.r) // read client request

    op, k, err := getOpKey(resp)
    i := mapKey2Slot(k)

check_state:        # 这里是一个循环来检查, 等待SLOT_STATUS_PRE_MIGRATE结束
    s.mu.RLock()
    if s.slots[i] == nil {
        s.mu.Unlock()
        return errors.Errorf(&amp;quot;should never happend, slot %d is empty&amp;quot;, i)
    }
    //wait for state change, should be soon
    if s.slots[i].slotInfo.State.Status == models.SLOT_STATUS_PRE_MIGRATE {
        s.mu.RUnlock()
        time.Sleep(10 * time.Millisecond)
        goto check_state
    }

    s.handleMigrateState(i, k);

    //get redis connection
    redisConn, err := s.pools.GetConn(s.slots[i].dst.Master())
    redisErr, clientErr := forward(c, redisConn.(*redispool.PooledConn), resp)
}

func (s *Server) handleConn(c net.Conn) {
    for {
        err = s.redisTunnel(client)
        client.Ops++
    }
}

func (s *Server) Run() {
    log.Info(&amp;quot;listening on&amp;quot;, s.addr)
    listener, err := net.Listen(&amp;quot;tcp&amp;quot;, s.addr)
    for {
        conn, err := listener.Accept()
        go s.handleConn(conn)       #起一个
    }
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id34"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;更新路由&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;proxy 会watch action 树下的变更, 有变化时 重新加载路由:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
func (s *Server) OnGroupChange(groupId int) {
    log.Warning(&amp;quot;group changed&amp;quot;, groupId)

    for i, slot := range s.slots {
        if slot.slotInfo.GroupId == groupId {
            s.fillSlot(i, true)
        }
    }
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="pipeline"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id35"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;pipeline&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;上面代码是&amp;#64;ngaut同学pipeline优化前的代码,&lt;/p&gt;
&lt;p&gt;一般来说, 实现pipeline可能存在下面两个问题, 不过测试发现: &lt;strong&gt;codis都没有问题&lt;/strong&gt; .&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;返回乱序:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
get     k1 k2 k3 k4
return  v2 v1 v3 vj
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;原因是k1,k2发到不同后端,  如果其中一个后端很慢, 而先返回的后端就先写客户端, 就是这个错误.&lt;/p&gt;
&lt;p&gt;测试发现codis没有这个问题, 但是看代码没有看懂为什么. 涉及到多个channel中传递消息(TODO).&lt;/p&gt;
&lt;ol class="arabic" start="2"&gt;
&lt;li&gt;&lt;p class="first"&gt;乱序执行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
lpush   lst 1
lpush   lst 2
lpush   lst 3
lpush   lst 4

lpop return 2 1 3 4
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第二种情况是发到同一个后端, 但是如果向同一个后端有多个连接, 就可能出这个问题.
某个连接上的请求先执行.&lt;/p&gt;
&lt;p&gt;codis一个后端只有一个TaskRunner(一个连接), 所以应该不会出这个问题.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mget"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id36"&gt;4.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;mget&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;逐一访问:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
func (oper *MultiOperator) mgetResults(mop *MulOp) ([]byte, error) {
    results := make([]interface{}, len(mop.keys))
    conn := oper.pool.Get()
    defer conn.Close()
    for i, key := range mop.keys {
        replys, err := redis.Values(conn.Do(&amp;quot;mget&amp;quot;, key))

        for _, reply := range replys {
            if reply != nil {
                results[i] = reply
            } else {
                results[i] = nil
            }
        }
    }

    b, err := respcoding.Marshal(results)
    return b, errors.Trace(err)
}
&lt;/pre&gt;
&lt;p&gt;这是为了保证迁移过程中的一致性, 必须一个一个处理.&lt;/p&gt;
&lt;p&gt;性能较差.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id37"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;几个问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="slot"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id38"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;slot内存&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;对于简单value(value大小1字节) slots内存占用:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
keys         0          1000      10000     100000      1000000
---------------------------------------------------------------
codis-server 2519112    2678920   4073224   17449032    176095304
redis-server 908688     1019856   2078736   12356240    120496272
&lt;/pre&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;可以看出codis 内存占用大约是 原生redis 的 &lt;strong&gt;1.5倍&lt;/strong&gt; .&lt;/li&gt;
&lt;li&gt;越长的key, 浪费的内存越多.&lt;/li&gt;
&lt;li&gt;对于大value(复杂的hash, set结构), 浪费的内存会较少.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;测试代码: &lt;a class="reference external" href="https://gist.github.com/idning/b23c4d4fe76da5b00ae3"&gt;https://gist.github.com/idning/b23c4d4fe76da5b00ae3&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="value"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id39"&gt;5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞迁移大value&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;为了保证迁移的一致性, codis选择牺牲可用性, 迁移单个key是通过阻塞当前实例来实现的.&lt;/p&gt;
&lt;p&gt;一个100w 字段的hset(内存中大约占70M), 迁移耗时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
本机:           1.85 s
同机房不同机器: 2.06s
&lt;/pre&gt;
&lt;p&gt;1-2s的不响应对大多数业务来说, 还是可以接受的, 所以这个问题不是很严重.&lt;/p&gt;
&lt;p&gt;但是一定要注意:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;业务中不要出现1000w字段的hset, len=1000w的list之类.&lt;/li&gt;
&lt;li&gt;如果一个集群跨机房部署, 数据传输时间会更长, 迁移时间也会更长.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;测试代码: &lt;a class="reference external" href="https://gist.github.com/idning/03f43b6789f14e1fe878"&gt;https://gist.github.com/idning/03f43b6789f14e1fe878&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在proxy代码中, 给迁移一个key设置的超时是30s:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
func (s *Server) handleMigrateState(slotIndex int, key []byte) error {
    ...
    err = WriteMigrateKeyCmd(redisConn.(*redispool.PooledConn), shd.dst.Master(), 30*1000, key)
    ...
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id40"&gt;5.3&amp;nbsp;&amp;nbsp;&amp;nbsp;pipeline 性能&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;codis proxy对每个请求都是解析 =&amp;gt; 找个连接发到后端 =&amp;gt; 等待响应 =&amp;gt; 发给客户端&lt;/p&gt;
&lt;p&gt;这样就相当于不能使用pipeline, 而pipeline对要求高性能的case是非常重要的,&lt;/p&gt;
&lt;p&gt;开pipeline的情况下, 单redis, 单线程client做简单set可以达到 &lt;strong&gt;100w qps&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="section" id="id13"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id41"&gt;5.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;性能问题&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;spinlock同学的测试:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/wandoulabs/codis/issues/63"&gt;https://github.com/wandoulabs/codis/issues/63&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
CONC        PIPELINE        CODIS-LATENCY   REDIS-LATENCY
50      10          3.17            0.60
50      20          5.88            0.89
50      75          21.78           2.40p
&lt;/pre&gt;
&lt;p&gt;&amp;#64;ngaut 同学在15年2月实现了pipeline的支持: &lt;a class="reference external" href="https://github.com/wandoulabs/codis/pull/110"&gt;https://github.com/wandoulabs/codis/pull/110&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;用go来实现pipeline的问题是:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;pipeline并不是一个命令, pipeline实际上是异步处理所带来的一个好处, 只是一种使用方法.&lt;/li&gt;
&lt;li&gt;理论上, proxy/redis都不需要做任何事情来支持pipeline.&lt;/li&gt;
&lt;li&gt;但是codis采用了逐一转发的方法来处理请求, 就需要对pipeline专门处理.&lt;/li&gt;
&lt;li&gt;需要把go写成异步处理的形式, go 带来的编程模型简单的好处就没有了.&lt;/li&gt;
&lt;li&gt;优化后, 对所有的请求统一使用同样的方法(proxy并不知道自己处在一个pipeline中)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;pipeline 遇到slot迁移状态性能又是一个严重的问题.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id14"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id42"&gt;5.4&amp;nbsp;&amp;nbsp;&amp;nbsp;使用时遇到的其它小问题&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;命令行支持:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
只支持 ./bin/codis-config  -c sample/config.ini dashboard
不支持 ./bin/codis-config  dashboard -c sample/config.ini, 这个命令报一个非常奇怪的错误.
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;努棒性:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;配置写错, 比如:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dashboard_addr=:8087
&lt;/pre&gt;
&lt;p&gt;zk节点也能建成功, 而且不删, 需要等一段时间.&lt;/p&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;很多地方没有检查, 如果 add group 时写错参数.&lt;/li&gt;
&lt;li&gt;proxy 启动后为啥不直接是online呢?&lt;/li&gt;
&lt;li&gt;代码上有些同名的函数, 比如NewServer一个Server是backendServer, 一个是proxy自己, 读的时候要小心.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-port"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id43"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-port&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这是整个系统一个极大的亮点, 用于数据迁移, 比我们的redis-replay-aof好的是, 不需要到目标机器读aof文件.&lt;/p&gt;
&lt;p&gt;实现原理: 作为一个假的 slave，挂在一个redis后面，然后将master的数据同步回来，sync 到 codis 集群上，&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id15"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id44"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;参考&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;设计文章: &lt;a class="reference external" href="http://0xffff.me/blog/2014/11/11/codis-de-she-ji-yu-shi-xian-part-2/"&gt;http://0xffff.me/blog/2014/11/11/codis-de-she-ji-yu-shi-xian-part-2/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;代码: &lt;a class="reference external" href="https://github.com/wandoulabs/codis"&gt;https://github.com/wandoulabs/codis&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;codis design pdf&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;豌豆荚分布式REDIS设计与实现－刘奇&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://blog.qiniu.com/?p=871"&gt;http://blog.qiniu.com/?p=871&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id45"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;总结&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;非常赞的人&amp;amp;非常赞的项目&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;几个比较重要的问题:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;slot内存占用 &lt;tt class="docutils literal"&gt;1.5倍&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;redis阻塞迁移, 为了一致性降低可用性.&lt;/li&gt;
&lt;li&gt;不是自动failover&lt;/li&gt;
&lt;li&gt;pipeline/mget性能&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;迁移状态是瞬态(在一个集群运行过程中, 迁移时间只占1/1000不到)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;但是为了保持迁移状态, mget 性能做了牺牲, redis内存占用做了牺牲, 这不划算.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;redis-port很赞.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每种方案都是适用的地方.&lt;/p&gt;
&lt;/div&gt;
</summary></entry><entry><title>redis-data-migrate</title><link href="/redis-data-migrate.html" rel="alternate"></link><updated>2014-11-02T11:41:38+08:00</updated><author><name>ning</name></author><id>tag:,2014-11-02:redis-data-migrate.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么要设计这样的扩容方式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id8"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;怎么实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id9"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof" id="id10"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;aof不是幂等的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id11"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;切流量时的不一致&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id12"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-mgr" id="id13"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr 集成&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id14"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;在 &lt;a class="reference external" href="/redis-instance-migrate.html"&gt;这篇blog&lt;/a&gt; 里面提到2种扩容:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;一个是 redis-mgr 中redis实例的迁移, 迁到一个内存大的机器&lt;/li&gt;
&lt;li&gt;另外一个是新搭建集群, 把数据迁移过去.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里考虑第二种思路.&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么要设计这样的扩容方式&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;简单可依赖&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;从架构上, 这不需要像redis-cluster那样复杂的重新设计, 用现有的redis就可以完成扩容,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不需要升级redis服务端, 也不需要升级client端(redis-cluster需要client支持)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;这套方案可以用于:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;从单机redis迁移到 redis-mgr / twemproxy 管理的 集群.&lt;/li&gt;
&lt;li&gt;从一种集群架构迁移到另一种, 比如迁移到官方redis3.0 集群&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总之, 就算redis3.0 的cluster 成熟以后, 还是需要这样的一套迁移方案.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;怎么实现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;mysql 的主从同步是基于binlog, redis主从是一个op buf, mongo主从同步是oplog.&lt;/p&gt;
&lt;p&gt;redis里的aof就是类似binlog, 记录每个操作的log&lt;/p&gt;
&lt;p&gt;所以, 我们可以利用aof, 把它当作binlog, 用于做迁移, 具体的迁移我们在mysql, mongo里面都多次用过了, 分三步:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;迁移基准数据&lt;/li&gt;
&lt;li&gt;追增量&lt;/li&gt;
&lt;li&gt;追上后, 上层切流量.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;redis的aof包含了基准数据和增量, 所以我们只需要把旧集群中redis实例上的aof重放到新集群, 重放追上时修改上层, 把入口换为新集群即可.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="aof"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;aof不是幂等的&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;aof不像binlog那样可以重做 &lt;tt class="docutils literal"&gt;redolog&lt;/tt&gt;, binlog 记录的操作是 &lt;tt class="docutils literal"&gt;幂等(idempotent)&lt;/tt&gt; 的, 意味着如果失败了, 可以重做一次.&lt;/p&gt;
&lt;p&gt;这是因为binlog记录的是操作的结果, 比如:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
op                  log
---------------------------
set x 0             x = 0
incr x              x = 1
incr x              x = 2
&lt;/pre&gt;
&lt;p&gt;但是redis的aof记录的是操作:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
op                  log
---------------------------
set x 0             x = 0
incr x              incr x
incr x              incr x
&lt;/pre&gt;
&lt;p&gt;这就是说, 如果我们在重放aof的过程中出错(比如网络中断):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;不能继续(不好找到上次同步到哪),&lt;/li&gt;
&lt;li&gt;也不能重新重放一次, (incr两次, 值就错了)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;只能清除目标集群的数据重新迁移一次 ( &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-mgr&lt;/span&gt;&lt;/tt&gt; 里面有 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;clean-keys&lt;/span&gt;&lt;/tt&gt; 命令按照前缀清除)&lt;/p&gt;
&lt;p&gt;不过, 好在redis单实例的afo数据都不大, 一般10G左右, 重放大约20min就能完成, 出错的概率也很小. (这也是redis可以这样做, 而其他持久存储比如mysql, mongo必须支持断点同步的原因)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;切流量时的不一致&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;前面说的步骤是:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;追aof&lt;/li&gt;
&lt;li&gt;追上后, 切流量.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;追aof是一个动态的过程, 追上后, 新的写操作马上就来, 所以这里追上的意思是说, 新的写入马上会被消化掉.&lt;/p&gt;
&lt;p&gt;但是考虑这样一种场景:&lt;/p&gt;
&lt;p&gt;假设client上做对x做两次set(一个机器上做两次, 或者两个app-server上分别做):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
client          old_cluster         new_cluster
-----------------------------------------------
set x 1(a)      set x 1(客户操作)
-----------------------------------------------&amp;gt; 切流量到new_cluster
set x 2(b)                          set x 2 (客户操作)
                                    set x 1 (b 操作被重放到 new_cluster)
&lt;/pre&gt;
&lt;p&gt;a操作还没同步到new_cluster, 流量就已经切到了new_cluster, 这时候对同一个key的更新, 会被老集群上的操作覆盖掉.&lt;/p&gt;
&lt;p&gt;解决:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;这个短暂的不一致, 对多数业务, 是能容忍的(很少有业务会高速更新同一个key)&lt;/li&gt;
&lt;li&gt;如果非要达到一致, 当追aof追上后, app-server停写, 等待彻底追上(此时老集群的aof不会有更新了), 然后再切流量.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id12"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;有两份代码:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;推荐 &lt;a class="reference external" href="https://github.com/cen-li/redis/blob/redis-2.8.3_replay-aof/src/redis-replay-aof.c"&gt;https://github.com/cen-li/redis/blob/redis-2.8.3_replay-aof/src/redis-replay-aof.c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;写着玩: &lt;a class="reference external" href="https://github.com/idning/redis/blob/replay/src/redis-cli.c"&gt;https://github.com/idning/redis/blob/replay/src/redis-cli.c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原理就是不断的看aof文件是否有更新, 有更新的话写到目标集群, 支持 按前缀过滤, 加前缀, 换前缀之类的操作.&lt;/p&gt;
&lt;div class="section" id="redis-mgr"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id13"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr 集成&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-mgr&lt;/span&gt;&lt;/tt&gt; 里面集成了一个命令来方便操作:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#从cluster1迁移到cluster5
./bin/deploy.py cluster1 replay_aof cluster5 'prefix_'
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id14"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;文档: &lt;a class="reference external" href="https://github.com/idning/redis-mgr/blob/master/doc/scalablity.rst"&gt;https://github.com/idning/redis-mgr/blob/master/doc/scalablity.rst&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>hyperloglog</title><link href="/hyperloglog.html" rel="alternate"></link><updated>2014-10-11T13:55:22+08:00</updated><author><name>ning</name></author><id>tag:,2014-10-11:hyperloglog.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#what" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;what&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#how" id="id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;how&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis" id="id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;redis实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ref" id="id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;ref&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id8"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;思考&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id9"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;其它算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id10"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;典型问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#lossy-counting" id="id11"&gt;7.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Lossy Counting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#sticky-counting" id="id12"&gt;7.2&amp;nbsp;&amp;nbsp;&amp;nbsp;Sticky Counting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="what"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;what&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Hyperloglog是 counting 算法&lt;/li&gt;
&lt;li&gt;Hyperloglog is an approximate technique for computing the number of distinct entries in a set, It does this while using a small amount of memory. For instance, to achieve 99% accuracy, it needs only 16 KB.&lt;/li&gt;
&lt;li&gt;It is derived from the LogLog counting technique&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是, 不就是需要一个计数么?  i++ 不就行了么?&lt;/p&gt;
&lt;p&gt;需求:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;计算每天访问某个网站的 &lt;tt class="docutils literal"&gt;uniq&lt;/tt&gt; ips&lt;/li&gt;
&lt;li&gt;计算google 每天 &lt;tt class="docutils literal"&gt;uniq&lt;/tt&gt; query 个数.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们怎么处理呢:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
脚本:           sort | uniq | wc -l
map-reduce:     sort | uniq | wc -l
程序:           通过一个大字典去重.
&lt;/pre&gt;
&lt;p&gt;它们的特点是:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;sort方法时间复杂度O(n log N)&lt;/li&gt;
&lt;li&gt;去重方法 需要很大内存来去重, 空间复杂度O(n)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="how"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;how&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Here I’ll cover only the basic idea using a very clever example found at [3]. Imagine you tell me you spent your day flipping a coin, counting how many times you encountered a non interrupted run of heads. If you tell me that the maximum run was of 3 heads, I can imagine that you did not really flipped the coin a lot of times. If instead your longest run was 13, you probably spent a lot of time flipping the coin.&lt;/p&gt;
&lt;p&gt;Long story short this is what HyperLogLog does: it hashes every new element you observe. Part of the hash is used to index a register,
The other part of the hash is used to count the longest run of leading zeroes in the hash (our run of heads).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="redis"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;redis实现&lt;/a&gt;&lt;/h2&gt;
&lt;pre class="literal-block"&gt;
PFADD var element element … element
PFCOUNT var
PFMERGE dst src src src … src
&lt;/pre&gt;
&lt;p&gt;The commands prefix is “PF” in honor of Philippe Flajolet [4].&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ref"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;ref&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;很有意思.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;这个算法大致是2007年发明出来的, google 做了改进.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://antirez.com/news/75"&gt;http://antirez.com/news/75&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf"&gt;http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf"&gt;http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;这里做了模拟展示: &lt;a class="reference external" href="http://content.research.neustar.biz/blog/hll.html"&gt;http://content.research.neustar.biz/blog/hll.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lossy Counting ppt(很赞): &lt;a class="reference external" href="http://www.cse.ust.hk/vldb2002/VLDB2002-proceedings/slides/S10P03slides.pdf"&gt;http://www.cse.ust.hk/vldb2002/VLDB2002-proceedings/slides/S10P03slides.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;同上: &lt;a class="reference external" href="http://www.cs.utah.edu/~lifeifei/cis5930/lecture8.pdf"&gt;http://www.cs.utah.edu/~lifeifei/cis5930/lecture8.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;思考&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;如何动态维护top10&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;redis的简单kv做计数, 再加个zset.&lt;/li&gt;
&lt;li&gt;zset里面放当前最大的N个, 每次来一个query, 更新hash中的value, 同时看, 如果当前value &amp;gt; zset.min 把zset最后一个踢掉, 把当前这个插入到zset.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;其它算法&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这一类算法可以叫做: Streaming_algorithm&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Streaming_algorithm"&gt;http://en.wikipedia.org/wiki/Streaming_algorithm&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Streams can be denoted as an ordered sequence of points (or &amp;quot;updates&amp;quot;)&lt;/li&gt;
&lt;li&gt;但是通常 too large to be stored&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;模型:
- cash register
- turnstile model
- sliding window&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id10"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;典型问题&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Frequency moments&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Heavy hitters (&lt;strong&gt;top 10&lt;/strong&gt;)
Find the most frequent (popular) elements in a data stream. Some notable algorithms are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Karp-Papadimitriou-Shenker algorithm&lt;/li&gt;
&lt;li&gt;Count-Min sketch&lt;/li&gt;
&lt;li&gt;Sticky sampling&lt;/li&gt;
&lt;li&gt;Lossy counting&lt;/li&gt;
&lt;li&gt;Multi-stage Bloom filters&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Trend detection[edit]
Detecting trends in data streams is often done using an heavy hitters algorithm as listed above&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Counting distinct elements&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;hyperloglog&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Entropy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Online learning&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="lossy-counting"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;7.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Lossy Counting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Say you're looking at the traffic for facebook profiles. You have billions of hits. You want to find which profiles are accessed the most often. You could keep a count for each profile, but then you'd have a very large number of counts to keep track of, the vast majority of which would be meaningless.&lt;/p&gt;
&lt;p&gt;With lossy counting, you periodically remove very low count elements from the table. The most-frequently accessed profiles would almost never have low counts anyway, and if they did, they wouldn't be likely to stay there for long.&lt;/p&gt;
&lt;p&gt;-- 其实就相当于用redis做count, expire调的比较小(比如1 day)&lt;/p&gt;
&lt;p&gt;There are a large number of refinements to the algorithm. But the basic idea is this -- to find the heavy hitters without having to track every element, periodically purge your counts of any elements that don't seem likely to be heavy hitters based on the data so far.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="sticky-counting"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id12"&gt;7.2&amp;nbsp;&amp;nbsp;&amp;nbsp;Sticky Counting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;抽样计算counting.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis设计与实现 笔记</title><link href="/book-redis-implement.html" rel="alternate"></link><updated>2014-09-29T17:39:16+08:00</updated><author><name>ning</name></author><id>tag:,2014-09-29:book-redis-implement.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c4-hash" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;c4 hash&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#rehash" id="id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;rehash&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;渐进式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c5-skiplist" id="id7"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;c5 跳表(skiplist)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c8-object" id="id8"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;c8 object(类型和编码)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c9" id="id9"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;c9 数据库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c16-sentinel" id="id10"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;c16 sentinel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;事物&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#lua" id="id12"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;lua&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id13"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;读的比较粗, 部分笔记:&lt;/p&gt;
&lt;div class="section" id="c4-hash"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;c4 hash&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="rehash"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;rehash&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;扩展与收缩(rehash) 下面条件满足时:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;没有在进行bgsave或bgrewriteaof, 并且hash表的负载因子大于1&lt;/li&gt;
&lt;li&gt;在进行bgsave或bgrewriteaof, 并且hash表的负载因子大于5&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因为在bgsave或bgrewriteaof的时候, 有子进程存在, redis会尽量避免进行rehash, 从而避免不必要的内存写入, 节约内存  - 这个分析很赞.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;渐进式&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;每次操作一个桶.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="c5-skiplist"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;c5 跳表(skiplist)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;sorted set 的实现:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
方法1: skip list
方法2: skiplist + hash
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="c8-object"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;c8 object(类型和编码)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;几种编码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
REDIS_ENCODING_RAW 0            // 编码为字符串
REDIS_ENCODING_INT 1            // 编码为整数
REDIS_ENCODING_HT 2             // 编码为哈希表
REDIS_ENCODING_ZIPMAP 3         // 编码为 zipmap
REDIS_ENCODING_LINKEDLIST 4     // 编码为双端链表
REDIS_ENCODING_ZIPLIST 5        // 编码为压缩列表
REDIS_ENCODING_INTSET 6         // 编码为整数集合
REDIS_ENCODING_SKIPLIST 7       // 编码为跳跃表
&lt;/pre&gt;
&lt;p&gt;不同类型可能的编码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
string      REDIS_ENCODING_INT
string      REDIS_ENCODING_EMBSTR
string      REDIS_ENCODING_RAW
list        REDIS_ENCODING_ZIPLIST
list        REDIS_ENCODING_LINKEDLIST
hash        REDIS_ENCODING_INTSET
hash        REDIS_ENCODING_HT
set         REDIS_ENCODING_INTSET
set         REDIS_ENCODING_HT
zset        REDIS_ENCODING_ZIPLIST
zset        REDIS_ENCODING_SKIPLIST
&lt;/pre&gt;
&lt;p&gt;object 命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
object encoding numberso
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="c9"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;c9 数据库&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;expire 保存在一个单独的dict里面:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
-----------------------------------------------------------------------

                        +------+
             ---------&amp;gt; |dict  |
             |          +======+
             |          |a     |  -&amp;gt; string val
             |          +------+
+---------+  |          |b     |  -&amp;gt; string val
|redisDB  |  |          +------+
+=========+  |          |c     |  -&amp;gt; string val
|dict     | --          +------+
+---------+
|expires  | --          +------+
+---------+  |--------&amp;gt; |dict  |
                        +======+
                        |a     |  -&amp;gt; longlong 1411987363000
                        +------+
                        |b     |  -&amp;gt; longlong 1411987363000
                        +------+
&lt;/pre&gt;
&lt;p&gt;p113 主从在复制问题上可能出现不一致:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;从上不会主动淘汰key,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不会在cron上尝试删除key&lt;/li&gt;
&lt;li&gt;就算访问到一个已经过期的key, 也不会删除, 而是返回它&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;从库只会从主同步 del命令.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="c16-sentinel"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id10"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;c16 sentinel&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;p229讲的很细致, 不过还是太复杂.&lt;/p&gt;
&lt;p&gt;INFO: 发现slave
publish: 发现其它sentinel&lt;/p&gt;
&lt;p&gt;p244, sentinel选举是 &lt;strong&gt;raft&lt;/strong&gt; 算法 (得看下论文)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id11"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;事物&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;watch 其实是一种cas概念(总算懂了)&lt;/li&gt;
&lt;li&gt;redis事物满足ACID&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="lua"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id12"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;lua&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;对于有些lua中执行的命令, 会对输出做一个排序:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;比如 smember, keys等, 为了保证每次在lua中调用顺序一致.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;如果执行lua超时阻塞, 那么redis 只会接受 shutdown nosave / script kill 命令&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;有的地方比较罗嗦, 比如一个set操作完了之后内存是怎么样的, 不过换句话说, 就是细致.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;很多之前不知道的知识点(不过确实很少用到)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;比如: info/shutdown/publish 这几个命令可以在loading 状态下调用.&lt;/li&gt;
&lt;li&gt;p187, qps的计算: 16个取样, 取平均值.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;关于淘汰: redis 记录访问时间, 从而可以做近似lru&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;v1 链接: &lt;a class="reference external" href="https://github.com/huangz1990/redisbook/"&gt;https://github.com/huangz1990/redisbook/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>hhvm-redis-bug</title><link href="/hhvm-redis-bug.html" rel="alternate"></link><updated>2014-09-09T21:29:40+08:00</updated><author><name>ning</name></author><id>tag:,2014-09-09:hhvm-redis-bug.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试问题复现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fake-redis" id="id14"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;fake-redis 复现&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id15"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;测试1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id16"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis" id="id17"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis库的问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mock" id="id18"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id19"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;修复&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fgets" id="id20"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id21"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id22"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;情况1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id23"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;情况2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fgets-bug" id="id24"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets bug&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id25"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;看实现&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id26"&gt;4.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#readimpl" id="id27"&gt;4.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;readImpl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id28"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hang" id="id29"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;模拟hang住的情况&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id30"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id31"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;更新&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;最近发现hhvm和redis的交互偶尔hang住(这里连接没有设置超时), 分析有三种可能性:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;server端返回错误的response.
比如返回一个超大的 length:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$10240000\r\nabcd\4\n
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
客户端读到这个大数, 但是发现没有这么多字节要读, 于是就一直等着读&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;client解析的时候出错, 如果读到正确的 &lt;tt class="docutils literal"&gt;$12\r\n&lt;/tt&gt; , 解析出错溢出, 被解析成一个超大的数, 也会一直等.&lt;/li&gt;
&lt;li&gt;由于网络问题造成hang住(比如FIN包丢失)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然, 要绕过这个问题最简单的办法是:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;请求加读写超时&lt;/li&gt;
&lt;li&gt;给每个线程加个超时重启机制 (php就可以这么干).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鉴于其它client很少发现类似问题(不过其它client通常都是连接超时, hhvm没有设置), 而且hhvm redis库代码质量较低(之前已经发现了bug), 首先怀疑是client解析出错.&lt;/p&gt;
&lt;p&gt;这篇分析做下面几个事情:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;尝试复现hang住的问题&lt;/li&gt;
&lt;li&gt;通过一个fake-redis稳定复现解析错误.&lt;/li&gt;
&lt;li&gt;检查hhvm Redis/fgets中的bug&lt;/li&gt;
&lt;li&gt;构造hang住的case.&lt;/li&gt;
&lt;li&gt;如何fix.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试问题复现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;由于之前发现 hgetall比较容易hang住, 写了这样一个php来测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;?php
set_time_limit(0);

$r = new Redis();
$r-&amp;gt;setOption('OPT_READ_TIMEOUT', 0.0);
$conn = $r-&amp;gt;connect('10.81.19.14', 4000, 0.1 );

$key = 'kkkkkkkkk';
for ($i=0; $i&amp;lt;3000; $i++) {
    $value = str_pad( $i, $i%100, &amp;quot;\r\n&amp;quot; );

    $r-&amp;gt;hMset($key, array(&amp;quot;field-$i&amp;quot; =&amp;gt; $value));
}

for($i=0; $i&amp;lt;10000000; $i++) {
    $v = $r-&amp;gt;hgetall($key);
    $len = count($v);

    if ($i%100 == 0) {
        echo &amp;quot;$i: $len\n&amp;quot;;
    }
}

hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf a.php
&lt;/pre&gt;
&lt;p&gt;发现不会hang住, 但是经常报错:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[Tue Sep  9 12:58:00 2014] [hphp] [54093:7f598d376340:0:000955] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'o' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processMapResponse()
#2 /home/ning/hhvm/a.php(26): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;这个应该是解析过程中发生的某种错误, 我们先研究这个问题.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fake-redis"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id14"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;fake-redis 复现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;粗略看了hhvm Redis库的代码, 发现读response的地方处理不好, 所以我们构造一个fake-redis用于测试, fake-redis在response的时候, 每次写一个字节, sleep &lt;tt class="docutils literal"&gt;100ms&lt;/tt&gt; .&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/idning/fake-redis/blob/master/fake-redis.py"&gt;https://github.com/idning/fake-redis/blob/master/fake-redis.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(这个测试估计可以让多数网络程序出bug, 包括lighttpd, openssl等)&lt;/p&gt;
&lt;p&gt;应用这个 fake-redis, 做了下面测试&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;测试1&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;c.php:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$r = new Redis();

$conn = $r-&amp;gt;connect('127.1', 9999, 0.1 );

echo &amp;quot;set\n&amp;quot;;
echo $r-&amp;gt;set('k', 'abc');
echo &amp;quot;get\n&amp;quot;;
echo $r-&amp;gt;Get('k');
echo &amp;quot;done\n&amp;quot;;
&lt;/pre&gt;
&lt;p&gt;会出问题:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
get
[Tue Sep  9 22:10:57 2014] [hphp] [54178:7f539ac6f340:0:000001] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'K' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processSerializedResponse()
#2 hhvm/c.php(11): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;加了strace打算看下原因, 发现ok了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
1get
abcdone
&lt;/pre&gt;
&lt;p&gt;后来仔细分析了strace, 发现客户端会经常用100ms 去poll(更详细的分析参考后面):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
recvfrom(7, &amp;quot;O&amp;quot;, 1, MSG_PEEK|MSG_DONTWAIT, NULL, NULL) = 1
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP, revents=POLLIN}], 1, 100) = 1
getsockopt(7, SOL_SOCKET, SO_ERROR, [0], [4]) = 0
recvfrom(7, &amp;quot;O&amp;quot;, 8192, MSG_DONTWAIT, NULL, NULL) = 1
&lt;/pre&gt;
&lt;p&gt;因为server端也是sleep 100ms, 所以用了strace后, cliet慢了一点, server端的response已经来了, 正好就ok了.&lt;/p&gt;
&lt;p&gt;修改 sleep 为150ms, 这时候就能稳定复现, 每次结果都一样:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
NRedis: type=+, resp=
get
[Wed Sep 10 10:43:44 2014] [hphp] [14966:7f42e70f4340:0:000001] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'O' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processSerializedResponse()
#2 /home/ning/hhvm/c.php(56): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;strace如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
recvfrom(7, &amp;quot;O&amp;quot;, 1, MSG_PEEK|MSG_DONTWAIT, NULL, NULL) = 1
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP, revents=POLLIN}], 1, 100) = 1
getsockopt(7, SOL_SOCKET, SO_ERROR, [0], [4]) = 0
recvfrom(7, &amp;quot;O&amp;quot;, 8192, MSG_DONTWAIT, NULL, NULL) = 1
recvfrom(7, 0x7fff6c432e40, 1, 66, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP}], 1, 100) = 0
recvfrom(7, 0x7fa647bf5000, 8192, 64, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id16"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;到了这里, 我们很容易模拟fgets不符合预期的情况了, 通过读代码, 发现主要是fgets的问题.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="redis"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis库的问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="mock"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;我们通过继承Redis，来看看到底发生了什么(这个php被编译在二进制里面了, 每次修改都要重新编译, 不如继承, 方便调试):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class NRedis extends Redis{

  protected function processBooleanResponse() {
    if ($this-&amp;gt;mode === self::ATOMIC) {
      $resp = $this-&amp;gt;sockReadData($type);
      echo &amp;quot;NRedis: type=$type, resp=$resp\r\n&amp;quot;;

      return ($type === self::TYPE_LINE) AND ($resp === 'OK');
    }
    $this-&amp;gt;multiHandler[] = [ 'cb' =&amp;gt; [$this,'processBooleanResponse'] ];
    if (($this-&amp;gt;mode === self::MULTI) &amp;amp;&amp;amp; !$this-&amp;gt;processQueuedResponse()) {
      return false;
    }
    return $this;
  }

  public function hMSet($key, array $pairs) {
    $args = [$this-&amp;gt;prefix($key)];
    foreach ($pairs as $k =&amp;gt; $v) {
      $args[] = $k;
      $args[] = $this-&amp;gt;serialize($v);
    }
    $this-&amp;gt;processArrayCommand('HMSET', $args);
    return $this-&amp;gt;processBooleanResponse();
  }
}


$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
NRedis: type=+, resp=
get
[Wed Sep 10 10:43:44 2014] [hphp] [14966:7f42e70f4340:0:000001] []
Fatal error: Uncaught exception 'RedisException' with Message 'protocol error, got 'O' as reply type byte' in :
Stack trace:
#0 (): Redis-&amp;gt;sockReadData()
#1 (): Redis-&amp;gt;processSerializedResponse()
#2 /home/ning/hhvm/c.php(56): Redis-&amp;gt;__call()
#3 {main}
&lt;/pre&gt;
&lt;p&gt;发现第一个set请求, server 端的返回是 &lt;tt class="docutils literal"&gt;+OK\r\n&lt;/tt&gt;, 但是客户端读到 &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; 就返回了, 此时返回的type是 &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; , resp为空, 所以接下来读get请求的response的时候, 就读到了 'O', 这就是上面这个异常的原因.&lt;/p&gt;
&lt;p&gt;这里 &lt;tt class="docutils literal"&gt;fgets&lt;/tt&gt; 返回了 &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; , 还没遇到 &lt;tt class="docutils literal"&gt;\n&lt;/tt&gt; 就返回, 这是 &lt;tt class="docutils literal"&gt;fgets&lt;/tt&gt; 的问题, 我们后面再分析&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;修复&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;既然fgets有问题, 我们可以换一个比较保守的readLine实现:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class NRedis extends Redis{
  ...
  protected function sockReadLine() {
   if (!$this-&amp;gt;checkConnection()) {
     return false;
   }

   $line = '';
   while(1) {
     $c = fgetc($this-&amp;gt;connection);
     $line .= $c;
     if (substr($line, -2) == &amp;quot;\r\n&amp;quot;) {
       $line = substr($line, 0, -2);
       return $line;
     }
   }

   return false;
  }
}
&lt;/pre&gt;
&lt;p&gt;使用修复版的NRedis, 测试OK:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
set
NRedis: type=+, resp=OK
1get
abcdone
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="fgets"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id20"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id21"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Mock 测试&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;利用前面的fake-redis server, 写了这样一个测试代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat d.php
&amp;lt;?php

$conn = fsockopen('127.1', 9999, $errno, $errstr, 0.1);

fwrite($conn, &amp;quot;*3\r\n$3\r\nSET\r\n$1\r\nk\r\n$1\r\nv\r\n&amp;quot;);
$r = fgets($conn);
var_dump($r);

fwrite($conn, &amp;quot;*2\r\n$3\r\nGET\r\n$1\r\nk\r\n&amp;quot;);

$r = fgets($conn);
var_dump($r);

$r = fgets($conn);
var_dump($r);
&lt;/pre&gt;
&lt;div class="section" id="id6"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id22"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;情况1&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;server端不sleep时, 返回一切正常:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf d.php
string(5) &amp;quot;+OK
&amp;quot;
string(4) &amp;quot;$1
&amp;quot;
string(3) &amp;quot;v
&amp;quot;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id23"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;情况2&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;server端每发送1个byte sleep 150ms:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf d.php
string(1) &amp;quot;+&amp;quot;
string(1) &amp;quot;O&amp;quot;
string(1) &amp;quot;K&amp;quot;
&lt;/pre&gt;
&lt;p&gt;每次 &lt;tt class="docutils literal"&gt;fgets&lt;/tt&gt; 只能读到一个字节.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="fgets-bug"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id24"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets bug&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="http://php.net/manual/en/function.fgets.php"&gt;http://php.net/manual/en/function.fgets.php&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;php.net上fgets 的文档:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Reading ends when length - 1 bytes have been read, or a newline (which is included in the return value), or an EOF (whichever comes first). If no length is specified, it will keep reading from the stream until it reaches the end of the line.
&lt;/pre&gt;
&lt;p&gt;有三种情况这个函数返回:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;读到1行&lt;/li&gt;
&lt;li&gt;读到eof&lt;/li&gt;
&lt;li&gt;读到(length-1) 字节&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id8"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id25"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;看实现&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="id9"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id26"&gt;4.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fgets&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;implement of fgets hphp/runtime/ext/ext_file.cpp&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Variant f_fgets(const Resource&amp;amp; handle, int64_t length /* = 0 */) {
  if (length &amp;lt; 0) {
    throw_invalid_argument(&amp;quot;length (negative): %&amp;quot; PRId64, length);
    return false;
  }
  CHECK_HANDLE(handle, f);
  String line = f-&amp;gt;readLine(length);
  if (!line.isNull()) {
    return line;
  }
  return false;
}
&lt;/pre&gt;
&lt;p&gt;hphp/runtime/base/file.cpp:readLine:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1   String File::readLine(int64_t maxlen /* = 0 */) {
2     size_t current_buf_size = 0;
3     size_t total_copied = 0;
4     char *ret = nullptr;
5     for (;;) {
6       int64_t avail = bufferedLen();
7       if (avail &amp;gt; 0) {
8         int64_t cpysz = 0;
9         bool done = false;
10
11        char *readptr = m_buffer + m_readpos;
12        const char *eol;
13        const char *cr;
14        const char *lf;
15        cr = (const char *)memchr(readptr, '\r', avail);
16        lf = (const char *)memchr(readptr, '\n', avail);
17        if (cr &amp;amp;&amp;amp; lf != cr + 1 &amp;amp;&amp;amp; !(lf &amp;amp;&amp;amp; lf &amp;lt; cr)) {
18          /* mac */
19          eol = cr;
20        } else if ((cr &amp;amp;&amp;amp; lf &amp;amp;&amp;amp; cr == lf - 1) || (lf)) {
21          /* dos or unix endings */
22          eol = lf;
23        } else {
24          eol = cr;
25        }
26
27        if (eol) {
28          cpysz = eol - readptr + 1;
29          done = true;
30        } else {
31          cpysz = avail;
32        }
33        if (maxlen &amp;gt; 0 &amp;amp;&amp;amp; maxlen &amp;lt;= cpysz) {
34          cpysz = maxlen;
35          done = true;
36        }
37
38        current_buf_size += cpysz + 1;
39        if (ret) {
40          ret = (char *)realloc(ret, current_buf_size);
41        } else {
42          ret = (char *)malloc(current_buf_size);
43        }
44        memcpy(ret + total_copied, readptr, cpysz);
45
46        m_position += cpysz;
47        m_readpos += cpysz;
48        maxlen -= cpysz;
49        total_copied += cpysz;
50
51        if (done) {
52          break;                              ////////////////////////// 1: eol 或者读到了maxlen
53        }
54      } else if (eof()) {
55        break;                                /////////////////////////  2: eof
56      } else {
57        if (m_buffer == nullptr) {
58          m_buffer = (char *)malloc(CHUNK_SIZE);
59          m_bufferSize = CHUNK_SIZE;
60        }
61        m_writepos = filteredReadToBuffer();
62        m_readpos = 0;
63        if (bufferedLen() == 0) {
64          break;                              /////////////////////////  3: 一次读返回空.
65        }
66      }
67    }
68
69    if (total_copied == 0) {
70      assert(ret == nullptr);
71      return String();
72    }
73
74    ret[total_copied] = '\0';
75    return String(ret, total_copied, AttachString);
76  }
&lt;/pre&gt;
&lt;p&gt;看这个长函数, 有几个情况会返回, 我在代码中标了1, 2, 3. 根据fgets的定义, 1,2两处返回是合理的, 3不应该返回, 而应该继续读, 这就是 &lt;strong&gt;fgets的bug&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这个函数的另一个问题是, 如果一个socket上发来 &lt;tt class="docutils literal"&gt;abc\r\n&lt;/tt&gt;, 但是一次读只读到 &lt;tt class="docutils literal"&gt;abc\r&lt;/tt&gt; 的时候, 它就会返回以 &lt;tt class="docutils literal"&gt;\r&lt;/tt&gt; 结尾的一行, 这个问题, Redis.php已经针对它做了专门的适配, 这里不讨论:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
protected function sockReadLine() {
  if (!$this-&amp;gt;checkConnection()) {
    return false;
  }
  $line = fgets($this-&amp;gt;connection);
  if (substr($line, -2) == &amp;quot;\r\n&amp;quot;) {
    $line = substr($line, 0, -2);
  } else if (substr($line, -1) == &amp;quot;\r&amp;quot;) {             //就是这里.
    $line = substr($line, 0, -1);
    $lf = fgetc($this-&amp;gt;connection);
    if ($lf === false) {
      // A response must terminate with both CR and LF. Refuse to guess.
      return false;
    } else if ($lf !== &amp;quot;\n&amp;quot;) {
      throw new RedisException(&amp;quot;Protocol error: CR not followed by LF&amp;quot;);
    }
  }

  return $line;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="readimpl"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id27"&gt;4.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;readImpl&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;上面的readLine会调用filteredReadToBuffer 来read more bytes, 实际上就是调用readImpl(), 下面我们分析readImpl可能返回空的情况:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int64_t File::filteredReadToBuffer() {
  int64_t bytes_read = readImpl(m_buffer, CHUNK_SIZE);
  if (LIKELY(m_readFilters.empty())) {
    return bytes_read;
  }
&lt;/pre&gt;
&lt;p&gt;readImpl for Socket: hphp/runtime/base/socket.cpp::readImpl:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1   int64_t Socket::readImpl(char *buffer, int64_t length) {
2     assert(m_fd);
3     assert(length &amp;gt; 0);
4
5     IOStatusHelper io(&amp;quot;socket::recv&amp;quot;, m_address.c_str(), m_port);
6
7     int recvFlags = 0;
8     if (m_timeout &amp;gt; 0) {
9       int flags = fcntl(m_fd, F_GETFL, 0);  // ning: we will get into this.
10      if ((flags &amp;amp; O_NONBLOCK) == 0) {
11        if (!waitForData()) {
12          m_eof = true;
13          return 0;
14        }
15        recvFlags = MSG_DONTWAIT; // polled, so no need to wait any more
16      }
17    }
18
19    int64_t ret = recv(m_fd, buffer, length, recvFlags);
20    if (ret == 0 || (ret == -1 &amp;amp;&amp;amp; errno != EWOULDBLOCK)) {
21      m_eof = true;
22    }
23    return (ret &amp;lt; 0) ? 0 : ret;
24  }
25
26  bool Socket::waitForData() {
27    m_timedOut = false;
28    while (true) {
29      struct pollfd fds[1];
30      fds[0].fd = m_fd;
31      fds[0].events = POLLIN|POLLERR|POLLHUP;
32      if (poll(fds, 1, m_timeout / 1000)) {
33        socklen_t lon = sizeof(int);
34        int valopt;
35        getsockopt(m_fd, SOL_SOCKET, SO_ERROR, (void*)(&amp;amp;valopt), &amp;amp;lon);
36        if (valopt == EINTR) continue;
37        return valopt == 0;
38      } else {
39        m_timedOut = true;
40        return true;
41      }
42    }
43    return false;
44  }
&lt;/pre&gt;
&lt;p&gt;Socket::readImpl 会进入11行的waitForData函数(从strace结果看, 这里m_timeout是设为100*1000的):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
recvfrom(7, 0x7fff5be32f00, 1, 66, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
fcntl(7, F_GETFL)                       = 0x2 (flags O_RDWR)
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP, revents=POLLIN}], 1, 100) = 1
&lt;/pre&gt;
&lt;p&gt;我们可以先不管m_timeout怎么设置的, 这个值设为多大, 或者设为0, 都不影响分析, 看waitForData函数, 如果poll超时后没有收到事件, 就会设置m_timedOut=true, 并且return true.&lt;/p&gt;
&lt;p&gt;所以此时 readImpl 进入 19行recv, 明显是返回 EAGAIN 的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
poll([{fd=7, events=POLLIN|POLLERR|POLLHUP}], 1, 100) = 0
recvfrom(7, 0x7f3a3d9e2000, 8192, 64, 0, 0) = -1 EAGAIN (Resource temporarily unavailable)
&lt;/pre&gt;
&lt;p&gt;EAGAIN就是EWOULDBLOCK, 所以这里没有进入21行, 而是进入23行, 返回 &lt;tt class="docutils literal"&gt;ret = 0&lt;/tt&gt; .&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id28"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;所以, 这应该认为是 &lt;a class="reference external" href="File::readLine"&gt;File::readLine&lt;/a&gt; 的一个bug, 建议的修改是这样:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git diff
diff --git a/hphp/runtime/base/file.cpp b/hphp/runtime/base/file.cpp
index b180301..3d216bd 100644
--- a/hphp/runtime/base/file.cpp
+++ b/hphp/runtime/base/file.cpp
&amp;#64;&amp;#64; -611,9 +611,9 &amp;#64;&amp;#64; String File::readLine(int64_t maxlen /* = 0 */) {
       }
       m_writepos = filteredReadToBuffer();
       m_readpos = 0;
-      if (bufferedLen() == 0) {
-        break;
-      }
+      //if (bufferedLen() == 0) {
+        //break;
+      //}
     }
   }
&lt;/pre&gt;
&lt;p&gt;这需要重新编译hhvm, 所以我没有测试.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="hang"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id29"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;模拟hang住的情况&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最后, 知道bug的原因, 怎么模拟hang住呢, 我们需要构造合法的返回, 被这个bug的解析代码解析认为符合协议, 同时又解析出错。&lt;/p&gt;
&lt;p&gt;因为fgets在server端sleep 200ms 的时候就会返回当前已经读到的 部分, 构造如下response:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$10\r\n$123456789\r\n
  ^
  |
  返回 '$1' 后sleep, 此时client读到 '$1' 认为是读到了一行, 并且认为这个response的阵阵大小是1, 接下来读到 '0\r\n', 所以client 会认为服务器返回了 '0' 这个长度为1的字符串.
  接下来, 下一个get请求来的时候, 会读到 ``$123456789\r\n`` 这一行, 它会认为这个response有123456789这么多字节, 就会一致尝试去读, 当然就一直hang住了.
&lt;/pre&gt;
&lt;p&gt;模拟这个响应的代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def handle_get(self, argv):
    key = argv[1]
    if key == 'special-key-for-hhvm':

        # $10\r\n$123456789\r\n
        self.request.sendall('$1')
        time.sleep(.15)
        self.request.sendall('0\r\n$123456789\r\n')

    elif key in store:
        self.reply_bulk(store[key])
    else:
        self.reply_bulk(None)
&lt;/pre&gt;
&lt;p&gt;这是一个完全合法的get请求的response, 表达的值为 '$123456789', 客户端测试代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$r = new Redis();

$conn = $r-&amp;gt;connect('127.1', 9999, 0.1 );

$t = $r-&amp;gt;get('special-key-for-hhvm');
var_dump($t);
$t = $r-&amp;gt;get('special-key-for-hhvm');
var_dump($t);

$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
string(1) &amp;quot;0&amp;quot;
--- 这里hang住
[Wed Sep 10 11:37:39 2014] [hphp] [52895:7ffc15e5c340:0:000001] []
Fatal error: Maximum execution time of 30 seconds exceeded
&lt;/pre&gt;
&lt;p&gt;使用修改了 &lt;tt class="docutils literal"&gt;sockReadLine&lt;/tt&gt; 后的NRedis代码, 就ok:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ strace -oa.txt hhvm_backend/bin/hhvm_backend -c hhvm_backend/conf/hhvm.conf c.php
string(10) &amp;quot;$123456789&amp;quot;
string(10) &amp;quot;$123456789&amp;quot;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id30"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;fgets有bug, 修复方法参考正文&lt;/li&gt;
&lt;li&gt;Redis类最好不要用有bug的fgets代码, 自己实现一个sockReadLine即可.&lt;/li&gt;
&lt;li&gt;不排除server端(redis/twemproxy) 也有类似bug的可能性.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id31"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;更新&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;fgets其实没有bug, hhvm在这里的行为和php是一致的, 就是:&lt;/p&gt;
&lt;p&gt;超时后返回已读到的部分, 实际上, 这时候应该通过stream_get_meta_data() 获取是否超时信息:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$conn = fsockopen('127.1', 9999, $errno, $errstr, 0.1);
//$conn = fsockopen('127.1', 9999);

fwrite($conn, &amp;quot;*3\r\n$3\r\nSET\r\n$1\r\nk\r\n$1\r\nv\r\n&amp;quot;);
$r = fgets($conn);
var_dump($r);

fwrite($conn, &amp;quot;*2\r\n$3\r\nGET\r\n$1\r\nk\r\n&amp;quot;);

$r = fgets($conn);
var_dump($r);
$info = stream_get_meta_data($conn);
var_dump($info);


$r = fgets($conn);
var_dump($r);
$info = stream_get_meta_data($conn);
var_dump($info);
&lt;/pre&gt;
&lt;p&gt;输出如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
string(1) &amp;quot;+&amp;quot;
string(1) &amp;quot;O&amp;quot;
array(10) {
  ...
  [&amp;quot;timed_out&amp;quot;]=&amp;gt;
  bool(true)
  [&amp;quot;eof&amp;quot;]=&amp;gt;
  bool(false)
  [&amp;quot;wrapper_data&amp;quot;]=&amp;gt;
  NULL
}
string(1) &amp;quot;K&amp;quot;
array(10) {
  [&amp;quot;timed_out&amp;quot;]=&amp;gt;
  bool(true)
  [&amp;quot;blocked&amp;quot;]=&amp;gt;
  bool(false)
  [&amp;quot;eof&amp;quot;]=&amp;gt;
  bool(false)
  [&amp;quot;wrapper_data&amp;quot;]=&amp;gt;
  NULL
}
&lt;/pre&gt;
&lt;p&gt;接口会输出timeout.&lt;/p&gt;
&lt;p&gt;所以fgets应该认为没bug, 修改Redis库即可.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>Redis/MySQL/MongoDB replication分析</title><link href="/replication.html" rel="alternate"></link><updated>2014-08-20T10:07:08+08:00</updated><author><name>ning</name></author><id>tag:,2014-08-20:replication.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id15"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;幂等&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis" id="id16"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mysql-binlog" id="id17"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql binlog格式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mongo" id="id18"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id19"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;推/拉&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id20"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mysql" id="id21"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id22"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#oplog" id="id23"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;如何索引oplog&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id24"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id25"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mysql5-6-gtid" id="id26"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql5.6 GTID&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id27"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#failover" id="id28"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;failover&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id29"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id30"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id31"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;第一个问题:&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mysql-5-6" id="id32"&gt;4.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql 5.6以前&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mysql-gtid" id="id33"&gt;4.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql GTID&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id34"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;第二个问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id35"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id36"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id14" id="id37"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;参考:&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#gtid" id="id38"&gt;6.1&amp;nbsp;&amp;nbsp;&amp;nbsp;关于GTID&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;replication 这个问题, 包括同步和failover两个方面:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;如何保存oplog &amp;amp; 如何实现同步.&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;oplog是否幂等&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;存操作: 不幂等(mysql 的binlog STATEMENT模式, redis的aof)&lt;/li&gt;
&lt;li&gt;存结果: (MySQL binlog ROW模式)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;同步是master主动还是slave主动?&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;master主动推&lt;/li&gt;
&lt;li&gt;slave主动拉&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;怎么索引一条oplog&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;常见三种方法:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;时间ts(mongo)&lt;/li&gt;
&lt;li&gt;字节数(redis/mysql)&lt;/li&gt;
&lt;li&gt;idx&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;这个问题其实涉及到发生主从切换后, 老主继续同步的问题.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;假设A=&amp;gt;master, B=&amp;gt;slave, 如果A挂掉, 发生主从切换, B变成主,&lt;/li&gt;
&lt;li&gt;等A恢复后, A如何找到从B的什么位置去同步.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;如何failover.&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;master挂了之后, 如何选择新的master.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;master挂了又回来后的一致性问题&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;还是刚才的例子, 假设A=&amp;gt;master, B=&amp;gt;slave, 如果A挂掉, 发生主从切换, A上面的写是比B新的,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;当A恢复后, A再去找B同步时, A上多余的数据, 怎么办.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;对redis来说, 这时候A会从B做一次全量同步, 从而保证一致&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;关于一致性, 我们可以看这个例子:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
-------------------------------------------------------------

   +-------+        +-------+
   |   A   |        |   B   |
   +-------+        +-------+

t1 insert 1 --\
      |        \
t2 insert 2 --\ \-- insert 1
      |        \
t3 insert 3 --\ \-- insert 2
      |        \
t4 insert 4     \-- insert 3
--------------------------------&amp;gt; A down, B is master now

t5              /-- insert 5
               /       |
t6 insert 5 --/ /-- insert 6
               /
t7 insert 6 ---

#到这里, 我们已经看到了不一致:

1,2,3,4,5,6          1,2,3,5,6
&lt;/pre&gt;
&lt;p&gt;接下来我们从这几个方面, 研究redis/mysql/mongo如何实现&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id15"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;幂等&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="redis"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id16"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;redis 的主从同步和aof记录的都是操作, 而不是结果, 也就是非幂等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;这造成重放aof时不可重入.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;仔细考虑, redis这样的设计是对的, 因为redis支持set, hash, list等数据结构.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;以list为例&lt;/li&gt;
&lt;li&gt;list push操作转化为幂等aof需要将整个list记录到aof中, 这太浪费了.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="mysql-binlog"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql binlog格式&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;关于格式&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;三种格式&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;STATEMENT-BASED format&lt;/li&gt;
&lt;li&gt;ROW-BASED format&lt;/li&gt;
&lt;li&gt;mised: 是上面两种的混合.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;STATEMENT模式记录操作, ROW模式记录结果.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;考虑下面一些不同场景:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;每个sql操作从索引命中一条, 并更新这一条中一个字段:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;如果使用ROW模式, 每次要记录整个行, 较大, 在从库上插入也较慢, 所以会导致跟不上同步.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;如果一个sql操作很多条记录 update xxx while x &amp;gt; 10 , 或者改表(alter)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;ROW: 产生很多条binlog&lt;/li&gt;
&lt;li&gt;STATEMENT: 只有一条binlog&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;一个sql需要扫描很多条, 最后才更新一条(比如不能命中索引), 然后更新.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;如果用STATEMENT模式, 着一个操作在从库上执行也会慢.&lt;/li&gt;
&lt;li&gt;如果用ROW模式, 就很快.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;一般来说, mixed性能可能更好, 多数都是用mixed模式.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;存在问题(jira报的一些bug):&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;tt class="docutils literal"&gt;INSERT DELAYED ... &lt;span class="pre"&gt;VALUES(LAST_INSERT_ID())&lt;/span&gt;&lt;/tt&gt; inserts a different value on the master and the slave. (Bug #20819)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;This is fixed in MySQL 5.1 when using row-based or mixed-format binary logging.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Adding an AUTO_INCREMENT column to a table with ALTER TABLE might not produce the same ordering of the rows on the slave and the master&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Replication of LIMIT clauses in DELETE, UPDATE, and INSERT ... SELECT statements is not guaranteed, since the order of the rows affected is not defined. Such statements can be replicated correctly only if they also contain an ORDER BY clause.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;应该是 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;STATEMENT-BASED&lt;/span&gt;&lt;/tt&gt; 格式有这个问题, &lt;tt class="docutils literal"&gt;ROW&lt;/tt&gt; 格式应该没有这个问题.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;不像redis那样全量同步数据, 很难避免这些问题.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体保存方法:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;多个文件, 每次启动或者写满一个max_binlog_size, 就新开一个.&lt;/li&gt;
&lt;li&gt;binlog index文件, 记录当前哪些binlog文件在使用.&lt;/li&gt;
&lt;li&gt;PURGE BINARY LOGS命令用于清除binlog&lt;/li&gt;
&lt;li&gt;binlog也可以自动清理, &lt;tt class="docutils literal"&gt;expire_logs_days&lt;/tt&gt; .&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="literal-block"&gt;
shell&amp;gt; mysqlbinlog binlog.0000003
The output includes events contained in binlog.000003. Event information includes the SQL statement, the ID of the server on which it was executed, the timestamp when the statement was executed, how much time it took, and so forth.

Events are preceded by header comments that provide additional information. For example:

# at 141
#100309  9:28:36 server id 123  end_log_pos 245
  Query thread_id=3350  exec_time=11  error_code=0
In the first line, the number following at indicates the file offset, or starting position, of the event in the binary log file.

The second line starts with a date and time indicating when the statement started on the server where the event originated. For replication, this timestamp is propagated to slave servers. server id is the server_id value of the server where the event originated. end_log_pos indicates where the next event starts (that is, it is the end position of the current event + 1). thread_id indicates which thread executed the event. exec_time is the time spent executing the event, on a master serve
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="mongo"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;mongo 是记录记录结果, 幂等.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id19"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;推/拉&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id20"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;slave通过sync命令连上来后, master 每次做完一个写操作, 就会 调用replicationFeedSlaves, 向这个socket 发送命令&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;这个机制和 monitor一样:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;replicationFeedMonitors 方法是把cmd通过一定的格式把命令发到monitor客户端.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;也就是说, 是master主动推到slave&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="mysql"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id21"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;slave 来拉&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;slave pulls the data from the master, rather than the master pushing the data to the slave&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;好处是: slave可以随时决定停止或重启repl, slave可以决定用什么样的速度.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;三个线程&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;master:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Binlog Dump线程: slave连上来时启动, 加锁读binlog, 读完释放锁.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;slave:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;slave IO线程: 从master读取, 写到slave's relay log&lt;/li&gt;
&lt;li&gt;slave SQL 线程: 从relay log 读, apply&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;slave拉&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;mongo的oplog里面是带时间戳的, 从库来同步的时候, 相当于: 找到这个时间点后的更新序列.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;主库上的一个操作oplog的time为t1, 同步到丛库上后, 丛库oplog的time应该也是t1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;而redis, mysql 的同步都是用一个位置来记录, 比如redis是一个offset, mysql是file + pos&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;用时间戳 的好处:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;从库不需要像mysql一样, 开一个文件来记录 当前同步到了主库的哪条oplog, 只需要记录 每条记录的ts, ts在主库和从库上是一样的.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="oplog"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id23"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;如何索引oplog&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id24"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;repl_backlog用字节数做索引:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
+------------------------------------------------+
|                                                |
|                                                |
+------------------------------------------------+
                           ^                     ^
                           |                     |
                           |                     |
                           repl_backlog_idx      repl_backlog_size

feed 10个byte::

+------------------------------------------------+
|                                                |
|                                                |
+------------------------------------------------+
                                      ^          ^
                                      |          |
                                      |          |
                                      idx        repl_backlog_size
&lt;/pre&gt;
&lt;p&gt;客户端连上后, 通过 &lt;tt class="docutils literal"&gt;addReplyReplicationBacklog&lt;/tt&gt; 发送backlog:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* Feed the slave 'c' with the replication backlog starting from the
 * specified 'offset' up to the end of the backlog. */
long long addReplyReplicationBacklog(redisClient *c, long long offset) {
&lt;/pre&gt;
&lt;p&gt;s和m之间有一个runid 来确认, 上次是从它开始同步的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int masterTryPartialResynchronization(redisClient *c) {
&lt;/pre&gt;
&lt;p&gt;如果master收到slave的sync命令, 要求的runid和master不同, 或者要求的oplog不在当前oplog范围内, 都要求客户端做全量同步.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id25"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;mysql 5.6以前, 主从同步依赖于每个mysql 实例的binlog file 和binlog pos(用binlog-file + binlog-pos作为索引)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="mysql5-6-gtid"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id26"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql5.6 GTID&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;mysql 5.6 开始的GTID方案.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;一个binlog在master和所有slave上都有一个全局唯一的ID&lt;/li&gt;
&lt;li&gt;由GTID索引.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id27"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;mongo的做法其实类似于GTID.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;mongo里面每个oplog都有一个ts子段, 它的值为写操作发生的时间戳 + 秒内自增id.&lt;/li&gt;
&lt;li&gt;mongo主从同步逻辑保证在一个replset中, 一个操作的ts保持不变.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="failover"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id28"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;failover&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;假设这样一个场景:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
.  A
 / | \
B  C  D
&lt;/pre&gt;
&lt;p&gt;A是主库, BCD是丛库, A机器宕机后, 我们决定B成为新的主库:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
.  B
   | \
   C  D
&lt;/pre&gt;
&lt;p&gt;这里涉及第一个问题:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
问题一: 如何从三个丛库B, C, D里面选择B作为新的master
&lt;/pre&gt;
&lt;p&gt;我们考虑 主从切换后, 老主重新成为从库时的行为, 当A复活后, 我们希望把A挂回去, 这时候存在第二个问题:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
问题二: A上可能有领先于BCD的数据, 如何让A和BCD上数据一致
&lt;/pre&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;最简单的做法是全量同步, 如redis/ledisdb, 实现简单, 但是太慢, 网卡打满等问题, 对于磁盘存储的数据来说, 不可接受&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;较好的办法是让A挂回去后, 利用已有数据, 从B继续同步, 这存在两个问题&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;A上领先的数据怎么办?&lt;/li&gt;
&lt;li&gt;A挂回去后, 从B的什么位置开始继续同步?&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id29"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;而redis的同步是用一个位置来记录(offset)&lt;/li&gt;
&lt;li&gt;不保证主从上offset一致&lt;/li&gt;
&lt;li&gt;slave上记录同步到主的什么offset, 网络瞬断后可以继续.&lt;/li&gt;
&lt;li&gt;如果发生主从切换, 全量同步.&lt;/li&gt;
&lt;li&gt;全量同步,  所以不存在第二个问题.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id30"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id10"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id31"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;第一个问题:&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="mysql-5-6"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id32"&gt;4.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql 5.6以前&lt;/a&gt;&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;mysql 5.6以前, 主从同步依赖于每个mysql 实例的binlog file 和binlog pos&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;发生主从切换时,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;通常BCD上都已经把A的binlog读到本地, 保存为relaylog&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这种情况下, 可以等待BCD都apply完本地的relaylog, 这样数据就达到一个一致的点, 可以从BCD上随便选一个作为新的master&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;如果BCD上没有把binlog都拉到本地.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;需要通过人工找到同步点, 即找到B,C,D上哪个的binlog/relaylog最新.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;假设我们找到B的binlog最新, 在通过下面命令继续令CD向B同步:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
stop slave;
change master to master_host='',master_port=,master_user='',master_password='',master_log_file='',master_log_pos=;
start slave;
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;至于如何找到这个同步点, 有很多方法, 不过目前基本都是靠人工, 依靠DBA的经验,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;MHA貌似也能实现&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="mysql-gtid"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id33"&gt;4.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql GTID&lt;/a&gt;&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;mysql 5.6 开始的GTID方案.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;针对上面这个问题(可运维性差), mysql设计了GTID, 保证同一个事务, 在一个主从结构中的log_idx是一致的.&lt;/li&gt;
&lt;li&gt;这样发生主从切换时, 只需要从BCD上找到GTID最新的一个binlog, 作为新的master.&lt;/li&gt;
&lt;li&gt;之后CD只需要知道自己最后一条binlog的GTID, 然后到B上去找这个GTID之后的binlog同步过来即可.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id34"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;第二个问题&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;当A又加回来后，无论是使用人工找同步点, 还是GTID自动找点. 都可能出现A领先于B的情况(A上的数据没有被同步到B)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;这时候可以有2个办法:&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;让A全量重新同步, 达成一致.&lt;/li&gt;
&lt;li&gt;把A上多余的数据人工补充到B(这需要人工操作, 操作的结果很难保证一致)&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id35"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;mongo&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;通过rollback, 把A上多余的数据删掉/rollback, 达到于BCD一致的状态&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;参看notes/mongo/rollback.rst&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;mongo的做法其实类似于GTID.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;mongo里面每个oplog都有一个ts子段, 它的值为写操作发生的时间戳 + 秒内自增id.&lt;/li&gt;
&lt;li&gt;mongo主从同步逻辑保证在一个replset中, 一个操作的ts保持不变.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;关于A上领先的数据, mongo会通过一个回滚机制&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;把A上多余的数据删掉/rollback, 达到于BCD一致的状态&lt;/li&gt;
&lt;li&gt;参看notes/mongo/rollback.rst&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id13"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id36"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;我们从推拉模式, binlog格式, 如何发生主从切换来考察&lt;/p&gt;
&lt;pre class="literal-block"&gt;
-               mysql           redis       mongo       hadooop
模式            推              推          拉          推.
格式            row/statement   statement   row         ?
主从切换机制    人肉            sentinel    选举        ?
主从切换        人肉找点/       全量同步    自动GTID    ?
后如何继续同步  用GTID同步
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;在mysql这样复杂, 操作丰富的数据库里面实现binlog同步有很多难点, 比如LAST_INSERT_ID() 等.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;oplog记录操作和记录结果, 各有好处.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;failover时的一致性问题有很多解决方法&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;忽略&lt;/li&gt;
&lt;li&gt;重做&lt;/li&gt;
&lt;li&gt;rollback.&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id14"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id37"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;参考:&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://dev.mysql.com/doc/internals/en/binary-log.html"&gt;http://dev.mysql.com/doc/internals/en/binary-log.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://dev.mysql.com/doc/refman/5.0/en/replication-features.html"&gt;http://dev.mysql.com/doc/refman/5.0/en/replication-features.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://dev.mysql.com/doc/refman/5.1/en/mysqlbinlog-row-events.html"&gt;http://dev.mysql.com/doc/refman/5.1/en/mysqlbinlog-row-events.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;淘宝, 主库自动切换 &lt;a class="reference external" href="http://www.slideshare.net/mysqlops/ss-9183821"&gt;http://www.slideshare.net/mysqlops/ss-9183821&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;mysql5.6 GTID: &lt;a class="reference external" href="http://dev.mysql.com/doc/refman/5.6/en/replication-gtids.html"&gt;http://dev.mysql.com/doc/refman/5.6/en/replication-gtids.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GTID 简介: &lt;a class="reference external" href="http://mysqllover.com/?p=87"&gt;http://mysqllover.com/?p=87&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="gtid"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id38"&gt;6.1&amp;nbsp;&amp;nbsp;&amp;nbsp;关于GTID&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;GTID的全称为 global transaction identifier  ， 可以翻译为全局事务标示符，GTID在原始master上的事务提交时被创建。GTID需要在全局的主-备拓扑结构中保持唯一性，GTID由两部分组成：&lt;/p&gt;
&lt;p&gt;A global transaction identifier (GTID) is a unique identifier created and associated with each transaction committed on the server of origin (master). This identifier is unique not only to the server on which it originated, but is unique across all servers in a given replication setup. There is a 1-to-1 mapping between all transactions and all GTIDs.&lt;/p&gt;
&lt;p&gt;GTID = source_id:transaction_id&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;source_id用于标示源服务器，用server_uuid来表示，这个值在第一次启动时生成，并写入到配置文件data/auto.cnf中&lt;/li&gt;
&lt;li&gt;transaction_id则是根据在源服务器上第几个提交的事务来确定。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个GTID的生命周期包括：
1.事务在主库上执行并提交
给事务分配一个gtid（由主库的uuid和该服务器上未使用的最小事务序列号），该GTID被写入到binlog中。
2.备库读取relaylog中的gtid，并设置session级别的gtid_next的值，以告诉备库下一个事务必须使用这个值
3.备库检查该gtid是否已经被其使用并记录到他自己的binlog中。slave需要担保之前的事务没有使用这个gtid，也要担保此时已分读取gtid，但未提交的事务也不恩呢过使用这个gtid.
4.由于gtid_next非空，slave不会去生成一个新的gtid，而是使用从主库获得的gtid。这可以保证在一个复制拓扑中的同一个事务gtid不变。&lt;/p&gt;
&lt;p&gt;支持启用GTID，对运维人员来说应该是一件令人高兴的事情，在配置主从复制，传统的方式里，你需要找到binlog和POS点，然后change master to指向，而不是很有经验的运维，往往会将其找错，造成主从同步复制报错，在mysql5.6里，无须再知道binlog和POS点，需要知道master的IP、端口，账号密码即可，因为同步复制是自动的，mysql通过内部机制GTID自动找点同步。&lt;/p&gt;
&lt;pre class="literal-block"&gt;
mysql&amp;gt; show slave status\G
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: 192.168.18.201
                  Master_User: repluser
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: master-bin.000001
          Read_Master_Log_Pos: 151
               Relay_Log_File: relay-log.000002
                Relay_Log_Pos: 363
        Relay_Master_Log_File: master-bin.000001
             Slave_IO_Running: Yes  #IO线程与SQL线程都是yes，说明复制启动完成。
            Slave_SQL_Running: Yes
              Replicate_Do_DB:
          Replicate_Ignore_DB:
           Replicate_Do_Table:
       Replicate_Ignore_Table:
      Replicate_Wild_Do_Table:
  Replicate_Wild_Ignore_Table:
                   Last_Errno: 0
                   Last_Error:
                 Skip_Counter: 0
          Exec_Master_Log_Pos: 151
              Relay_Log_Space: 561
              Until_Condition: None
               Until_Log_File:
                Until_Log_Pos: 0
           Master_SSL_Allowed: No
           Master_SSL_CA_File:
           Master_SSL_CA_Path:
              Master_SSL_Cert:
            Master_SSL_Cipher:
               Master_SSL_Key:
        Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No
                Last_IO_Errno: 0
                Last_IO_Error:
               Last_SQL_Errno: 0
               Last_SQL_Error:
  Replicate_Ignore_Server_Ids:
             Master_Server_Id: 1
                  Master_UUID: 6b27d8b7-0e14-11e3-9eab-000c291192e4
             Master_Info_File: mysql.slave_master_info
                    SQL_Delay: 0
          SQL_Remaining_Delay: NULL
      Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it
           Master_Retry_Count: 86400
                  Master_Bind:
      Last_IO_Error_Timestamp:
     Last_SQL_Error_Timestamp:
               Master_SSL_Crl:
           Master_SSL_Crlpath:
           Retrieved_Gtid_Set:
            Executed_Gtid_Set:
                Auto_Position: 1
1 row in set (0.00 sec)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>ssdb-benchmark</title><link href="/ssdb-benchmark.html" rel="alternate"></link><updated>2014-08-13T14:48:03+08:00</updated><author><name>ning</name></author><id>tag:,2014-08-13:ssdb-benchmark.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hdd" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;hdd 测试结果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ssd" id="id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 测试结果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#leveldb" id="id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB的问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;关于读性能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id8"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;改进&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id9"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;注意&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;因为小规模benchmark时文件都被cache, IO访问其实只有内存操作而已, 所以测试数据只能说明系统在基本无IO操作时的处理能力.&lt;/p&gt;
&lt;p&gt;为了避免文件被cache, 可以减少机器空闲内存, 或者使操作的数据集远大于内存, 我们的测试机内存64G, 所以测试时, 我们使用大约100G的数据集来进行测试.&lt;/p&gt;
&lt;p&gt;benchmark场景:&lt;/p&gt;
&lt;p&gt;先写, 后读, 采集的数据包括:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;qps随时间的变化&lt;/li&gt;
&lt;li&gt;进程内存, cpu占用,&lt;/li&gt;
&lt;li&gt;磁盘读写带宽, r/s, w/s, await, %util,&lt;/li&gt;
&lt;li&gt;磁盘占用量.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为此, 写了这样一个程序用于benchmark和记录结果:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
...
class LoadThread(threading.Thread):
    def run(self):
        global g_qps
        num = 1000000000
        #num = 100000
        cmd = 'redis-benchmark  -p 8888 -t set -n %s -r 100000000000 -d 100' % num
        p = Popen(cmd, shell=True, stdout=PIPE, bufsize=1024)

        for line in iter(lambda: p.stdout.readline(), ''):
            line = str(line).strip()
            #print(&amp;quot;&amp;gt;&amp;gt;&amp;gt; &amp;quot; + line)
            if line.startswith('SET'):
                g_qps = line.split()[1]

        cmd = 'redis-benchmark  -p 8888 -t get -n %s -r 100000000000 -d 100' % num
        p = Popen(cmd, shell=True, stdout=PIPE, bufsize=1024)
        for line in iter(lambda: p.stdout.readline(), ''):
            line = str(line).strip()
            #print(&amp;quot;&amp;gt;&amp;gt;&amp;gt; &amp;quot; + line)
            if line.startswith('GET'):
                g_qps = line.split()[1]
...
&lt;/pre&gt;
&lt;p&gt;代码在此: &lt;a class="reference external" href="https://github.com/idning/iostat-py/blob/master/ssdb-bench/ssdb-bench.py"&gt;https://github.com/idning/iostat-py/blob/master/ssdb-bench/ssdb-bench.py&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="hdd"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;hdd 测试结果&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这个测试是手工完成和记录的, 没有图.&lt;/p&gt;
&lt;p&gt;写:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark  -p 8888 -t set -n 1000000000 -r 100000000000 -d 100
38000
&lt;/pre&gt;
&lt;p&gt;持续写1000000000条, (93G)&lt;/p&gt;
&lt;p&gt;磁盘写带宽持续70M/s左右, 内存使用会上升到10G左右, 低峰会回落, 12核cpu上, cpu占用约30%(4个核占满)&lt;/p&gt;
&lt;p&gt;qps稳定在3.8w/s, 不会随着写数据增多而变差.&lt;/p&gt;
&lt;p&gt;写完之后, 读:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark  -p 8888 -t get -n 1000000000 -r 100000000000 -d 100
60~400
&lt;/pre&gt;
&lt;p&gt;如果能命中热点:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark  -p 8888 -t get -n 1000000000 -r 100000 -d 100
23803.46
&lt;/pre&gt;
&lt;p&gt;初始qps只能达到60/s, 逐渐上升到400/s趋于稳定.&lt;/p&gt;
&lt;p&gt;此时磁盘每秒读请求达到150-300r/s (达到磁盘IOPS极限):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
sda               0.00     0.00  137.00    0.00 12940.00     0.00   188.91     1.08    7.86   6.86  94.00
&lt;/pre&gt;
&lt;p&gt;小结:&lt;/p&gt;
&lt;p&gt;ssdb在hdd上的表现:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;写性能稳定在40000/s左右. 不随着数据集的增大而变差.&lt;/li&gt;
&lt;li&gt;读性能在不能命中热点的情况下, 受限于磁盘的IOPS (400/s)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;hdd上, ssdb适合写多读少的场景.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ssd"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 测试结果&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/dev/sdb1 on /ssd type ext4 (rw,noatime)
mem: 48G
cpu: 12
ssd: Intel SSD 530 480GB, 2.5in SATA  参数: http://ark.intel.com/products/75336/Intel-SSD-530-Series-480GB-2_5in-SATA-6Gbs-20nm-MLC
&lt;/pre&gt;
&lt;p&gt;这块SSD 的性能参数:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Random Read : 48000 IOPS&lt;/li&gt;
&lt;li&gt;Random Write : 80000 IOPS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们实际上是3块ssd做RAID0, fio测试结果:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ sudo fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=1k -size=200G -numjobs=30 -runtime=1000 -group_repor
5.7w/s

$rw=randread
7.3w/s
&lt;/pre&gt;
&lt;p&gt;ssdb测试结果:&lt;/p&gt;
&lt;img alt="" src="/imgs/stat.log.ssdb.0.png" style="width: 800px;" /&gt;
&lt;p&gt;小结&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ssd上写性能稳定在3.8wqps, 不会随着写数据增多而变差, 和hdd差不多,&lt;/li&gt;
&lt;li&gt;读性能稳定在5000qps, 明显好与hdd.&lt;/li&gt;
&lt;li&gt;读性能不够, 只能到5000qps, 而此时ssd上的iops大约 5000-7000/s, 此时util%只能到50%, cpu利用率也上不去, 这里可以优化.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="leveldb"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB的问题&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;LevelDB只有block级别的cache, 所有Key集合是记录在磁盘上, 内存中并没有一个记录key是否存在的hash表或树结构, 所以每次查询, 不管key是否存在, LevelDB都需要到磁盘上去找, 如果block不在缓存中, 就要一层层去找, 是非常耗时的,&lt;/p&gt;
&lt;p&gt;为此, LevelDB增加了bloomfilter支持, 可以过滤掉一些key不存在的情况, 减少对磁盘的访问:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssdb-&amp;gt;options.filter_policy = leveldb::NewBloomFilterPolicy(10);
ssdb-&amp;gt;options.block_cache = leveldb::NewLRUCache(cache_size * 1048576);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;关于读性能&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;benchmark显示 &lt;strong&gt;100G数据&lt;/strong&gt; 时, 读性能稳定在大约5000 qps&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;自己实现了一个单线程的服务ndb对比, 发现读qps存在和SSDB一样的低效问题, 而且更低(2000), 如下图:&lt;/li&gt;
&lt;/ul&gt;
&lt;img alt="" src="/imgs/stat.log.ndbv0.0.png" style="width: 800px;" /&gt;
&lt;p&gt;原因:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;ssdb读的时候并未判断expire, 一个读操作只需要一次LevelDB查询, 所以性能较ndb高.&lt;/li&gt;
&lt;li&gt;ssdb是使用单线程去读(并且没有加锁), IO队列上一次只有一个IO请求, 此时avgqu-sz是0.5,
这样想当于把IO操作串行化了, 根据ssd的基本数据, 平均读延迟是90us左右, 也就是说串行使用最多之能支持 1w/s的读操作, 这和我们测的数据比较接近了.
多线程的读操作应该有利于更好的利用io调度器(几个io请求可以排队, 一起发给磁盘控制器)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;改进&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;修改:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static Command commands[] = {
-       PROC(get, &amp;quot;r&amp;quot;),
+       PROC(get, &amp;quot;rt&amp;quot;),
&lt;/pre&gt;
&lt;p&gt;把读放到多线程里面去做, &lt;strong&gt;性能从5000提到15000&lt;/strong&gt; , 磁盘r/s 达到23000左右, 日志级别改为error后可以达到16000/s&lt;/p&gt;
&lt;p&gt;读没有用Transaction加锁, 所以这时候已经能同时向IO系统发多个IO请求了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int SSDB::get(const Bytes &amp;amp;key, std::string *val) const{
    std::string buf = encode_kv_key(key);
    leveldb::Status s = db-&amp;gt;Get(leveldb::ReadOptions(), buf, val);
    ...
    return 1;
}
&lt;/pre&gt;
&lt;p&gt;调整 &lt;tt class="docutils literal"&gt;READER_THREADS = 10&lt;/tt&gt; 为5, 20, 50, 发现在我的机器上10貌似是个最佳值,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;注意&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;coding for ssd 系列 关于多线程read的观点:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;concurrent read threads can impair the readahead (prefetching buffer) capabilities of SSDs&lt;/li&gt;
&lt;li&gt;A single large read is better than many small concurrent reads
Concurrent random reads cannot fully make use of the readahead mechanism. In addition, multiple Logical Block Addresses may end up on the same chip, not taking advantage or of the internal parallelism.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a class="reference external" href="http://codecapsule.com/2014/02/12/coding-for-ssds-part-5-access-patterns-and-system-optimizations/"&gt;http://codecapsule.com/2014/02/12/coding-for-ssds-part-5-access-patterns-and-system-optimizations/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>reading: coding-for-ssd &amp; implement a kv</title><link href="/coding-for-ssd.html" rel="alternate"></link><updated>2014-07-30T16:58:07+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-30:coding-for-ssd.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#coding-for-ssds" id="id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Coding for SSDs&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-1-introduction-and-table-of-contents" id="id8"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 1: Introduction and Table of Contents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-2-architecture-of-an-ssd-and-benchmarking" id="id9"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 2: Architecture of an SSD and Benchmarking&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ssd" id="id10"&gt;1.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#benchmark" id="id11"&gt;1.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何做benchmark:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-3-pages-blocks-and-the-flash-translation-layer" id="id12"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 3: Pages, Blocks, and the Flash Translation Layer&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id13"&gt;1.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基本操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id14"&gt;1.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;写放大&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#wear-leveling" id="id15"&gt;1.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;wear leveling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#flash-translation-layer-ftl" id="id16"&gt;1.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Flash Translation Layer (FTL)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-4-advanced-functionalities-and-internal-parallelism" id="id17"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 4: Advanced Functionalities and Internal Parallelism&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#trim" id="id18"&gt;1.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;TRIM 命令&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#over-provisioning" id="id19"&gt;1.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;over-provisioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#secure-erase" id="id20"&gt;1.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Secure Erase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#internal-parallelism-in-ssds" id="id21"&gt;1.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Internal Parallelism in SSDs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-5-access-patterns-and-system-optimizations" id="id22"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 5: Access Patterns and System Optimizations&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id23"&gt;1.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;访问模式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#part-6-a-summary-what-every-programmer-should-know-about-solid-state-drives" id="id24"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 6: A Summary – What every programmer should know about solid-state drives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id25"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#implementing-a-key-value-store-felixdb" id="id26"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;Implementing a Key-Value Store(FelixDB)&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#what-are-key-value-stores-and-why-implement-one" id="id27"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1 What are key-value stores, and why implement one?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#using-existing-key-value-stores-as-models" id="id28"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2 Using existing key-value stores as models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#comparative-analysis-of-the-architectures-of-kyoto-cabinet-and-leveldb" id="id29"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3 Comparative Analysis of the Architectures of Kyoto Cabinet and LevelDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#api-design" id="id30"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4 API Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hash-table-implementations" id="id31"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5 Hash table implementations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#implementing-a-memory-efficient-hash-table-stored-on-the-file-system" id="id32"&gt;2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;-6 Implementing a memory-efficient hash table stored on the file system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#memory-management" id="id33"&gt;2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;7 Memory Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#networking" id="id34"&gt;2.8&amp;nbsp;&amp;nbsp;&amp;nbsp;8 Networking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#interfaces-rest-memcached-etc" id="id35"&gt;2.9&amp;nbsp;&amp;nbsp;&amp;nbsp;9 Interfaces: REST, memcached, etc.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#going-further" id="id36"&gt;2.10&amp;nbsp;&amp;nbsp;&amp;nbsp;10 Going further&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id37"&gt;2.11&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id38"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="coding-for-ssds"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Coding for SSDs&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://codecapsule.com/2014/02/12/coding-for-ssds-part-1-introduction-and-table-of-contents/"&gt;http://codecapsule.com/2014/02/12/coding-for-ssds-part-1-introduction-and-table-of-contents/&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="part-1-introduction-and-table-of-contents"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 1: Introduction and Table of Contents&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="part-2-architecture-of-an-ssd-and-benchmarking"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 2: Architecture of an SSD and Benchmarking&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;两种flash:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;NOR flash&lt;/li&gt;
&lt;li&gt;NAND flash (主流)&lt;/li&gt;
&lt;li&gt;寿命有限, Each cell has a maximum number of P/E cycles (Program/Erase)&lt;/li&gt;
&lt;li&gt;高温会导致数据清除.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;存储单元类型:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 bit per cell (single level cell, &lt;strong&gt;SLC&lt;/strong&gt; ),   &lt;tt class="docutils literal"&gt;寿命相对较长&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;2 bits per cell (multiple level cell, &lt;strong&gt;MLC&lt;/strong&gt; ),  &lt;tt class="docutils literal"&gt;成本低&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;3 bits per cell (triple-level cell, &lt;strong&gt;TLC&lt;/strong&gt; ).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MLC/TLC成本较低  目前多数是MLC或TLC, 如果update很多的话, 还是SLC好.&lt;/p&gt;
&lt;div class="section" id="ssd"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id10"&gt;1.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 架构&lt;/a&gt;&lt;/h4&gt;
&lt;img alt="" src="/imgs/ssd_architecture.jpg" style="width: 360px; height: 207px;" /&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;接口主要是  Serial ATA (SATA), PCI Express (PCIe), 现在还有新的SAS.&lt;/li&gt;
&lt;li&gt;通常都有RAM存储(256M+), 用作buffer/cache/map关系等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;厂商给的数字通常是在某种条件下测得的, 不见得能表示真实性能:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
In his articles about common flaws in SSD benchmarking [66], Marc Bevand mentioned that for instance it is common for the IOPS of random write workloads to be reported without any mention of the span of the LBA, and that many IOPS are also reported for queue depth of 1 instead of the maximum value for the drive being tested. There are also many cases of bugs and misuses of the benchmarking tools.

Correctly assessing the performance of SSDs is not an easy task.
&lt;/pre&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;span&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;queue-depth很重要.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;测试时间, 和SSD的size有很大关系:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
the performance of SSDs only drops under a sustained workload of random writes, which depending on the total size of the SSD can take just 30 minutes or up to three hours
&lt;/pre&gt;
&lt;p&gt;如下图, 30min后性能有明显下降:&lt;/p&gt;
&lt;img alt="" src="/imgs/writes_preconditioning.jpg" style="width: 360px; height: 414px;" /&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;原因:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;garbage collection must erase blocks as write commands arrive, therefore competing with the foreground operations from the host,&lt;/li&gt;
&lt;li&gt;GC影响正常流量.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里: &lt;a class="reference external" href="http://www.storagereview.com/samsung_ssd_840_pro_review"&gt;http://www.storagereview.com/samsung_ssd_840_pro_review&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="benchmark"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id11"&gt;1.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何做benchmark:&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The parameters used are generally the following:
- The type of workload: can be a specific benchmark based on data collected from users, or just only sequential or random accesses of the same type (ex: only random writes)
- The percentages of reads and writes performed concurrently (ex: 30% reads and 70% writes)
- The queue length: this is the number of concurrent execution threads running commands on a drive
- The size of the data chunks being accessed (4 KB, 8 KB, etc.)&lt;/p&gt;
&lt;p&gt;结果:
- Throughput (对顺序读写)
- ipos (对随机读写)
- Latancy&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-3-pages-blocks-and-the-flash-translation-layer"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id12"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 3: Pages, Blocks, and the Flash Translation Layer&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;不少概念:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;how writes are handled at the page and block level,&lt;/li&gt;
&lt;li&gt;write amplification&lt;/li&gt;
&lt;li&gt;wear leveling&lt;/li&gt;
&lt;li&gt;Flash Translation Layer (FTL),&lt;/li&gt;
&lt;li&gt;logical block mapping&lt;/li&gt;
&lt;li&gt;garbage collection&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id1"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id13"&gt;1.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基本操作&lt;/a&gt;&lt;/h4&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Reads are aligned on page size (It is not possible to read less than one page at once.)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;和hdd其实一样.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Writes are aligned on page size&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;每次读一个page比较好理解, 每次怎么写一个page??&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;write amplification(写放大)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;写操作不是直接覆盖原来的page, 而是 拷贝这个page到ssd的RAM中, 在RAM中修改, 最后写到一个新的page里面去.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;When data is changed, the content of the page is copied into an internal register, the data is updated, and the new version is stored in a “free” page,  an operation called “read-modify-write”. The data is not updated in-place, as the “free” page is a different page than the page that originally contained the data. Once the data is persisted to the drive, the original page is marked as being “stale”, and will remain as such until it is erased.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Erases are aligned on block size&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;对于write造成的 &lt;tt class="docutils literal"&gt;stale&lt;/tt&gt; 状态的page, 需要一个erase操作, 变成 &lt;tt class="docutils literal"&gt;free&lt;/tt&gt; 状态.&lt;/li&gt;
&lt;li&gt;但是, 又不能Erase单独的一个Page, 只能Erase整个block.&lt;/li&gt;
&lt;li&gt;这些都是由ssd控制器的garbage collection process来处理的, 所以这里有很多各种算法(因为寿命有限, 所以寿命管理也需要复杂算法)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="" src="/imgs/ssd_writing_data.jpg" style="width: 360px; height: 380px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id14"&gt;1.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;写放大&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;写一个字节也会导致整个page的read-modify-write&lt;/p&gt;
&lt;p&gt;应该尽量避免 small write.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="wear-leveling"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id15"&gt;1.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;wear leveling&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;写均衡. 避免总是写同一个page.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="flash-translation-layer-ftl"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id16"&gt;1.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Flash Translation Layer (FTL)&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Flash Translation Layer 是一个地址映射机制, 提供像磁盘一样的逻辑地址.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;logical block mapping&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;一个逻辑地址到page的有映射表.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;This mapping table is stored in the RAM of the SSD for speed of access, and is persisted in flash memory in case of power failure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;When the SSD powers up, the table is read from the persisted version and reconstructed into the RAM of the SSD&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;block-level&lt;/span&gt; mapping&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;page-level&lt;/span&gt; mapping&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;page-level 太费内存. Let’s assume that an SSD drive has 256 pages per block. This means that block-level mapping requires 256 times less memory than page-level mapping&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;block-level 让写放大更加明显&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;which uses an approach similar to log-structured file systems. Incoming write operations are written sequentially to log blocks. When a log block is full, it is merged with the data block associated to the same logical block number (LBN) into a free block&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; 应该是现在ssd写能达到和读一样性能的关键点.&lt;/li&gt;
&lt;li&gt;This allows random writes to be handled like sequential writes.&lt;/li&gt;
&lt;li&gt;但是read requests need to check both the log-block mapping table and the data-block mapping table, 性能损耗应该很小.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;garbage collection.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;做ssd控制器的厂商比较少:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
seven companies are providing controllers for 90% of the solid-state drive market(做ssd的厂商很多, 但是做控制芯片/算法的很少)
&lt;/pre&gt;
&lt;p&gt;Erase: 1500-3500 μs
Write: 250-1500 μs&lt;/p&gt;
&lt;p&gt;A less important reason for blocks to be moved is the read disturb. Reading can change the state of nearby cells, thus blocks need to be moved around after a certain number of reads have been reached [14].&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-4-advanced-functionalities-and-internal-parallelism"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 4: Advanced Functionalities and Internal Parallelism&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="trim"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id18"&gt;1.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;TRIM 命令&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;which can be sent by the operating system to notify the SSD controller that pages are no longer in use in the logical space&lt;/p&gt;
&lt;p&gt;帮助控制器更好的GC.&lt;/p&gt;
&lt;p&gt;The TRIM command will only work if the SSD controller, the operating system, and the filesystem are supporting it.&lt;/p&gt;
&lt;p&gt;Under Linux, support for the ATA TRIM was added in version &lt;tt class="docutils literal"&gt;2.6.33&lt;/tt&gt; .
ext2 and ext3 filesystems do not support TRIM,
&lt;tt class="docutils literal"&gt;ext4&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;XFS&lt;/tt&gt; , among others, do support it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="over-provisioning"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id19"&gt;1.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;over-provisioning&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Over-provisioning is simply having more physical blocks than logical blocks, by keeping a ratio of the physical blocks reserved for the controller and not visible to the user. Most manufacturers of professional SSDs already include some over-provisioning, generally in the order of 7 to 25%&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="secure-erase"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id20"&gt;1.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Secure Erase&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Some SSD controllers offer the ATA Secure Erase functionality&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="internal-parallelism-in-ssds"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id21"&gt;1.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;Internal Parallelism in SSDs&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Due to physical limitations, an asynchronous NAND-flash I/O bus cannot provide more than 32-40 MB/s of bandwidth [5].&lt;/p&gt;
&lt;p&gt;所以实际上, ssd控制器内部有多个芯片, 类似raid那样.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-5-access-patterns-and-system-optimizations"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 5: Access Patterns and System Optimizations&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id3"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id23"&gt;1.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;访问模式&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;在ssd里面, 因为映射关系是动态的, contiguous addresses in the logical space may refer to addresses that are not contiguous in the physical space.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;避免随机small write.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;amall write 实际上需要写整个block. 所以写一个小数据和一个大数据都需要同样的copy-erase-write操作&lt;/li&gt;
&lt;li&gt;需要大量操作映射关系表.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Reads are faster than writes&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;顺序读比随机读throughput好.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;其它优化&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;对齐读写(有比较小的提升)&lt;/li&gt;
&lt;li&gt;打开 TRIM&lt;/li&gt;
&lt;li&gt;IO scheduler, (默认是CFQ,  NOOP or Deadline 会好一些)&lt;/li&gt;
&lt;li&gt;尽量不要用ssd存临时文件或做swap (写次数有限)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-6-a-summary-what-every-programmer-should-know-about-solid-state-drives"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id24"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;Part 6: A Summary – What every programmer should know about solid-state drives&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id25"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;ssd在大量写压力下, 性能可能恶化到8000iops.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;因为很多update, GC可能跟不上, 如果每次写操作需要做一次erase整个block, 就悲剧了.&lt;/li&gt;
&lt;li&gt;正常情况下, GC利用后台的时间, 可以完成erase工作.&lt;/li&gt;
&lt;li&gt;The TRIM command and over-provisioning are two great ways to reduce this effect, and are covered in more details in Sections 6.1 and 6.2.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;写放大, 写一个字节也会导致整个page的read-modify-write&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;应该尽量避免 small write.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;很多ssd会通过hybrid log-block mapping来做写merge. 从而减轻写放大.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;ssd 适合写少, 读多的情况&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们到底要不要避免用small write 呢?&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;如果没用 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; , 明显是要避免small-write.&lt;/li&gt;
&lt;li&gt;如果有 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; 呢? 小的写操作还是没有大的写操作效率高.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="implementing-a-key-value-store-felixdb"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id26"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;Implementing a Key-Value Store(FelixDB)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://codecapsule.com/2012/11/07/ikvs-implementing-a-key-value-store-table-of-contents/"&gt;http://codecapsule.com/2012/11/07/ikvs-implementing-a-key-value-store-table-of-contents/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;July 8, 2014: I am currently implementing the key-value store and will write a post about it when it’s done&lt;/p&gt;
&lt;p&gt;1-4: 作者选了半天名字, api形式, 命名风格....&lt;/p&gt;
&lt;div class="section" id="what-are-key-value-stores-and-why-implement-one"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id27"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1 What are key-value stores, and why implement one?&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;练习目的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;I am starting this project as a way to refresh my knowledge of some fundamentals of hardcore back-end engineering&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Reading books and Wikipedia articles is boring and exempt of practice&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;练习点&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;The C++ programming language&lt;/li&gt;
&lt;li&gt;Object-oriented design&lt;/li&gt;
&lt;li&gt;Algorithmics and data structures&lt;/li&gt;
&lt;li&gt;Memory management&lt;/li&gt;
&lt;li&gt;Concurrency control with multi-processors or multi-threading&lt;/li&gt;
&lt;li&gt;Networking with a server/client model&lt;/li&gt;
&lt;li&gt;I/O problems with disk access and use of the file system&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;现有的: Redis, MongoDB, memcached, BerkeleyDB, Kyoto Cabinet and LevelDB.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;打算提供的特性:
- Adapt to a specific data representation (ex: graphs, geographic data, etc.)
- Adapt to a specific operation (ex: performing very well for reads only, or writes only, etc.)
- Offer more data access options. For instance in LevelDB, data can be accessed forward or backward, with iterators&lt;/p&gt;
&lt;p&gt;貌似没有什么特点..&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;I will use a hash table for the underlying data Structure, the data will be persistent on disk, and a network interface will also be implemented.&lt;/li&gt;
&lt;li&gt;不求速度 I will not run for absolute speed&lt;/li&gt;
&lt;li&gt;将基于一个现有c/c++项目(见第2节)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="using-existing-key-value-stores-as-models"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id28"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2 Using existing key-value stores as models&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;One of the most memorable projects is DBM, the initial database manager coded by Kenneth Thompson for Unix version 7 and released in 1979&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主要考察:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;DBM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Berkeley DB , 当时作为改进的DBM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Kyoto Cabinet, &lt;strong&gt;主要考察对象&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;(a straightforward implementation of DBM)一般性能7w/s, 在超过某一个buckets值之后有性能问题&lt;/li&gt;
&lt;li&gt;hash 或者B+ tree.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;LevelDB &lt;strong&gt;主要考察对象&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;LSM structures are allegedly optimized for SSD drives [13].&lt;/li&gt;
&lt;li&gt;有测试, 当条目数从1e6 到1e9的时候, 性能有下降: &lt;tt class="docutils literal"&gt;找不到原始文章了&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;作者认为LevelDB 代码很好: it is just pure beauty. Everything is clear, simple, and logical.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Memcached and MemcacheDB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;MongoDB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Redis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;OpenLDAP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;SQLite&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="comparative-analysis-of-the-architectures-of-kyoto-cabinet-and-leveldb"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id29"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3 Comparative Analysis of the Architectures of Kyoto Cabinet and LevelDB&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;分成这些模块:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Interface, Get/Put/Delete&lt;/li&gt;
&lt;li&gt;配置参数&lt;/li&gt;
&lt;li&gt;String库&lt;/li&gt;
&lt;li&gt;Logging&lt;/li&gt;
&lt;li&gt;Compression&lt;/li&gt;
&lt;li&gt;Checksum&lt;/li&gt;
&lt;li&gt;Data Storage&lt;/li&gt;
&lt;li&gt;Data Structure Hash/B+Tree/LSM-Tree&lt;/li&gt;
&lt;li&gt;Memory Management&lt;/li&gt;
&lt;li&gt;Iteration&lt;/li&gt;
&lt;li&gt;Lock 管理&lt;/li&gt;
&lt;li&gt;Error管理&lt;/li&gt;
&lt;li&gt;Transaction&lt;/li&gt;
&lt;li&gt;Comparators&lt;/li&gt;
&lt;li&gt;Snapshot&lt;/li&gt;
&lt;li&gt;Sharding&lt;/li&gt;
&lt;li&gt;Replication&lt;/li&gt;
&lt;li&gt;Testing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;太多了... 后面4个不该考虑.&lt;/p&gt;
&lt;p&gt;作者认为Kyoto Cabinet 代码耦合较重, 比如: such as the definition of the Parametrization module inside the Core.&lt;/p&gt;
&lt;p&gt;String库:
- LevelDB is using a specialized class called “Slice
- Kyoto Cabinet is using std::string&lt;/p&gt;
&lt;p&gt;Memory Management
- Kyoto Cabinet 用mmap()
- LevelDB: 用LSM-tree&lt;/p&gt;
&lt;p&gt;Data Storage&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Kyoto Cabinet, LevelDB, BerkeleyDB, MongoDB and Redis are using the file system to store the data. Memcached, on the contrary, is storing the data in memory (RAM).&lt;/li&gt;
&lt;li&gt;对Redis 说错了.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于代码:&lt;/p&gt;
&lt;p&gt;Kyoto Cabinet 会把实现写在.h里面, Kyoto Cabinet 代码比Tokyo Cabinet好多了(The overall architecture and naming conventions have been greatly improved.) 但是还是很糟糕:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
embcomp, trhard, fmtver(), fpow()
&lt;/pre&gt;
&lt;p&gt;LevelDB 的代码命名就很好.&lt;/p&gt;
&lt;p&gt;Kyoto Cabinet 的代码重复也很严重.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="api-design"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id30"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4 API Design&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Opening and closing a database&lt;/li&gt;
&lt;li&gt;Reading and writing data to a database&lt;/li&gt;
&lt;li&gt;Iterating over the full collection of keys and values in a database&lt;/li&gt;
&lt;li&gt;Offer a way to tune parameters&lt;/li&gt;
&lt;li&gt;Offer a decent error notification interface&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者考虑的: Kyoto, LevelDB, BDB, SQLite, 都是库的形式.&lt;/p&gt;
&lt;p&gt;LevelDB 的api有open(). 但是没有close(), 关闭的时候是通过delete 指针做的 -&amp;gt; 不对称.&lt;/p&gt;
&lt;p&gt;Iteration接口, sqlite 是通过一个回调, 不好:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* SQLite3 */
static int callback(void *NotUsed, int argc, char **argv, char **szColName) {
  for(int i = 0; i &amp;lt; argc; i++) {
    printf(&amp;quot;%s = %s\n&amp;quot;, szColName[i], argv[i] ? argv[i] : &amp;quot;NULL&amp;quot;);
  }
  printf(&amp;quot;\n&amp;quot;);
  return 0;
}

char *query = “SELECT * FROM table”;
sqlite3_exec(db, query, callback, 0, &amp;amp;szErrMsg);
&lt;/pre&gt;
&lt;p&gt;it's always interesting to see how different engineers solved the same problems.&lt;/p&gt;
&lt;p&gt;小结: 作者很喜欢LevelDB的api. 除了没有close.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="hash-table-implementations"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id31"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5 Hash table implementations&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这都研究cache line的优化去了, 每必要把.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;gcc4.8中stl 的 hash&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2. sparsehash库, 提供 sparse_hash_map 和 dense_hash_map两个类.
其中dense_hash_map可以scales up or down&lt;/p&gt;
&lt;ol class="arabic" start="3"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Kyoto Cabinet 中的HashDB&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不会自动扩容.&lt;/li&gt;
&lt;li&gt;一旦冲突后, 性能就很差.&lt;/li&gt;
&lt;li&gt;it is very difficult to allow the bucket array to be resized for an on-disk hash table implementation&lt;/li&gt;
&lt;li&gt;把hash表存在磁盘里面, 导致一旦冲突, 就需要在磁盘中访问链表, 这是严重的随机IO&lt;/li&gt;
&lt;li&gt;所以, 基于ssd的cache应该优化: &lt;strong&gt;读操作最多进行多少次IO&lt;/strong&gt; .&lt;/li&gt;
&lt;li&gt;碎片: 有磁盘整理&lt;/li&gt;
&lt;li&gt;一个基于磁盘的存储引擎确实较复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;也许我们能设计这样一个引擎:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;hash表放在内存, 对hash的所有操作写aof(像redis一样)&lt;/li&gt;
&lt;li&gt;数据操作直接写磁盘.&lt;/li&gt;
&lt;li&gt;如何解决碎片.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://code.google.com/p/sparsehash/"&gt;https://code.google.com/p/sparsehash/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="implementing-a-memory-efficient-hash-table-stored-on-the-file-system"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id32"&gt;2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;-6 Implementing a memory-efficient hash table stored on the file system&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="memory-management"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id33"&gt;2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;7 Memory Management&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="networking"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id34"&gt;2.8&amp;nbsp;&amp;nbsp;&amp;nbsp;8 Networking&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="interfaces-rest-memcached-etc"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id35"&gt;2.9&amp;nbsp;&amp;nbsp;&amp;nbsp;9 Interfaces: REST, memcached, etc.&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="going-further"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id36"&gt;2.10&amp;nbsp;&amp;nbsp;&amp;nbsp;10 Going further&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id37"&gt;2.11&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这里作者考察的一些KV系统, 实际是一些库(KV引擎), 从我的角度看, 有这些引擎:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;BDB&lt;/li&gt;
&lt;li&gt;LevelDB&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id38"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;参考&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这里有很多ssd测试数据: &lt;a class="reference external" href="http://www.storagereview.com/samsung_ssd_840_pro_review"&gt;http://www.storagereview.com/samsung_ssd_840_pro_review&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>cr-ssdb</title><link href="/cr-ssdb.html" rel="alternate"></link><updated>2014-07-24T15:12:18+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-24:cr-ssdb.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id19"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id20"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#util" id="id21"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;util&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id22"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;请求处理模型&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#link" id="id23"&gt;2.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redislink" id="id24"&gt;2.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RedisLink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id25"&gt;2.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;命令表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id26"&gt;2.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;处理模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#serv-proc" id="id27"&gt;2.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;serv.proc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#workerpool" id="id28"&gt;2.2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;WorkerPool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id29"&gt;2.2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id30"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;功能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#kv" id="id31"&gt;2.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;kv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hash" id="id32"&gt;2.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;hash&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hscan-hkeys" id="id33"&gt;2.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;hscan/hkeys的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#queue" id="id34"&gt;2.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;queue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#zset" id="id35"&gt;2.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;zset&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#zrank" id="id36"&gt;2.3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;zrank&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id37"&gt;2.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;名字空间划分&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id38"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从相关&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#binlog" id="id39"&gt;2.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;binlog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#binlogqueue" id="id40"&gt;2.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;BinlogQueue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id41"&gt;2.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Binlog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id42"&gt;2.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从同步&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slave" id="id43"&gt;2.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;slave&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dump" id="id44"&gt;2.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;dump&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id45"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#incr" id="id46"&gt;2.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;incr 如何保证原子性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#expire" id="id47"&gt;2.5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何实现expire&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#benchmark" id="id48"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id49"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id14" id="id50"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;读性能的问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#compact" id="id51"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何compact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#expirekey" id="id52"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;所有expire的key记录在内存&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id15" id="id53"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;兼容问题&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#del" id="id54"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;del 兼容&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ttlkey" id="id55"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;ttl一个不存在的key&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id56"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;没有expire命令&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#set-key-val-ex-nx" id="id57"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;不支持set key val ex nx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#scan" id="id58"&gt;4.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;scan类&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id17" id="id59"&gt;4.4.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;scan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-hscan" id="id60"&gt;4.4.5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;没有redis 的hscan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id18" id="id61"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;style type="text/css"&gt;
      table {
        width: 30%
      }
&lt;/style&gt;&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id19"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;请求处理模型, 每个线程一个req?&lt;/li&gt;
&lt;li&gt;如何在kv上实现hash/zset/queue&lt;/li&gt;
&lt;li&gt;如何处理expire/ttl&lt;/li&gt;
&lt;li&gt;如何支持事务, binlog?&lt;/li&gt;
&lt;li&gt;如何主从同步.&lt;/li&gt;
&lt;li&gt;LevelDB读有没有缓存, 如果没有缓存, 那么读性能 &amp;lt; iops&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id20"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;代码量大约9000行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/test/ssdb/src$ cat *.cpp *.h | wc -l
7223

ning&amp;#64;ning-laptop:~/test/ssdb/src$ cat util/*.cpp util/*.h | wc -l
2404
&lt;/pre&gt;
&lt;p&gt;协议解析:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
link.cpp
link.h
link_redis.cpp
link_redis.h
&lt;/pre&gt;
&lt;p&gt;数据类型:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
t_hash.cpp
t_hash.h
t_kv.cpp
t_kv.h
t_queue.cpp
t_queue.h
t_zset.cpp
t_zset.h
proc_hash.cpp
proc_kv.cpp
proc_queue.cpp
proc_zset.cpp

#ttl 也相当于是一种数据类型.
ttl.cpp
ttl.h
&lt;/pre&gt;
&lt;p&gt;主从同步:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
binlog.cpp
binlog.h
slave.cpp
slave.h
#backend_dump.cpp
#backend_dump.h
backend_sync.cpp
backend_sync.h
&lt;/pre&gt;
&lt;p&gt;服务框架:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
serv.cpp
serv.h
ssdb.cpp
ssdb.h
ssdb-server.cpp
&lt;/pre&gt;
&lt;p&gt;其它:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
include.h
version.h
iterator.cpp
iterator.h
&lt;/pre&gt;
&lt;div class="section" id="util"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id21"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;util&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;和icomet一样:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
config.cpp
config.h
daemon.h
file.h
ip_filter.h
log.cpp
log.h
strings.h
&lt;/pre&gt;
&lt;p&gt;epoll:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fde.cpp
fde_epoll.cpp
fde.h
fde_select.cpp
&lt;/pre&gt;
&lt;p&gt;bytes.cpp bytes.h Bytes, Buffer 用于实现string的一些操作.&lt;/p&gt;
&lt;p&gt;sorted_set.cpp
sorted_set.h&lt;/p&gt;
&lt;p&gt;SelectableQueue: 提供一个基于管道实现的Queue, 从而使得这个Queue 可以做Select.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;请求处理模型&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="link"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id23"&gt;2.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;Link&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
class Link{
    int sock;
    bool noblock_;
    static int min_recv_buf;
    static int min_send_buf;

    std::vector&amp;lt;Bytes&amp;gt; recv_data; //recv_data 是解析后的bulk链表.
    Buffer *input;
    Buffer *output;

    double create_time;
    double active_time;

    int read();                             //从网络读到input
    int write();                            //从output写到网络
    int flush();                            //调用wirte.

    const std::vector&amp;lt;Bytes&amp;gt;* recv();       //从input解析到recv_data

    int send(const Bytes &amp;amp;s1);              //写到output
    int send(const Bytes &amp;amp;s1, const Bytes &amp;amp;s2);
    int send(const Bytes &amp;amp;s1, const Bytes &amp;amp;s2, const Bytes &amp;amp;s3);
    ...

    const std::vector&amp;lt;Bytes&amp;gt;* response();                           //通过read() 和recv() 读取response.

    const std::vector&amp;lt;Bytes&amp;gt;* request(const Bytes &amp;amp;s1);             //铜鼓send() 和flush() 写request.
    const std::vector&amp;lt;Bytes&amp;gt;* request(const Bytes &amp;amp;s1, const Bytes &amp;amp;s2);
    ...
}
&lt;/pre&gt;
&lt;p&gt;这里:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;read/recv 是一样的语义, 很容易混淆, write/send也是类似,
read, write 为内部函数, 如果改为 _read, _write 就好懂些.&lt;/li&gt;
&lt;li&gt;request, response 之类, 使用名词做函数名. 不好.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="redislink"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id24"&gt;2.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RedisLink&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;两个函数, 处理对象是input, output:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
send_resp(Buffer *output, const std::vector&amp;lt;std::string&amp;gt; &amp;amp;resp)  //发送redis格式的响应, resp是一个 string 构成的vector.
parse_req(Buffer *input)                                         //读redis格式的请求
recv_req(Buffer *input)                                          //调用parse_req 之后调用convert 转为内部cmd格式.
&lt;/pre&gt;
&lt;p&gt;parse_req 对input的处理是, 如果一次没有解析到一个完整的命令, 那么input buffer不动, 下次继续.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id25"&gt;2.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;命令表&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;命令表:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#define PROC(c, f) {#c, f, 0, proc_##c, 0, 0, 0}
static Command commands[] = {
    PROC(get, &amp;quot;r&amp;quot;),
    PROC(set, &amp;quot;wt&amp;quot;),        //t表示在线程池里面run
    ...
    PROC(dump, &amp;quot;b&amp;quot;),        //b表示在后台run
}
&lt;/pre&gt;
&lt;p&gt;全局变量:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static proc_map_t proc_map;

//启动时初始化 这个map
for(Command *cmd=commands; cmd-&amp;gt;name; cmd++){
    proc_map[cmd-&amp;gt;name] = cmd;
}
&lt;/pre&gt;
&lt;p&gt;收到请求后, Server::proc函数会在proc_map里面查找&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id26"&gt;2.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;处理模型&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;ssdb-server.cpp&lt;/p&gt;
&lt;p&gt;全局:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Config *conf = NULL;
SSDB *ssdb = NULL;
Link *serv_link = NULL;
IpFilter *ip_filter = NULL;

typedef std::vector&amp;lt;Link *&amp;gt; ready_list_t;
volatile bool quit = false;
volatile uint32_t g_ticks = 0;
&lt;/pre&gt;
&lt;p&gt;main:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
main(){
    init(); //load cfg, daemon, listen, init ipfilter, init SSDB, signal
    run(argc, argv);
}
&lt;/pre&gt;
&lt;p&gt;run():&lt;/p&gt;
&lt;pre class="literal-block"&gt;
run(){
    Fdevents fdes;
    fdes.set(serv_link-&amp;gt;fd(), FDEVENT_IN, 0, serv_link);            //监听socket
    fdes.set(serv.reader-&amp;gt;fd(), FDEVENT_IN, 0, serv.reader);        //reader.SelectableQueue.fd
    fdes.set(serv.writer-&amp;gt;fd(), FDEVENT_IN, 0, serv.writer);

    while(!quit){
        ready_list.clear();
        ready_list_2.clear();

        events = fdes.wait(50);
        for(int i=0; i&amp;lt;(int)events-&amp;gt;size(); i++){
            if(fde-&amp;gt;data.ptr == serv_link){
                //do accept
            }else if(fde-&amp;gt;data.ptr == serv.reader || fde-&amp;gt;data.ptr == serv.writer){
                //从子进程那里收结果, 这里比较复杂
                proc_result(job, fdes, ready_list_2);
            }else{
                if(fde-&amp;gt;events &amp;amp; FDEVENT_IN){
                    int len = link-&amp;gt;read();                 //用read
                    ready_list.push_back(link);                         //放到ready_list
                }else if(fde-&amp;gt;events &amp;amp; FDEVENT_OUT){
                    int len = link-&amp;gt;write();                //用write
                    ready_list.push_back(link);                         //放到ready_list
                }
            }
        }
        for(it = ready_list.begin(); it != ready_list.end(); it ++){
            Link *link = *it;
            const Request *req = link-&amp;gt;recv();

            ProcJob job;
            job.link = link;
            serv.proc(&amp;amp;job);                        //这里面可能把Job发到一个线程去.
            if(job.result == PROC_THREAD){
                fdes.del(link-&amp;gt;fd());
                continue;
            }
            if(job.result == PROC_BACKEND){
                fdes.del(link-&amp;gt;fd());
                link_count --;
                continue;
            }
            //这里是直接处理的情况.
            if(proc_result(job, fdes, ready_list_2) == PROC_ERROR){
                link_count --;
            }
        }
        ready_list.swap(ready_list_2);
    }
}
&lt;/pre&gt;
&lt;p&gt;所以请求可以在主线程里面处理, 也可能在线程池里面处理, 如果在线程里面处理, 就会返回PROC_THREAD或者PROC_BACKEND, 此时fd被摘掉, 等请求处理完, 发送response后, 再把fd加入epoll.&lt;/p&gt;
&lt;p&gt;TODO: 为什么最后把ready_list_2 里面的元素放到ready_list里面去了, 但是到下一个循环一开始就   &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ready_list.clear();&lt;/span&gt;&lt;/tt&gt;, 这个clear() 是不是不应该有?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="serv-proc"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id27"&gt;2.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;serv.proc&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;这个函数会根据command_table里的标记, 决定是在主线程处理, 还是在线程池处理, 或者新开一个线程处理:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void Server::proc(ProcJob *job){
    proc_map_t::iterator it = proc_map.find(req-&amp;gt;at(0));
    if(it == proc_map.end()){
        resp.push_back(&amp;quot;client_error&amp;quot;);
    }else{
        Command *cmd = it-&amp;gt;second;
        job-&amp;gt;cmd = cmd;
        if(cmd-&amp;gt;flags &amp;amp; Command::FLAG_THREAD){              //标记为thread的cmd, 会被分到2个线程池里面去跑
            if(cmd-&amp;gt;flags &amp;amp; Command::FLAG_WRITE){
                job-&amp;gt;result = PROC_THREAD;
                writer-&amp;gt;push(*job);
                return; /////
            }else if(cmd-&amp;gt;flags &amp;amp; Command::FLAG_READ){
                job-&amp;gt;result = PROC_THREAD;
                reader-&amp;gt;push(*job);
                return; /////
            }else{
                log_error(&amp;quot;bad command config: %s&amp;quot;, cmd-&amp;gt;name);
            }
        }

        proc_t p = cmd-&amp;gt;proc;
        job-&amp;gt;time_wait = 1000 *(millitime() - job-&amp;gt;stime);
        job-&amp;gt;result = (*p)(this, job-&amp;gt;link, *req, &amp;amp;resp);   //直接在主线程处理.
        job-&amp;gt;time_proc = 1000 *(millitime() - job-&amp;gt;stime);
    }
}
&lt;/pre&gt;
&lt;p&gt;这里调用cmd-&amp;gt;proc, 就是prox_xxx 函数, 它们都是然后调用 &lt;tt class="docutils literal"&gt;SSDB&lt;/tt&gt; 类的相应函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_hdel(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    int ret = serv-&amp;gt;ssdb-&amp;gt;hdel(req[1], req[2]);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="workerpool"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id28"&gt;2.2.6&amp;nbsp;&amp;nbsp;&amp;nbsp;WorkerPool&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;thread.h 提供线程池(WorkerPool), ssdb里面一个writer 线程池, 一个reader 线程池:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt; *writer;
WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt; *reader;

writer = new WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt;(&amp;quot;writer&amp;quot;);
writer-&amp;gt;start(WRITER_THREADS);                                  //1
reader = new WorkerPool&amp;lt;ProcWorker, ProcJob&amp;gt;(&amp;quot;reader&amp;quot;);
reader-&amp;gt;start(READER_THREADS);                                  //10
&lt;/pre&gt;
&lt;p&gt;每个WorkerPool有两个 Queue:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Queue&amp;lt;JOB&amp;gt; jobs;
SelectableQueue&amp;lt;JOB&amp;gt; results;

template&amp;lt;class W, class JOB&amp;gt;
int WorkerPool&amp;lt;W, JOB&amp;gt;::push(JOB job){
    return this-&amp;gt;jobs.push(job);
}

template&amp;lt;class W, class JOB&amp;gt;
int WorkerPool&amp;lt;W, JOB&amp;gt;::pop(JOB *job){
    return this-&amp;gt;results.pop(job);
}

template&amp;lt;class W, class JOB&amp;gt;
void* WorkerPool&amp;lt;W, JOB&amp;gt;::_run_worker(void *arg){
    while(1){
        JOB job;
        tp-&amp;gt;jobs.pop(&amp;amp;job);
        worker-&amp;gt;proc(&amp;amp;job);
        tp-&amp;gt;results.push(job);
    }
}
&lt;/pre&gt;
&lt;p&gt;SelectableQueue的fd, 在前面epoll_初始化的时候, 已经把这个fd加入监听, 每次一个job处理完成, 就会向SelectableQueue的fd上写一个字节, 这样主线程就能知道这个Job处理完了&lt;/p&gt;
&lt;p&gt;worker-&amp;gt;porc(&amp;amp;job) 的逻辑:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int Server::ProcWorker::proc(ProcJob *job){
    const Request *req = job-&amp;gt;link-&amp;gt;last_recv();
    Response resp;

    double stime = millitime();
    proc_t p = job-&amp;gt;cmd-&amp;gt;proc;
    job-&amp;gt;result = (*p)(job-&amp;gt;serv, job-&amp;gt;link, *req, &amp;amp;resp);
    double etime = millitime();
    job-&amp;gt;time_wait = 1000 * (stime - job-&amp;gt;stime);
    job-&amp;gt;time_proc = 1000 *(etime - stime);

    if(job-&amp;gt;link-&amp;gt;send(resp) == -1){
        job-&amp;gt;result = PROC_ERROR;
    }else{
        log_debug(&amp;quot;w:%.3f,p:%.3f, req: %s, resp: %s&amp;quot;,
            job-&amp;gt;time_wait, job-&amp;gt;time_proc,
            serialize_req(*req).c_str(),
            serialize_req(resp).c_str());
    }
    return 0;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id29"&gt;2.2.7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;这种请求处理模型没见过, 觉得很巧妙.&lt;/p&gt;
&lt;p&gt;HERE&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id30"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;功能&lt;/a&gt;&lt;/h3&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="30%" /&gt;
&lt;col width="70%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;redis&lt;/th&gt;
&lt;th class="head"&gt;ssdb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hash&lt;/td&gt;
&lt;td&gt;hash&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;list&lt;/td&gt;
&lt;td&gt;queue(不等于list)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;set&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zset&lt;/td&gt;
&lt;td&gt;zset&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;hash的hset, hget 可以O(n)实现,  list 的rpush/lpop也可以O(n) 实现, 但是list的 LINSERT, LINDEX是O(n), 所以ssdb没有实现, 只是实现了可以保持O(n)操作的queue&lt;/p&gt;
&lt;p&gt;如何在kv上实现hash/zset/queue&lt;/p&gt;
&lt;p&gt;kv:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(get);
DEF_PROC(set);
&lt;/pre&gt;
&lt;p&gt;hash:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(hget);
DEF_PROC(hset);
&lt;/pre&gt;
&lt;p&gt;zset:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(zrank);
DEF_PROC(zrrank);
DEF_PROC(zrange);
&lt;/pre&gt;
&lt;p&gt;queue:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(qsize);
DEF_PROC(qfront);
DEF_PROC(qback);
DEF_PROC(qpush);
&lt;/pre&gt;
&lt;div class="section" id="kv"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id31"&gt;2.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;kv&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;get:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_get(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    if(req.size() &amp;lt; 2){
        resp-&amp;gt;push_back(&amp;quot;client_error&amp;quot;);
    }else{
        std::string val;
        int ret = serv-&amp;gt;ssdb-&amp;gt;get(req[1], &amp;amp;val);
        if(ret == 1){
            resp-&amp;gt;push_back(&amp;quot;ok&amp;quot;);      //找到  这里是ok这个字符串, 后面会转为redis协议.
            resp-&amp;gt;push_back(val);
        }else if(ret == 0){
            resp-&amp;gt;push_back(&amp;quot;not_found&amp;quot;);
        }else{
            log_error(&amp;quot;fail&amp;quot;);
            resp-&amp;gt;push_back(&amp;quot;fail&amp;quot;);
        }
    }
    return 0;
}

typedef std::vector&amp;lt;std::string&amp;gt; Response;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="hash"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id32"&gt;2.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;hash&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;实现了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEF_PROC(hsize);        // O(1)
DEF_PROC(hget);         // O(1)
DEF_PROC(hset);         // O(1)
DEF_PROC(hdel);         // O(1)
DEF_PROC(hincr);        // O(1)
DEF_PROC(hdecr);        // O(1)
DEF_PROC(hexists);      //O(1)

DEF_PROC(hclear);       // O(n)
DEF_PROC(hscan);        // O(n)
DEF_PROC(hrscan);       // O(n)
DEF_PROC(hkeys);        // O(n)
DEF_PROC(hvals);        // O(n)
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;hkey: {a: b}&lt;/tt&gt; 存储结构:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
_hkey : 1           #size = 1
_hkey_a : b         # hkey.a = b
&lt;/pre&gt;
&lt;p&gt;hset_one时, 组一个新的key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
// returns the number of newly added items
static int hset_one(const SSDB *ssdb, const Bytes &amp;amp;name, const Bytes &amp;amp;key, const Bytes &amp;amp;val, char log_type){
    ...
    int ret = 0;
    std::string dbval;
    if(ssdb-&amp;gt;hget(name, key, &amp;amp;dbval) == 0){ // not found
        std::string hkey = encode_hash_key(name, key); ///////////////////////////////组新key.
        ssdb-&amp;gt;binlogs-&amp;gt;Put(hkey, val.Slice());
        ssdb-&amp;gt;binlogs-&amp;gt;add(log_type, BinlogCommand::HSET, hkey);
        ret = 1;
    }
}

inline static
std::string encode_hash_key(const Bytes &amp;amp;name, const Bytes &amp;amp;key){
    std::string buf;
    buf.append(1, DataType::HASH);
    buf.append(1, (uint8_t)name.size());
    buf.append(name.data(), name.size());
    buf.append(1, '=');
    buf.append(key.data(), key.size());
    return buf;
}
&lt;/pre&gt;
&lt;p&gt;专门存size的key, 参考:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int incr_hsize(SSDB *ssdb, const Bytes &amp;amp;name, int64_t incr){
&lt;/pre&gt;
&lt;div class="section" id="hscan-hkeys"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id33"&gt;2.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;hscan/hkeys的实现&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;需要客户端传来, 从那个key scan到哪个key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_hscan(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    uint64_t limit = req[4].Uint64();
    HIterator *it = serv-&amp;gt;ssdb-&amp;gt;hscan(req[1], req[2], req[3], limit);
    resp-&amp;gt;push_back(&amp;quot;ok&amp;quot;);
    while(it-&amp;gt;next()){
        resp-&amp;gt;push_back(it-&amp;gt;key);
        resp-&amp;gt;push_back(it-&amp;gt;val);
    }
}
&lt;/pre&gt;
&lt;p&gt;用法应该是:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hscan hkey a '' 100
&lt;/pre&gt;
&lt;p&gt;只有ssdb协议支持hscan, 不支持redis的hscan.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="queue"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id34"&gt;2.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;queue&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;实现了这些命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{STRATEGY_AUTO,         &amp;quot;lpush&amp;quot;,                &amp;quot;qpush_front&amp;quot;,          REPLY_STATUS},
{STRATEGY_AUTO,         &amp;quot;rpush&amp;quot;,                &amp;quot;qpush_back&amp;quot;,           REPLY_STATUS},
{STRATEGY_AUTO,         &amp;quot;lpop&amp;quot;,                 &amp;quot;qpop_front&amp;quot;,           REPLY_BULK},
{STRATEGY_AUTO,         &amp;quot;rpop&amp;quot;,                 &amp;quot;qpop_back&amp;quot;,            REPLY_BULK},
{STRATEGY_AUTO,         &amp;quot;llen&amp;quot;,                 &amp;quot;qsize&amp;quot;,                        REPLY_INT},
&lt;/pre&gt;
&lt;p&gt;只能在端上操作, 不能在list中间插入/删除等.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static uint64_t QFRONT_SEQ = 2;
static uint64_t QBACK_SEQ  = 3;
static uint64_t QITEM_MIN_SEQ = 10000;
static uint64_t QITEM_MAX_SEQ = 9223372036854775807ULL;
static uint64_t QITEM_SEQ_INIT = QITEM_MAX_SEQ/2;           //4611686018427387903
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;rpush qkey msg&lt;/tt&gt; 后, 存储结构如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
qkey_2: 4611686018427387903             //front下标
qkey_3:  4611686018427387904            //end下标
qkey_4611686018427387904                //msg
&lt;/pre&gt;
&lt;p&gt;这里 &lt;tt class="docutils literal"&gt;qkey_4611686018427387904&lt;/tt&gt; 后面这个数字在leveldb key里面是直接存binary格式, 8个字节.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="zset"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id35"&gt;2.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;zset&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;每个zset中的元素对应2个key: zset_key, zscore_key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
k2 = encode_zscore_key(name, key, new_score);
k0 = encode_zset_key(name, key);
&lt;/pre&gt;
&lt;p&gt;如下操作:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
127.0.0.1:8888&amp;gt; Zadd zkey 3 a
(integer) 1
127.0.0.1:8888&amp;gt; ZSCORE zkey a
&amp;quot;3&amp;quot;
&lt;/pre&gt;
&lt;p&gt;存储结构:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
zkey: 1                 #size
zkey_a_3: ''            #zscore_key
zkey_a: 3               #zset_key
&lt;/pre&gt;
&lt;p&gt;每次zset, 先用zset_key 取的score, 构造zscore_key, 删除老记录.&lt;/p&gt;
&lt;p&gt;再写新的zset_key和zscore_key.&lt;/p&gt;
&lt;div class="section" id="zrank"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id36"&gt;2.3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;zrank&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;利用zscore_key, 遍历:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int64_t SSDB::zrank(const Bytes &amp;amp;name, const Bytes &amp;amp;key) const{
    ZIterator *it = ziterator(this, name, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, INT_MAX, Iterator::FORWARD);
    uint64_t ret = 0;
    while(true){
        if(it-&amp;gt;next() == false){
            ret = -1;
            break;
        }
        if(key == it-&amp;gt;key){
            break;
        }
        ret ++;
    }
    delete it;
    return ret;
}
&lt;/pre&gt;
&lt;p&gt;zrange类似&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id37"&gt;2.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;名字空间划分&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;LevelDB里面, 每种key都有一个前缀:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class DataType{
public:
    static const char SYNCLOG       = 1;
    static const char KV            = 'k';
    static const char HASH          = 'h'; // hashmap(sorted by key)
    static const char HSIZE         = 'H';
    static const char ZSET          = 's'; // key =&amp;gt; score
    static const char ZSCORE        = 'z'; // key|score =&amp;gt; &amp;quot;&amp;quot;
    static const char ZSIZE         = 'Z';
    static const char QUEUE         = 'q';
    static const char QSIZE         = 'Q';
    static const char MIN_PREFIX = HASH;
    static const char MAX_PREFIX = ZSET;
};
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id38"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从相关&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="binlog"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id39"&gt;2.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;binlog&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;class Binlog
class BinlogQueue
class Transaction&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class Transaction{
private:
    BinlogQueue *logs;
public:
    Transaction(BinlogQueue *logs){
        this-&amp;gt;logs = logs;
        logs-&amp;gt;mutex.lock();
        logs-&amp;gt;begin();
    }

    ~Transaction(){
        // it is safe to call rollback after commit
        logs-&amp;gt;rollback();
        logs-&amp;gt;mutex.unlock();
    }
};
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="binlogqueue"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id40"&gt;2.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;BinlogQueue&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;整个SSDB只有一个BinlogQueue, 而且和数据存放在同一个leveldb里面:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssdb-&amp;gt;binlogs = new BinlogQueue(ssdb-&amp;gt;db);
&lt;/pre&gt;
&lt;p&gt;启动SSDB时, 申请一个BinlogQueue对象, seek 到最后一条binlog, (最后一条是用 encode_seq_key(UINT64_MAX) )
然后启动一个线程, 来删Binlog:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int err = pthread_create(&amp;amp;tid, NULL, &amp;amp;BinlogQueue::log_clean_thread_func, this);
&lt;/pre&gt;
&lt;p&gt;具体写操作的时候:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int SSDB::set(const Bytes &amp;amp;key, const Bytes &amp;amp;val, char log_type){
    Transaction trans(binlogs);                                     //这里开始加锁

    std::string buf = encode_kv_key(key);
    binlogs-&amp;gt;Put(buf, val.Slice());                                 //这里是真正的写操作.
    binlogs-&amp;gt;add(log_type, BinlogCommand::KSET, buf);               //这里是记录一条日志, 说我对这个key, 做了一次set操作 (没记录value, 难道同步的时候再去取value?)
    leveldb::Status s = binlogs-&amp;gt;commit();                          //两个操作一起写
}
&lt;/pre&gt;
&lt;p&gt;其实这里 ssdb-&amp;gt;binlogs 相当于存储层, 所有 set/del leveldb 读写操作都是通过 ssdb-&amp;gt;binlog 进行的, 但是Get操作却不是通过ssdb-&amp;gt;binlog() 操作的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int64_t SSDB::qsize(const Bytes &amp;amp;name){
    std::string key = encode_qsize_key(name);
    std::string val;

    leveldb::Status s;
    s = db-&amp;gt;Get(leveldb::ReadOptions(), key, &amp;amp;val);
}
&lt;/pre&gt;
&lt;p&gt;这就不太统一, 不方便换下面的存储引擎.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id41"&gt;2.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Binlog&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;有多种类型:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class BinlogCommand{
public:
    static const char NONE  = 0;
    static const char KSET  = 1;
    static const char KDEL  = 2;
    static const char HSET  = 3;
    static const char HDEL  = 4;
    static const char ZSET  = 5;
    static const char ZDEL  = 6;

    static const char BEGIN  = 7;
    static const char END    = 8;
};
&lt;/pre&gt;
&lt;p&gt;都是只记录key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssdb-&amp;gt;binlogs-&amp;gt;add(log_type, BinlogCommand::HSET, hkey);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id42"&gt;2.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;主从同步&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;由Master 主动向从数据, 一个Server 有一个BackendSync实例:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Server::Server(SSDB *ssdb){
    this-&amp;gt;ssdb = ssdb;
    backend_sync = new BackendSync(ssdb);
    ...
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="slave"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id43"&gt;2.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;slave&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
void Slave::start(){
    load_status();
    log_debug(&amp;quot;last_seq: %&amp;quot; PRIu64 &amp;quot;, last_key: %s&amp;quot;,
        last_seq, hexmem(last_key.data(), last_key.size()).c_str());

    thread_quit = false;
    int err = pthread_create(&amp;amp;run_thread_tid, NULL, &amp;amp;Slave::_run_thread, this);
    if(err != 0){
        log_error(&amp;quot;can't create thread: %s&amp;quot;, strerror(err));
    }
}
&lt;/pre&gt;
&lt;p&gt;启动时load last_seq , 然后连上master, 发一个 sync140 告诉服务器从哪里开始发binlog:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sprintf(seq_buf, &amp;quot;%&amp;quot; PRIu64 &amp;quot;&amp;quot;, this-&amp;gt;last_seq);
const char *type = is_mirror? &amp;quot;mirror&amp;quot; : &amp;quot;sync&amp;quot;;
link-&amp;gt;send(&amp;quot;sync140&amp;quot;, seq_buf, this-&amp;gt;last_key, type);
&lt;/pre&gt;
&lt;p&gt;当Slave通过sync命令连上来, Master就会从这个socket把最新的更新发给Slave:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_sync140(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    serv-&amp;gt;backend_sync-&amp;gt;proc(link);
    return PROC_BACKEND;
}

int BackendSync::Client::sync(BinlogQueue *logs){
    Binlog log;
    ret = logs-&amp;gt;find_next(expect_seq, &amp;amp;log);

    switch(log.cmd()){
        case BinlogCommand::KSET:
        case BinlogCommand::HSET:
        case BinlogCommand::ZSET:
            ret = backend-&amp;gt;ssdb-&amp;gt;raw_get(log.key(), &amp;amp;val);
            if(ret == -1){
                log_error(&amp;quot;fd: %d, raw_get error!&amp;quot;, link-&amp;gt;fd());
            }else if(ret == 0){
                //log_debug(&amp;quot;%s&amp;quot;, hexmem(log.key().data(), log.key().size()).c_str());
                log_trace(&amp;quot;fd: %d, skip not found: %s&amp;quot;, link-&amp;gt;fd(), log.dumps().c_str());
            }else{
                log_trace(&amp;quot;fd: %d, %s&amp;quot;, link-&amp;gt;fd(), log.dumps().c_str());
                link-&amp;gt;send(log.repr(), val);
            }
&lt;/pre&gt;
&lt;p&gt;因为binlog只记录了key, 所以这里会再查一次, 把value查出来一起发过去(需要一次读)&lt;/p&gt;
&lt;p&gt;问题: 基准数据怎么过去呢? =&amp;gt; 可以拷贝.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dump"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id44"&gt;2.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;dump&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
backend_dump.cpp
backend_dump.h
&lt;/pre&gt;
&lt;p&gt;有个dump命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PROC(dump, &amp;quot;b&amp;quot;),
&lt;/pre&gt;
&lt;p&gt;相当于redis 的keys,&lt;/p&gt;
&lt;p&gt;收到这个命令, 服务器新开一个线程, 把所有数据通过一个socket发过来, 问题:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;非redis 协议&lt;/li&gt;
&lt;li&gt;容易断&lt;/li&gt;
&lt;li&gt;有scan, 应该就不需要这个了 (不过这个简单, 简单一个命令就可以做backup了)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/ndb$ printf '*1\r\n$4\r\ndump\r\n' | socat - TCP:localhost:8888,shut-close | xxd
0000000: 350a 6265 6769 6e0a 0a33 0a73 6574 0a39  5.begin..3.set.9
0000010: 0a01 0000 0000 001e 953a 0a32 370a 3a95  .........:.27.:.
0000020: 1e00 0000 0000 0101 6b6b 6579 3a30 3030  ........kkey:000
0000030: 3030 3234 3833 3631 320a 0a33 0a73 6574  002483612..3.set
0000040: 0a39 0a01 0000 0000 001e 953b 0a32 370a  .9.........;.27.
0000050: 3b95 1e00 0000 0000 0101 6b6b 6579 3a30  ;.........kkey:0
0000060: 3030 3030 3738 3833 3133 310a 0a33 0a73  00007883131..3.s
0000070: 6574 0a39 0a01 0000 0000 001e 953c 0a32  et.9.........&amp;lt;.2
0000080: 370a 3c95 1e00 0000 0000 0101 6b6b 6579  7.&amp;lt;.........kkey
0000090: 3a30 3030 3030 3236 3435 3335 320a 0a33  :000002645352..3
00000a0: 0a73 6574 0a39 0a01 0000 0000 001e 953d  .set.9.........=
00000b0: 0a32 370a 3d95 1e00 0000 0000 0101 6b6b  .27.=.........kk
00000c0: 6579 3a30 3030 3030 3935 3033 3539 380a  ey:000009503598.
00000d0: 0a33 0a73 6574 0a39 0a01 0000 0000 001e  .3.set.9........
00000e0: 953e 0a32 370a 3e95 1e00 0000 0000 0101  .&amp;gt;.27.&amp;gt;.........
00000f0: 6b6b 6579 3a30 3030 3030 3938 3038 3139  kkey:00000980819
0000100: 360a 0a33 0a73 6574 0a39 0a01 0000 0000  6..3.set.9......
0000110: 001e 953f 0a32 370a 3f95 1e00 0000 0000  ...?.27.?.......
0000120: 0101 6b6b 6579 3a30 3030 3030 3238 3232  ..kkey:000002822
0000130: 3337 360a 0a33 0a73 6574 0a39 0a01 0000  376..3.set.9....
0000140: 0000 001e 9540 0a32 370a 4095 1e00 0000  .....&amp;#64;.27.&amp;#64;.....
0000150: 0000 0101 6b6b 6579 3a30 3030 3030 3134  ....kkey:0000014
0000160: 3936 3935 320a 0a33 0a73 6574 0a39 0a01  96952..3.set.9..
0000170: 0000 0000 001e 9541 0a32 370a 4195 1e00  .......A.27.A...
0000180: 0000 0000 0101 6b6b 6579 3a30 3030 3030  ......kkey:00000
0000190: 3432 3033 3036 370a 0a33 0a73 6574 0a39  4203067..3.set.9
00001a0: 0a01 0000 0000 001e 9542 0a32 370a 4295  .........B.27.B.
00001b0: 1e00 0000 0000 0101 6b6b 6579 3a30 3030  ........kkey:000
00001c0: 3030 3139 3133 3036 320a 0a33 0a73 6574  001913062..3.set
00001d0: 0a39 0a01 0000 0000 001e 9543 0a32 370a  .9.........C.27.
00001e0: 4395 1e00 0000 0000 0101 6b6b 6579 3a30  C.........kkey:0
00001f0: 3030 3030 3637 3432 3136 310a 0a33 0a65  00006742161..3.e
0000200: 6e64 0a32 0a31 300a 0a                   nd.2.10..
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id45"&gt;2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="incr"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id46"&gt;2.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;incr 如何保证原子性&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;通过Transaction上的锁实现.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="expire"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id47"&gt;2.5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何实现expire&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;ssdb为每个带有过期设置的key, 保存了2个结构:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;内存里面的一个sorted_set (全量)&lt;/li&gt;
&lt;li&gt;leveldb里面以 EXPIRATION_LIST_KEY 开头的一系列key.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ssdb 里面保留这个key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#define EXPIRATION_LIST_KEY &amp;quot;\xff\xff\xff\xff\xff|EXPIRE_LIST|KV&amp;quot;
&lt;/pre&gt;
&lt;p&gt;用这个key作为一个大zset(基于ssdb在leveldb上提供的zset), 当需要设置一个key的ttl时, 就向这个zset里面设置某个key的超时时间:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int ExpirationHandler::set_ttl(const Bytes &amp;amp;key, int ttl){
    int64_t expired = time_ms() + ttl * 1000;
    char data[30];
    int size = snprintf(data, sizeof(data), &amp;quot;%&amp;quot; PRId64, expired);
    if(size &amp;lt;= 0){
        log_error(&amp;quot;snprintf return error!&amp;quot;);
        return -1;
    }

    Locking l(&amp;amp;mutex);
    int ret = ssdb-&amp;gt;zset(this-&amp;gt;list_name, key, Bytes(data, size));

}
&lt;/pre&gt;
&lt;p&gt;同时还会放到一个内存的sorted_set(expiration_keys)里面去:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
expiration_keys.add(key.String(), expired);
&lt;/pre&gt;
&lt;p&gt;ssdb启动后, 会有一个线程把所有 EXPIRATION_LIST_KEY 这个 zset 里面的所有key扫描出来, 放到内存的 expiration_keys 里.&lt;/p&gt;
&lt;p&gt;回收时, 由一个线程从 expiration_keys 里面取出每个key, 把key和它对应的expire记录删掉:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if(handler-&amp;gt;expiration_keys.front(&amp;amp;key, &amp;amp;score)){
    int64_t now = time_ms();
    if(score &amp;lt;= now){
        log_debug(&amp;quot;expired %s&amp;quot;, key-&amp;gt;c_str());
        ssdb-&amp;gt;del(*key);
        ssdb-&amp;gt;zdel(handler-&amp;gt;list_name, *key);
        handler-&amp;gt;expiration_keys.pop_front();
        continue;
    }
}
&lt;/pre&gt;
&lt;p&gt;问题是: 所有的key都要装到内存, 内存会比较大, 而读的时候又没有利用上这个内存.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="benchmark"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id48"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;benchmark&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;请看:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="/ssdb-benchmark.html"&gt;ssdb benchmark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id13"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id49"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id14"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id50"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;读性能的问题&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;benchmark结果: &lt;strong&gt;100G数据&lt;/strong&gt; 时, 读性能稳定在大约5000qps&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="compact"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id51"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;如何compact&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;貌似是一个命令. 需要人工调用.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="expirekey"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id52"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;所有expire的key记录在内存&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;如果有10亿条, 每条100字节, 就需要100G+内存.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id15"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id53"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;兼容问题&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="del"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id54"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;del 兼容&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;因为leveldb 的接口, 删除实际上是一个写操作(写为空串).
所以删除接口不能返回这个key在是真的删了, 还是本来就不存在.&lt;/p&gt;
&lt;p&gt;所以在删除一个不存在的key时 for redis:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/redis/src$ redis-cli -p 2000 del xxx
(integer) 0
&lt;/pre&gt;
&lt;p&gt;for ssdb:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/redis/src$ redis-cli -p 8888 del xxx
(integer) 1
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="ttlkey"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id55"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;ttl一个不存在的key&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;ssdb:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
127.0.0.1:8888&amp;gt; ttl k
(error) ERR
&lt;/pre&gt;
&lt;p&gt;redis:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
127.0.0.1:5527&amp;gt; ttl k
(integer) -2
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id56"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;没有expire命令&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;改为通过ttl命令设置expire.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="set-key-val-ex-nx"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id57"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;不支持set key val ex nx&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;div class="section" id="scan"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id58"&gt;4.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;scan类&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="id17"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id59"&gt;4.4.5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;scan&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;一次在一个连接上吐回所有key, 而且要全放到内存resp里面再一次吐出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static int proc_scan(Server *serv, Link *link, const Request &amp;amp;req, Response *resp){
    if(req.size() &amp;lt; 4){
        resp-&amp;gt;push_back(&amp;quot;client_error&amp;quot;);
    }else{
        uint64_t limit = req[3].Uint64();
        KIterator *it = serv-&amp;gt;ssdb-&amp;gt;scan(req[1], req[2], limit);
        resp-&amp;gt;push_back(&amp;quot;ok&amp;quot;);
        while(it-&amp;gt;next()){
            resp-&amp;gt;push_back(it-&amp;gt;key);
            resp-&amp;gt;push_back(it-&amp;gt;val);
        }
        delete it;
    }
    return 0;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-hscan"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id60"&gt;4.4.5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;没有redis 的hscan&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;只有ssdb协议支持hscan, 用法是给出范围.&lt;/p&gt;
&lt;p&gt;支持redis的hgetall, hkeys, hvals&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id18"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id61"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ssdb 设计上, expire用区别于主key的另一个key存储&lt;/li&gt;
&lt;li&gt;oplog只记录key&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category><category term="redis"></category></entry><entry><title>twemproxy错误处理</title><link href="/twemproxy-error-handler.html" rel="alternate"></link><updated>2014-07-23T09:37:30+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-23:twemproxy-error-handler.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;如何处理错误&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#client-close" id="id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;client_close&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#server-close" id="id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;server_close&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id7"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;各个回调中应该怎么返回错误和错误检查&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#a-client-proxy" id="id8"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;(a)client-&amp;gt;proxy 路径&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#b-proxy-backend" id="id9"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;(b)proxy-&amp;gt;backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#c-backend-proxy" id="id10"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;(c)backend-&amp;gt;proxy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#d-proxy-client" id="id11"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;(d)proxy-&amp;gt;client&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id12"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#conn-err" id="id13"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;可能设置conn-&amp;gt;err的地方&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#return" id="id14"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;可能通过return 方式返回错误&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#msg-err" id="id15"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;可能设置msg-&amp;gt;err的地方&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#what-i-do" id="id16"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;what i do&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;错误处理是一个系统里面重要而容易忽略的环节, 我们读代码比写代码简单, 很大程度上就是因为读代码时基本不用考虑错误处理逻辑.&lt;/p&gt;
&lt;p&gt;twemproxy中, 主要的错误有:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;超内存 需要处理的地方最多&lt;/li&gt;
&lt;li&gt;连接后端错误&lt;/li&gt;
&lt;li&gt;server/cliet连接断掉&lt;/li&gt;
&lt;li&gt;msg 超时&lt;/li&gt;
&lt;li&gt;后端返回错误(E)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;如何处理错误&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;两种错误处理:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;关连接:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;比如内存不够.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;向客户读返回一个 Err response:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;能识别的逻辑错误, 比如连后端失败.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们先看conn上的几个回调&lt;/p&gt;
&lt;pre class="literal-block"&gt;
client:

    conn-&amp;gt;recv = msg_recv;
    conn-&amp;gt;recv_next = req_recv_next;
    conn-&amp;gt;recv_done = req_recv_done;

    conn-&amp;gt;send = msg_send;
    conn-&amp;gt;send_next = rsp_send_next;
    conn-&amp;gt;send_done = rsp_send_done;
    conn-&amp;gt;close = client_close;
    conn-&amp;gt;active = client_active;

server:

    conn-&amp;gt;recv = msg_recv;
    conn-&amp;gt;recv_next = rsp_recv_next;
    conn-&amp;gt;recv_done = rsp_recv_done;

    conn-&amp;gt;send = msg_send;
    conn-&amp;gt;send_next = req_send_next;
    conn-&amp;gt;send_done = req_send_done;

    conn-&amp;gt;close = server_close;
    conn-&amp;gt;active = server_active;
&lt;/pre&gt;
&lt;p&gt;最外层, 如果core_recv/core_send返回 非NC_Ok, 或者设置了 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;done&lt;/span&gt;&lt;/tt&gt; ,  &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;err&lt;/span&gt;&lt;/tt&gt; , 直接关连接:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
core_core(void *arg, uint32_t events)
{
    if (events &amp;amp; EVENT_ERR) {
        core_error(ctx, conn);
        return NC_ERROR;
    }

    if (events &amp;amp; EVENT_READ) {
        status = core_recv(ctx, conn);
        if (status != NC_OK || conn-&amp;gt;done || conn-&amp;gt;err) {
            core_close(ctx, conn);
            return NC_ERROR;
        }
    }

    if (events &amp;amp; EVENT_WRITE) {
        status = core_send(ctx, conn);
        if (status != NC_OK || conn-&amp;gt;done || conn-&amp;gt;err) {
            core_close(ctx, conn);
            return NC_ERROR;
        }
    }

    return NC_OK;
}
&lt;/pre&gt;
&lt;p&gt;这里:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;core_recv&lt;/tt&gt; 就是 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;recv&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;core_send&lt;/tt&gt; 就是 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;send&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;core_close 会调用 &lt;tt class="docutils literal"&gt;server_close&lt;/tt&gt; 或者 &lt;tt class="docutils literal"&gt;client_close&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="client-close"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;client_close&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;client_close_stats&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;conn-&amp;gt;unref (暂时不管)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;如果 conn-&amp;gt;rmsg 存在, 说明连接的读缓冲区有内容未处理,
把这个rmsg 丢掉&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;smsg&lt;/span&gt;&lt;/tt&gt;,  &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;imsg_q&lt;/span&gt;&lt;/tt&gt; 应该是为空的
conn 用rmsg做读缓冲, 读到了就放到server_conn-&amp;gt;omsg_q 里面, 所以clietn_conn-&amp;gt;smsg没用, client_conn-&amp;gt;imsg_q 也是完全没用
参考 &lt;a class="reference external" href="|filename|/notes/redis/twemproxy.rst"&gt;|filename|/notes/redis/twemproxy.rst&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;如果 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;omsg_q&lt;/span&gt;&lt;/tt&gt; 里面有消息, 这些消息已经发给后端了, 正在等待后端响应:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
for (msg = TAILQ_FIRST(&amp;amp;conn-&amp;gt;omsg_q); msg != NULL; msg = nmsg) {
    nmsg = TAILQ_NEXT(msg, c_tqe);

    conn-&amp;gt;dequeue_outq(ctx, conn, msg);

    if (msg-&amp;gt;done) {
        //日志: 这个消息的rsp被我丢了.
        req_put(msg);
    } else {
        msg-&amp;gt;swallow = 1;

        ASSERT(msg-&amp;gt;request);
        ASSERT(msg-&amp;gt;peer == NULL); //响应还没回来

        //日志: 这个消息被我标记为 swallow
        log_debug(LOG_INFO, &amp;quot;close c %d schedule swallow of req %&amp;quot;PRIu64&amp;quot; &amp;quot;
                  &amp;quot;len %&amp;quot;PRIu32&amp;quot; type %d&amp;quot;, conn-&amp;gt;sd, msg-&amp;gt;id, msg-&amp;gt;mlen,
                  msg-&amp;gt;type);
    }
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;至于 &lt;tt class="docutils literal"&gt;swallow&lt;/tt&gt;, 英语意思是 &lt;tt class="docutils literal"&gt;吞没&lt;/tt&gt;, 只有在上面这种情况下, 才会设置swallow标志, 对于这样的消息, 它的rsp回来之后, 就不应该转给client了, 而直接丢掉就行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static bool
rsp_filter(struct context *ctx, struct conn *conn, struct msg *msg)
{
    pmsg = TAILQ_FIRST(&amp;amp;conn-&amp;gt;omsg_q); //这是req, 至于为什么用 TAILQ_FIRST, 此时还没有设置msg-&amp;gt;peer.

    ASSERT(pmsg-&amp;gt;peer == NULL);
    ASSERT(pmsg-&amp;gt;request &amp;amp;&amp;amp; !pmsg-&amp;gt;done);
    if (pmsg-&amp;gt;swallow) {
        conn-&amp;gt;dequeue_outq(ctx, conn, pmsg);
        pmsg-&amp;gt;done = 1;

        log_debug(LOG_INFO, &amp;quot;swallow rsp %&amp;quot;PRIu64&amp;quot; len %&amp;quot;PRIu32&amp;quot; of req &amp;quot;
                  &amp;quot;%&amp;quot;PRIu64&amp;quot; on s %d&amp;quot;, msg-&amp;gt;id, msg-&amp;gt;mlen, pmsg-&amp;gt;id,
                  conn-&amp;gt;sd);

        rsp_put(msg);
        req_put(pmsg);
        return true;
    }
}
&lt;/pre&gt;
&lt;p&gt;另外在server_close的时候, 对server_conn-&amp;gt;imsg_q 和server_conn-&amp;gt;omsg_q, 如果有swallow req, 也直接丢掉(见server_close).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="server-close"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;server_close&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;server_close_stats&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;conn-&amp;gt;unref(conn)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;把server_conn中 的imsg_q 和omsg_q 中的消息 设置&lt;/p&gt;
&lt;pre class="literal-block"&gt;
msg-&amp;gt;done = 1
msg-&amp;gt;error = 1
msg-&amp;gt;err = conn-&amp;gt;err;
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;检查当前 c_conn上有没有完成的req, 给返回(因为这里对一些req设置了msg-&amp;gt;done, 所以有可能有完成的req):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if (raeq_done(c_conn, TAILQ_FIRST(&amp;amp;c_conn-&amp;gt;omsg_q))) {
    event_add_out(ctx-&amp;gt;evb, msg-&amp;gt;owner);
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;各个回调中应该怎么返回错误和错误检查&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;参看这个神图:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
*
*             Client+             Proxy           Server+
*                              (nutcracker)
*                                   .
*       msg_recv {read event}       .       msg_recv {read event}
*         +                         .                         +
*         |                         .                         |
*         \                         .                         /
*         req_recv_next             .             rsp_recv_next
*           +                       .                       +
*           |                       .                       |       Rsp
*           req_recv_done           .           rsp_recv_done      &amp;lt;===
*             +                     .                     +
*             |                     .                     |
*    Req      \                     .                     /
*    ===&amp;gt;     req_filter*           .           *rsp_filter
*               +                   .                   +
*               |                   .                   |
*               \                   .                   /
*               req_forward-//  (a) . (c)  \\-rsp_forward
*                                   .
*                                   .
*       msg_send {write event}      .      msg_send {write event}
*         +                         .                         +
*         |                         .                         |
*    Rsp' \                         .                         /     Req'
*   &amp;lt;===  rsp_send_next             .             req_send_next     ===&amp;gt;
*           +                       .                       +
*           |                       .                       |
*           \                       .                       /
*           rsp_send_done-//    (d) . (b)    //-req_send_done
*
*
* (a) -&amp;gt; (b) -&amp;gt; (c) -&amp;gt; (d) is the normal flow of transaction consisting
* of a single request response, where (a) and (b) handle request from
* client, while (c) and (d) handle the corresponding response from the
* server.
&lt;/pre&gt;
&lt;div class="section" id="a-client-proxy"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;(a)client-&amp;gt;proxy 路径&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;我们看core_recv 的调用链, 可能从什么地方返回这个错误码.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;core_recv()&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;conn-&amp;gt;recv(), 即msg_recv&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;msg_recv_chain(),&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;无内存: return NC_ENOMEM;&lt;/li&gt;
&lt;li&gt;读返回EAGAIN: return NC_OK,&lt;/li&gt;
&lt;li&gt;读出错: return NC_ERROR&lt;/li&gt;
&lt;li&gt;返回msg_parse()&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;msg_parse(), 调用msg-&amp;gt;parser(msg),&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;如果解析到一条消息(MSG_PARSE_OK), 返回msg_parsed()&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;如果需要REPAIR, 返回msg_repair()&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;msg_repair() 就是简单split一下, 可能返回NC_ENOMEM.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;如果parser出错, 函数里面同时设置 conn-&amp;gt;err, 并且返回 NC_ERROR&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static rstatus_t
msg_parse(struct context *ctx, struct conn *conn, struct msg *msg)
{
    msg-&amp;gt;parser(msg);

    switch (msg-&amp;gt;result) {
    case MSG_PARSE_OK:
        status = msg_parsed(ctx, conn, msg);
        break;

    case MSG_PARSE_REPAIR:
        status = msg_repair(ctx, conn, msg);
        break;

    case MSG_PARSE_AGAIN:
        status = NC_OK;
        break;

    default:
        status = NC_ERROR;
        conn-&amp;gt;err = errno;
        break;
    }

    return conn-&amp;gt;err != 0 ? NC_ERROR : status;
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;所以 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;msg-&amp;gt;parser()&lt;/span&gt;&lt;/tt&gt; 函数里面, 如果要返回错误, 是通过msg-&amp;gt;result设置为一个错误码做的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
r-&amp;gt;result = MSG_PARSE_ERROR;
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;接下来的重点是 &lt;tt class="docutils literal"&gt;msg_parsed()&lt;/tt&gt; , 他的返回值也会直接返回到core_core:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
 static rstatus_t
 msg_parsed(struct context *ctx, struct conn *conn, struct msg *msg)
 {
     conn-&amp;gt;recv_done(ctx, conn, msg, nmsg);

     return NC_OK;
 }

这里挺重要, 这个函数虽然调用了conn-&amp;gt;recv_done, 但是直接返回NC_OK, 而没有管conn-&amp;gt;recv_done的返回值, 实际上, conn-&amp;gt;recv_done() 没有返回值::

 conn_recv_done_t   recv_done;     /* read done handler */
 typedef void (*conn_recv_done_t)(struct context *, struct conn *, struct msg *, struct msg *);
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;到这里return链断了, 下面只能通过设置conn-&amp;gt;err来表示错误&lt;/strong&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;req_recv_done调用:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;req_forward (同样是一个void函数)   TODO: 这里在fragement里面, 我需要处理错误, 处理方法是设置c_conn-&amp;gt;err, 这还不好处理..&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;req_forward 如果出错,  是通过 &lt;tt class="docutils literal"&gt;req_forward_error&lt;/tt&gt; 来告诉客户端的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void
req_forward(struct context *ctx, struct conn *c_conn, struct msg *msg)
{
    s_conn = server_pool_conn(ctx, c_conn-&amp;gt;owner, key, keylen);
    if (s_conn == NULL) {
        req_forward_error(ctx, c_conn, msg);                //这里并不会设置c_conn-&amp;gt;err, 这时如果设置c_conn-&amp;gt;err, 就会直接关连接,
                                                            //这里的处理方法是: 设置msg-&amp;gt;err, 于是后面会构造一个ERR rsp返回给客户端, 这并不算一个连接错误.
        return;
    }

    c_conn-&amp;gt;enqueue_outq(ctx, c_conn, msg);                 //简单队列操作.
    s_conn-&amp;gt;enqueue_inq(ctx, s_conn, msg);

    if (TAILQ_EMPTY(&amp;amp;s_conn-&amp;gt;imsg_q)) {
        status = event_add_out(ctx-&amp;gt;evb, s_conn);
        if (status != NC_OK) {
            req_forward_error(ctx, c_conn, msg);            //这里会告诉客户端出错.
            s_conn-&amp;gt;err = errno;                            //这里设置 s_conn-&amp;gt;err, 关掉后端连接(什么时候处理 这里的s_conn-&amp;gt;err????? 还有机会有事件么?)
            return;
        }
    }
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;req_forward_error 需要标记msg-&amp;gt;err, 此时消息未被转发到后端, 此时为了告诉客户端出错, 需要:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;在c_conn上开始 ev_out 事件&lt;/li&gt;
&lt;li&gt;可写时, 构造一个ERR rsp返回给客户端.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;具体过程如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void
req_forward_error(struct context *ctx, struct conn *conn, struct msg *msg)
{
    rstatus_t status;

    ASSERT(conn-&amp;gt;client &amp;amp;&amp;amp; !conn-&amp;gt;proxy);

    msg-&amp;gt;done = 1;
    msg-&amp;gt;error = 1;
    msg-&amp;gt;err = errno;  //(如果内存分配失败, errno会被设为12, 对应错误消息'Cannot allocate memory')

    if (req_done(conn, TAILQ_FIRST(&amp;amp;conn-&amp;gt;omsg_q))) {
        status = event_add_out(ctx-&amp;gt;evb, conn);
        if (status != NC_OK) {
            conn-&amp;gt;err = errno;
        }
    }
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;到这里, 这个cliet-&amp;gt;proxy 的过程所有的出错路径都排查了.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="b-proxy-backend"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;(b)proxy-&amp;gt;backend&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="c-backend-proxy"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;(c)backend-&amp;gt;proxy&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这是另一个recv路径, 前半部分和(a)路径基本一样:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;core_recv()&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;conn-&amp;gt;recv(), 即msg_recv&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;msg_recv_chain(),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;msg_parse(), 调用msg-&amp;gt;parser(msg),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;msg_parsed()&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;到这里return链断了, 下面只能通过设置conn-&amp;gt;err来表示错误&lt;/strong&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;rsp_recv_done() 和rsp_forward():&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void
rsp_forward(struct context *ctx, struct conn *s_conn, struct msg *msg)
{
    pmsg-&amp;gt;peer = msg;
    msg-&amp;gt;peer = pmsg;

    msg-&amp;gt;pre_coalesce(msg);                                         //void函数.

    c_conn = pmsg-&amp;gt;owner;
    ASSERT(c_conn-&amp;gt;client &amp;amp;&amp;amp; !c_conn-&amp;gt;proxy);

    if (req_done(c_conn, TAILQ_FIRST(&amp;amp;c_conn-&amp;gt;omsg_q))) {           //这里调用req_done.
        status = event_add_out(ctx-&amp;gt;evb, c_conn);
        if (status != NC_OK) {
            c_conn-&amp;gt;err = errno;
        }
    }
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;这里rsp_forward比req_forward复杂, req_forward只是简单的dequeue_outq, enqueue_inq, event_add_out, 并没有太多的寄回设置conn-&amp;gt;err.&lt;/p&gt;
&lt;p&gt;rsp_forward则可能在pre_coalesce(), req_done(), post_coalesce() 函数里面设置.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;pre_coalesce():&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void
redis_pre_coalesce(struct msg *r)
{
    pr-&amp;gt;frag_owner-&amp;gt;nfrag_done++;

    switch (r-&amp;gt;type) {
    case MSG_RSP_REDIS_INTEGER:
        xxx;
    case MSG_RSP_REDIS_MULTIBULK:
        xxx;
    case MSG_RSP_REDIS_STATUS:
        xxx;
    default:
        mbuf = STAILQ_FIRST(&amp;amp;r-&amp;gt;mhdr);
        log_hexdump(LOG_ERR, mbuf-&amp;gt;pos, mbuf_length(mbuf), &amp;quot;rsp fragment &amp;quot;
                    &amp;quot;with unknown type %d&amp;quot;, r-&amp;gt;type);
        pr-&amp;gt;error = 1;
        pr-&amp;gt;err = EINVAL;       //这里都只是设置了msg-&amp;gt;err.
        break;
    }
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;在mget-improve之前, req_done() post_coalesce 都不会做什么设置.
TODO: 这里的post_coalesce我需要处理错误, 处理方法应该类似pre_coalesce, 设置msg-&amp;gt;error, msg-&amp;gt;err&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="d-proxy-client"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;(d)proxy-&amp;gt;client&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;接(c), rsp_forward 会在c_conn上开启out事件:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
status = event_add_out(ctx-&amp;gt;evb, c_conn);
&lt;/pre&gt;
&lt;p&gt;当c_conn可写时, 会触发 msg_send-&amp;gt;rsp_send_next-&amp;gt;rsp_send_done 路径.&lt;/p&gt;
&lt;p&gt;这里前几步和 (a) 也一样, 出错了直接通过返回值返回:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;msg_send 可能调用msg_send_chain 和rsp_send_next.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;rsp_send_next:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if (req_error(conn, pmsg)) { //这里也不会设置conn-&amp;gt;err. 所以如果在msg层没有内存, 也会返回一个错误给客户端. 但是如果在rsp_make_error的时候再次没内存, 就只能关闭连接了.
    msg = rsp_make_error(ctx, conn, pmsg);
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;msg_send_chain 可能通过返回值告诉最上层发生了错误 (直接调用conn_sendv):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static rstatus_t
msg_send_chain(struct context *ctx, struct conn *conn, struct msg *msg)
{
    conn-&amp;gt;smsg = NULL;
    n = conn_sendv(conn, &amp;amp;sendv, nsend);

    conn-&amp;gt;send_done(ctx, conn, msg);

    if (n &amp;gt;= 0) {
        return NC_OK;
    }
    return (n == NC_EAGAIN) ? NC_OK : NC_ERROR;
}
- 这里可能调用rsp_send_done, 单此时已经不能设置什么错误了
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id12"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;因为总的能逻辑就是 &lt;tt class="docutils literal"&gt;core_core&lt;/tt&gt; 里面的这段逻辑:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
status = core_recv(ctx, conn);
if (status != NC_OK || conn-&amp;gt;done || conn-&amp;gt;err) {
    core_close(ctx, conn);
    return NC_ERROR;
}
&lt;/pre&gt;
&lt;p&gt;在处理请求中, 比如读msg的时候, 发现没有内存了, 或者解析出错了, 有两个方法返回错误:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;通过返回值在core_recv 返回一个非NC_OK值.&lt;/li&gt;
&lt;li&gt;设置conn-&amp;gt;err 即可,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果在forward到后端时, 后端连接失败, 则可以通过 &lt;tt class="docutils literal"&gt;req_forward_error&lt;/tt&gt; 函数, 设置 msg-&amp;gt;err,
这时在 &lt;tt class="docutils literal"&gt;rsp_send_next&lt;/tt&gt; 中会用rsp_make_error生成一个err response返回给客户端.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;我们在forward时遇到内存不够, 调用req_forward_error就够了.&lt;/li&gt;
&lt;li&gt;收到response时遇到内存不够, 手动设置 msg-&amp;gt;err就行.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="conn-err"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id13"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;可能设置conn-&amp;gt;err的地方&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;parse失败.&lt;/li&gt;
&lt;li&gt;调nc_read() nc_writev(), server_connect() 出错.&lt;/li&gt;
&lt;li&gt;调用event_add_xx(), event_del_xx()&lt;/li&gt;
&lt;li&gt;req_get()/rsp_get() 调用msg_get() 无内存返回NULL&lt;/li&gt;
&lt;li&gt;rsp_make_error 无内存返回NULL&lt;/li&gt;
&lt;li&gt;发生timeout&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="return"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;可能通过return 方式返回错误&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
static rstatus_t
msg_parsed(struct context *ctx, struct conn *conn, struct msg *msg)
{
    ...
    nmsg = msg_get(msg-&amp;gt;owner, msg-&amp;gt;request, conn-&amp;gt;redis);
    if (nmsg == NULL) {
        mbuf_put(nbuf);
        return NC_ENOMEM;
    }
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="msg-err"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;可能设置msg-&amp;gt;err的地方&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
msg-&amp;gt;ferror         #是否有frag错误.
msg-&amp;gt;error          #错误标志, 0/1
msg-&amp;gt;err = errno;   #errno.
&lt;/pre&gt;
&lt;p&gt;比如memcache_pre_coalesce:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void
redis_pre_coalesce(struct msg *r)
{
    pr-&amp;gt;frag_owner-&amp;gt;nfrag_done++;

    switch (r-&amp;gt;type) {
    case MSG_RSP_REDIS_INTEGER:
        xxx;
    case MSG_RSP_REDIS_MULTIBULK:
    if (pr-&amp;gt;first_fragment) {
        mbuf = mbuf_get();
        if (mbuf == NULL) {
            pr-&amp;gt;error = 1;
            pr-&amp;gt;err = EINVAL;
            return;
        }
        STAILQ_INSERT_HEAD(&amp;amp;r-&amp;gt;mhdr, mbuf, next);
    }
    case MSG_RSP_REDIS_STATUS:
        xxx;
    default:
        mbuf = STAILQ_FIRST(&amp;amp;r-&amp;gt;mhdr);
        log_hexdump(LOG_ERR, mbuf-&amp;gt;pos, mbuf_length(mbuf), &amp;quot;rsp fragment &amp;quot;
                    &amp;quot;with unknown type %d&amp;quot;, r-&amp;gt;type);
        pr-&amp;gt;error = 1;
        pr-&amp;gt;err = EINVAL;       //这里都只是设置了msg-&amp;gt;err.
        break;
    }
}
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
void
redis_pre_coalesce(struct msg *r)
{
    if (pr-&amp;gt;first_fragment) {
        mbuf = mbuf_get();
        if (mbuf == NULL) {
            pr-&amp;gt;error = 1;
            pr-&amp;gt;err = EINVAL;
            return;
        }
        STAILQ_INSERT_HEAD(&amp;amp;r-&amp;gt;mhdr, mbuf, next);
    }
    ...
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="what-i-do"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id16"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;what i do&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;从前的msg_fragment是在msg_parsed里面, 还能通过return 返回错误.
因为作者认为在msg_parsed 之后, 消息必然在recv_done里面传给后端了, 不会出错了. 所以recv_done等函数都是void函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static rstatus_t
msg_parsed(struct context *ctx, struct conn *conn, struct msg *msg)
{
    conn-&amp;gt;recv_done(ctx, conn, msg, nmsg);

    return NC_OK;
}
&lt;/pre&gt;
&lt;p&gt;TODO 3: 我的fragement也得放到这里的msg_parsed里面, 否则的话, 就得修改 recv_done的返回值了, 这个动作更大些.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>从twemproxy计算 redis hitrate</title><link href="/redis-hitrate.html" rel="alternate"></link><updated>2014-07-11T11:37:13+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-11:redis-hitrate.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#get" id="id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;GET&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hmget" id="id2"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;HMGET:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hgetall" id="id3"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;HGETALL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mget" id="id4"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;MGET&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;如何从proxy日志中, 理容response的字节数计算命中率:&lt;/p&gt;
&lt;div class="section" id="get"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;GET&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;key 不存在时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 get kkk
(nil)
$-1..
&lt;/pre&gt;
&lt;p&gt;key存在时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 set k v
OK
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 get k
&amp;quot;v&amp;quot;

$1..v..
&lt;/pre&gt;
&lt;p&gt;判断:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if rsp_len &amp;gt; 5 :
    hit
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="hmget"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id2"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;HMGET:&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;key 不存在时, 或者请求的field都不存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hmget kkk 1 2
1) (nil)
2) (nil)

*2..$-1..$-1..
&lt;/pre&gt;
&lt;p&gt;key 存在, 请求的field有存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hmset kk 1 xxx
OK
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hmget kk 1 2
1) &amp;quot;xxx&amp;quot;
2) (nil)

*2..$3..xxx..$-1..
&lt;/pre&gt;
&lt;p&gt;这样判断:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nfiled = narg - 2
if rsp_len &amp;gt; 3+len(str(nfeild))+(5*nfield):
    hit
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="hgetall"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id3"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;HGETALL&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;key 存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hgetall kk
1) &amp;quot;1&amp;quot;
2) &amp;quot;xxx&amp;quot;
*2..$1..1..$3..xxx..
&lt;/pre&gt;
&lt;p&gt;key不存在:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ redis-cli -p 4100 hgetall kkk
(empty list or set)

|*0..|
&lt;/pre&gt;
&lt;p&gt;判断:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if rsp_len &amp;gt; 4:
    hit
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="mget"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;MGET&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;用的比较少, 不能简单的从rsp_len来判断.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-latancy问题</title><link href="/redis-latancy.html" rel="alternate"></link><updated>2014-07-09T10:04:00+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-09:redis-latancy.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-latency-problems-troubleshooting" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis latency problems troubleshooting&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1.网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slow-commands" id="id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2.slow commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fork" id="id7"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3.fork&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#swapping" id="id8"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4.swapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof-and-disk-i-o" id="id9"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5.aof and disk I/O&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#expires" id="id10"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;6.expires&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;工具&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#watchdog" id="id12"&gt;1.7.1&amp;nbsp;&amp;nbsp;&amp;nbsp;watchdog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#latancy" id="id13"&gt;1.7.2&amp;nbsp;&amp;nbsp;&amp;nbsp;最新的latancy监控&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id14"&gt;1.8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-latency-problems-troubleshooting"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Redis latency problems troubleshooting&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;主要来自redis 作者的文章: &lt;a class="reference external" href="http://redis.io/topics/latency"&gt;http://redis.io/topics/latency&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这篇文章介绍了很多工具, iostat, vmstat&lt;/p&gt;
&lt;p&gt;测量:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
redis-cli --latency -h `host` -p `port`
&lt;/pre&gt;
&lt;p&gt;基准(不可能好于这个数):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./redis-cli --intrinsic-latency 100
Max latency so far: 573 microseconds.
Max latency so far: 695 microseconds.
Max latency so far: 919 microseconds.
Max latency so far: 1606 microseconds.
Max latency so far: 3191 microseconds.
Max latency so far: 9243 microseconds.
Max latency so far: 9671 microseconds.
Here we have an intrinsic latency of 9.7 milliseconds: this means that we can't ask better than that to Redis.
&lt;/pre&gt;
&lt;p&gt;可能的原因:&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id5"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;1.网络&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The typical latency of a 1 GBits/s network is about 200 us, while the latency with a Unix domain socket can be as low as 30 us.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;不要用虚拟机.&lt;/li&gt;
&lt;li&gt;长连接&lt;/li&gt;
&lt;li&gt;use Unix domain sockets&lt;/li&gt;
&lt;li&gt;MSET/MGET/pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;On Linux, some people can achieve better latencies by playing with :&lt;/dt&gt;
&lt;dd&gt;process placement (taskset), cgroups, real-time priorities (chrt), NUMA configuration (numactl), or by using a low-latency kernel.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Please note vanilla Redis is not really suitable to be bound on a single CPU core. Redis can fork background tasks that can be extremely CPU consuming like bgsave or AOF rewrite. These tasks must never run on the same core as the main event loop.&lt;/p&gt;
&lt;p&gt;from Redis 2.4 we use threads in Redis in order to perform some slow I/O operations in the background, mainly related to disk I/O,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="slow-commands"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id6"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;2.slow commands&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;建议:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;避免keys, sort, lrem, sunion&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="fork"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id7"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;3.fork&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;内存page为4K,  24 GB Redis instance requires a page table of 24 GB / 4 KB * 8 = 48 MB&lt;/li&gt;
&lt;li&gt;Xen 上更加糟糕.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;建议:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;使用较小的实例.(&amp;lt;10G)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="swapping"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;1.4&amp;nbsp;&amp;nbsp;&amp;nbsp;4.swapping&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;查看swap:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ cat /proc/18941/smaps  | grep Swap
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                156 kB
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="aof-and-disk-i-o"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;1.5&amp;nbsp;&amp;nbsp;&amp;nbsp;5.aof and disk I/O&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;write() + fdatasync()&lt;/p&gt;
&lt;p&gt;Both the write(2) and fdatasync(2) calls can be source of latency. For instance write(2) can block both when there is a system wide sync in progress, or when the output buffers are full and the kernel requires to flush on disk in order to accept new writes.&lt;/p&gt;
&lt;p&gt;close 也会导致flush.&lt;/p&gt;
&lt;p&gt;fdatasync 可能从几个ms到几s. 所以redis2.4 尽可能在另一个线程里面做fdatasync.&lt;/p&gt;
&lt;p&gt;When appendfsync is set to the value of no Redis performs no fsync. In this configuration the only source of latency can be write(2).&lt;/p&gt;
&lt;p&gt;测量:&lt;/p&gt;
&lt;blockquote&gt;
sudo strace -p $(pidof redis-server) -T -e trace=fdatasync -f&lt;/blockquote&gt;
&lt;p&gt;因为fdatasync 是在另一个线程, 所以需要加-f&lt;/p&gt;
&lt;p&gt;However since write(2) is also used in order to write data to the client sockets this will likely show too many things unrelated to disk I/O. Apparently there is no way to tell strace to just show slow system calls so I use the following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
strace -f -p $(pidof redis-server) -T -e trace=fdatasync,write 2&amp;gt;&amp;amp;1 | grep -v '0.0' | grep -v unfinished
&lt;/pre&gt;
&lt;p&gt;建议:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;appendfsync no&lt;/li&gt;
&lt;li&gt;Using an SSD disk can help as well,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用这个, 我们在做copy 的时候, 可以观察到:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nhmset\r\n$37\r\np-lc-d687791&amp;quot;..., 272475) = 272475 &amp;lt;0.036430&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;2.030435&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;0.012418&amp;gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nHMSET\r\n$37\r\np-lc-6787211&amp;quot;..., 73) = 73 &amp;lt;0.125906&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;4.476948&amp;gt;
[pid 24734] &amp;lt;... write resumed&amp;gt; )       = 294594 &amp;lt;2.477184&amp;gt;   (2.47s)
&lt;/pre&gt;
&lt;p&gt;此时输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./_binaries/redis-cli --latency-history -h 10.38.114.60 -p 2000
min: 0, max: 223, avg: 1.24 (1329 samples) -- 15.01 seconds range
min: 0, max: 2500, avg: 3.46 (1110 samples) -- 15.00 seconds range   (这里观察到2.5s)
min: 0, max: 5, avg: 1.01 (1355 samples) -- 15.01 seconds range
&lt;/pre&gt;
&lt;p&gt;watchdog 输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[24734] 07 Jul 10:54:41.006 * Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.
[24734 | signal handler] (1404701682)
--- WATCHDOG TIMER EXPIRED ---
bin/redis-server *:2000(logStackTrace+0x4b)[0x443bdb]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
/lib64/tls/libpthread.so.0[0x302b80c420]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
bin/redis-server *:2000(flushAppendOnlyFile+0x76)[0x43f616]
bin/redis-server *:2000(serverCron+0x325)[0x41b5b5]
bin/redis-server *:2000(aeProcessEvents+0x2b2)[0x416a22]
bin/redis-server *:2000(aeMain+0x3f)[0x416bbf]
bin/redis-server *:2000(main+0x1c8)[0x41dcd8]
/lib64/tls/libc.so.6(__libc_start_main+0xdb)[0x302af1c4bb]
bin/redis-server *:2000[0x415b1a]
[24734 | signal handler] (1404701682) --------
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="expires"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;1.6&amp;nbsp;&amp;nbsp;&amp;nbsp;6.expires&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;if the database contains has many many keys expiring in the same second, and this keys are at least 25% of the current population of keys with an expire set,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;1.7&amp;nbsp;&amp;nbsp;&amp;nbsp;工具&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="watchdog"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id12"&gt;1.7.1&amp;nbsp;&amp;nbsp;&amp;nbsp;watchdog&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;redis2.6 自带. 通过时钟中断定时触发检查:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
CONFIG SET watchdog-period 500
&lt;/pre&gt;
&lt;p&gt;会在发现有大延迟时, 打印日志.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="latancy"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id13"&gt;1.7.2&amp;nbsp;&amp;nbsp;&amp;nbsp;最新的latancy监控&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;配置:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
latency-monitor-threshold 100
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;1.8&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;2, 3, 5 我们都遇到了.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-aof-latency</title><link href="/redis-aof-latency.html" rel="alternate"></link><updated>2014-07-09T08:36:06+08:00</updated><author><name>ning</name></author><id>tag:,2014-07-09:redis-aof-latency.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;一些分析&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id12"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么慢查询看不到?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id13"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;观察&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#appendfsync-no" id="id14"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么 appendfsync no 无效&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id15"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;一些想法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#page-cache" id="id16"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于page cache&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id17"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;查看当前page cache 状态&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id18"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;参数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#stable-page-write" id="id19"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Stable Page Write&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id20"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;查看线上&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dirty-ratio" id="id21"&gt;3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;调整dirty_ratio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dirty-expire-centisecs" id="id22"&gt;3.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;调整 dirty_expire_centisecs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id23"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id24"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;相关&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;我的redis配置的aof如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
appendonly yes
appendfsync everysec
&lt;/pre&gt;
&lt;p&gt;redis-mgr配置每天早上 6:00-8:00 做aof_rewrite 和 rdb, 所以每天早上这段时间, 我们就会收到twempxoy的forward_err报警, 大约每分钟会损失5000个请求.&lt;/p&gt;
&lt;p&gt;失败率是 10/10000.&lt;/p&gt;
&lt;p&gt;在线上测试, 做一个10G的文件写操作, 就会触发上面问题:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dd if=/dev/zero of=xxxxx bs=1M count=10000 &amp;amp;
&lt;/pre&gt;
&lt;p&gt;我们修改了 &lt;tt class="docutils literal"&gt;appendfsync no&lt;/tt&gt;, 发现这个问题能缓解, 但是不能解决.&lt;/p&gt;
&lt;p&gt;关于redis的各种延迟, 作者antirez的 &lt;a class="reference external" href="/redis-latancy.html"&gt;这篇文章&lt;/a&gt; 已经说的很清楚了.&lt;/p&gt;
&lt;p&gt;我们这里遇到的就是有disk I/O 的时候aof受到影响.&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id11"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;一些分析&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id12"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么慢查询看不到?&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;慢查询统计的时间只包括cpu计算的时间, 写aof这个过程不计入查询时间统计(也不应该计入)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id13"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;观察&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;用下面命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
strace -f -p $(pidof redis-server) -T -e trace=fdatasync,write 2&amp;gt;&amp;amp;1 | grep -v '0.0' | grep -v unfinished
&lt;/pre&gt;
&lt;p&gt;我们在做copy 的时候, 可以观察到:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nhmset\r\n$37\r\np-lc-d687791&amp;quot;..., 272475) = 272475 &amp;lt;0.036430&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;2.030435&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;0.012418&amp;gt;
[pid 24734] write(42, &amp;quot;*4\r\n$5\r\nHMSET\r\n$37\r\np-lc-6787211&amp;quot;..., 73) = 73 &amp;lt;0.125906&amp;gt;
[pid 24738] &amp;lt;... fdatasync resumed&amp;gt; )   = 0 &amp;lt;4.476948&amp;gt;
[pid 24734] &amp;lt;... write resumed&amp;gt; )       = 294594 &amp;lt;2.477184&amp;gt;   (2.47s)
&lt;/pre&gt;
&lt;p&gt;此时输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./_binaries/redis-cli --latency-history -h 10.38.114.60 -p 2000
min: 0, max: 223, avg: 1.24 (1329 samples) -- 15.01 seconds range
min: 0, max: 2500, avg: 3.46 (1110 samples) -- 15.00 seconds range   (这里观察到2.5s)
min: 0, max: 5, avg: 1.01 (1355 samples) -- 15.01 seconds range
&lt;/pre&gt;
&lt;p&gt;watchdog 输出:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[24734] 07 Jul 10:54:41.006 * Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.
[24734 | signal handler] (1404701682)
--- WATCHDOG TIMER EXPIRED ---
bin/redis-server *:2000(logStackTrace+0x4b)[0x443bdb]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
/lib64/tls/libpthread.so.0[0x302b80c420]
/lib64/tls/libpthread.so.0(__write+0x4f)[0x302b80b03f]
bin/redis-server *:2000(flushAppendOnlyFile+0x76)[0x43f616]
bin/redis-server *:2000(serverCron+0x325)[0x41b5b5]
bin/redis-server *:2000(aeProcessEvents+0x2b2)[0x416a22]
bin/redis-server *:2000(aeMain+0x3f)[0x416bbf]
bin/redis-server *:2000(main+0x1c8)[0x41dcd8]
/lib64/tls/libc.so.6(__libc_start_main+0xdb)[0x302af1c4bb]
bin/redis-server *:2000[0x415b1a]
[24734 | signal handler] (1404701682) --------
&lt;/pre&gt;
&lt;p&gt;所以确定是write hang住&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="appendfsync-no"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;为什么 appendfsync no 无效&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;当磁盘写buf满的时候, write就会阻塞, 释放一些buf才会允许继续写入,&lt;/p&gt;
&lt;p&gt;所以, 如果程序不调用sync, 系统就会在不确定的时候 做sync, 此时 &lt;tt class="docutils literal"&gt;wirte()&lt;/tt&gt; 就会hang住&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id15"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;一些想法&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;能否对rdb/aof_rewrite/cp等命令限速,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不可能针对每个进程(比如有其它写日志的进程) 都做限制. 所以最好不要这样.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;增加proxy timeout, 目前400ms, 增加到2000ms?&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;如果超时400ms, 想当于快速失败. 客户端重试效果一样, 所以还是不必改.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;master 关aof&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这个方法不需要做任何改动, 代价较小, 效果最好, 缺点是提高运维复杂性和数据可靠性, redis-mgr可以做这个支持.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;write 时的阻塞貌似无法避免, 能否用一个新的线程来做write呢?&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;关于这个想法写了个patch提给作者: &lt;a class="reference external" href="https://github.com/antirez/redis/pull/1862"&gt;https://github.com/antirez/redis/pull/1862&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;不过作者貌似不太感冒.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="page-cache"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id16"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于page cache&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;IO调度一般是针对读优化的, 因为读的时候是同步的, 进程读取不到, 就会睡眠.
写是异步的, 只是写到page cache.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;查看当前page cache 状态&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
grep ^Cached: /proc/meminfo # page cache size
grep ^Dirty: /proc/meminfo # total size of all dirty pages
grep ^Writeback: /proc/meminfo # total size of actively processed dirty pages
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;参数&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/test$ sysctl -a | grep dirty
vm.dirty_background_ratio = 10
vm.dirty_background_bytes = 0
vm.dirty_ratio = 20
vm.dirty_bytes = 0
vm.dirty_writeback_centisecs = 1500
vm.dirty_expire_centisecs = 3000
&lt;/pre&gt;
&lt;p&gt;详细参考: &lt;a class="reference external" href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt"&gt;https://www.kernel.org/doc/Documentation/sysctl/vm.txt&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/proc/sys/vm/dirty_expire_centisecs         #3000, 表示3000*0.01s = 30s, 队列中超过30s的被刷盘.
/proc/sys/vm/dirty_writeback_centisecs      #1500, 表示1500*0.01s = 15s, 内核pdflush wakeup 一次.

/proc/sys/vm/dirty_background_ratio
/proc/sys/vm/dirty_ratio
Both values are expressed as a percentage of RAM. When the amount of dirty pages reaches the first threshold (dirty_background_ratio), write-outs begin in the background via the “flush” kernel threads. When the second threshold is reached, processes will block, flushing in the foreground.


The problem with these variables is their minimum value: even 1% can be too much. This is why another two controls were introduced in 2.6.29:
/proc/sys/vm/dirty_background_bytes
/proc/sys/vm/dirty_bytes
&lt;/pre&gt;
&lt;p&gt;x_bytes 和 x_ratio是互斥的, 设置dirty_bytes 的时候, dirty_ratio 会被清0:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_bytes
0
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_ratio
20
root&amp;#64;ning-laptop:~# echo '5000000' &amp;gt; /proc/sys/vm/dirty_bytes
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_bytes
5000000
root&amp;#64;ning-laptop:~# cat /proc/sys/vm/dirty_ratio
0
&lt;/pre&gt;
&lt;p&gt;Lower values generate more I/O requests (and more interrupts), significantly decrease sequential I/O bandwidth but also decrease random I/O latency
数值小的时候, 会减小IO系统带宽, 同时减少 随机的IO延迟.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://monolight.cc/2011/06/barriers-caches-filesystems/"&gt;http://monolight.cc/2011/06/barriers-caches-filesystems/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stable-page-write"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Stable Page Write&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="http://yoshinorimatsunobu.blogspot.com/2014/03/why-buffered-writes-are-sometimes.html"&gt;http://yoshinorimatsunobu.blogspot.com/2014/03/why-buffered-writes-are-sometimes.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When a dirty page is written to disk, write() to the same dirty page is blocked until flushing to disk is done. This is called &lt;strong&gt;Stable Page Write&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This may cause write() stalls, especially when using slower disks. Without write cache, flushing to disk takes ~10ms usually, ~100ms in bad cases.&lt;/p&gt;
&lt;p&gt;有patch在较新的内核上能缓解这个问题, 原理是减少write调用 wait_on_page_writeback 的几率:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=1d1d1a767206fbe5d4c69493b7e6d2a8d08cc0a0
Here's the result of using dbench to test latency on ext2:

3.8.0-rc3:
 Operation      Count    AvgLat    MaxLat
 ----------------------------------------
 WriteX        109347     0.028    59.817
 ReadX         347180     0.004     3.391
 Flush          15514    29.828   287.283

Throughput 57.429 MB/sec  4 clients  4 procs  max_latency=287.290 ms

3.8.0-rc3 + patches:
 WriteX        105556     0.029     4.273
 ReadX         335004     0.005     4.112
 Flush          14982    30.540   298.634

Throughput 55.4496 MB/sec  4 clients  4 procs  max_latency=298.650 ms

As you can see, the maximum write latency drops considerably with this
patch enabled.
&lt;/pre&gt;
&lt;p&gt;据说xfs 也能解决问题.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id20"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;查看线上&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
$ cat /proc/sys/vm/dirty_background_ratio
10
$ cat /proc/sys/vm/dirty_ratio
20
&lt;/pre&gt;
&lt;p&gt;平时dirty:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ grep ^Dirty: /proc/meminfo
Dirty:            104616 kB
机器内存128G.
&lt;/pre&gt;
&lt;p&gt;早上做rdb/aof_rewrite时, dirty:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
500,000 kB (500M)
&lt;/pre&gt;
&lt;p&gt;都还没到达配置的 &lt;tt class="docutils literal"&gt;dirty_background_ratio&lt;/tt&gt; , &lt;tt class="docutils literal"&gt;dirty_ratio&lt;/tt&gt; 所以调这两个参数估计没用.&lt;/p&gt;
&lt;p&gt;测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#1. 最常90s.
vm.dirty_expire_centisecs = 9000
echo '9000' &amp;gt; /proc/sys/vm/dirty_expire_centisecs

#2. 改大dirty_ratio
echo '80' &amp;gt; /proc/sys/vm/dirty_ratio
&lt;/pre&gt;
&lt;div class="section" id="dirty-ratio"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id21"&gt;3.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;调整dirty_ratio&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;在一个io较差的48G机器上,  设置 dirty_ratio = 80, dirty 会涨的很高, 但是redis延迟看不明显的改善:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ grep ^Dirty: /proc/meminfo
Dirty:           8598180 kB  =&amp;gt;echo '80' &amp;gt; /proc/sys/vm/dirty_ratio
$ grep ^Dirty: /proc/meminfo
Dirty:          11887180 kB
$ grep ^Dirty: /proc/meminfo
Dirty:          21295624 kB
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="dirty-expire-centisecs"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id22"&gt;3.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;调整 dirty_expire_centisecs&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;看上去也没有效果, 有变差趋势.
因为我在线下是通过长期dd来压测, 和线上还不太一样.&lt;/p&gt;
&lt;p&gt;看来只能线上测试了.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id23"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;master关aof应该是目前最可以接受的方法&lt;/li&gt;
&lt;li&gt;antirez在做一个latency采样的工作&lt;/li&gt;
&lt;li&gt;XFS/Solaris 貌似没有这个问题.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id24"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;相关&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;a class="reference external" href="http://redis.io/topics/latency"&gt;http://redis.io/topics/latency&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;11 年就有的讨论 &lt;a class="reference external" href="https://groups.google.com/forum/#!msg/redis-db/jgGuGngDEb0/ZwnvUdx-gdAJ"&gt;https://groups.google.com/forum/#!msg/redis-db/jgGuGngDEb0/ZwnvUdx-gdAJ&lt;/a&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;作者本来想把write和fsync都移到另一个线程, 结论是把fsync移到一个线程了,&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Linkedin 的一个工程师做了这样一个实验, 测试用1/4的带宽来写的时候, 产生的延迟情况:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://blog.empathybox.com/post/35088300798/why-does-fwrite-sometimes-block"&gt;http://blog.empathybox.com/post/35088300798/why-does-fwrite-sometimes-block&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-config-hz</title><link href="/redis-config-hz.html" rel="alternate"></link><updated>2014-06-24T10:19:32+08:00</updated><author><name>ning</name></author><id>tag:,2014-06-24:redis-config-hz.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id3"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;现象&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#cen-li" id="id4"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;cen-li的分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hz-antirez" id="id5"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于hz, antirez 的一个解释&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id6"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id3"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;现象&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;redis 内存居高不下&lt;/p&gt;
&lt;p&gt;我们上线了一个新的业务后, 单实例内存从4G彪到6G左右, 凌晨低峰期大约5G. 调整cache时间, 由4h改为2h, 未见内存下降.&lt;/p&gt;
&lt;p&gt;怀疑是key已经过期, 但是并未淘汰. 通过把线上aof重放到线下看, 线上有19M个key, 线下只有12M个key, 说明存在很多脏key(过期但是未淘汰)&lt;/p&gt;
&lt;p&gt;修改配置 &lt;tt class="docutils literal"&gt;HZ=100&lt;/tt&gt; , 加速淘汰, 内存开始下降, 从5.5G下降到3.5G.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cen-li"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;cen-li的分析&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;至于hz应该设什么值, 可以参考 cen-li的分析: &lt;a class="reference external" href="http://cen-li.github.io/redis-expire.html"&gt;http://cen-li.github.io/redis-expire.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;总结下来:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;key的淘汰有三个时机:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;主动(cron定时执行)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;每秒执行HZ次(理想情况), 每次执行一个固定时间片: &lt;tt class="docutils literal"&gt;1s/HZ/4&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;被动&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;写操作时, 发现内存超过maxmemory, 此时淘汰n个key, 直到内存降到配置maxmemory以下.&lt;/li&gt;
&lt;li&gt;读操作时, 发现当前读取的key已经过期, 则淘汰掉.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;内存不满的集群, 主要受到cron淘汰机制的制约, 此时有一个算法来淘汰, 此时我们可以得出 &lt;tt class="docutils literal"&gt;脏key率&lt;/tt&gt; 和 &lt;tt class="docutils literal"&gt;key 淘汰速度&lt;/tt&gt; 的关系:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
X: 脏key率
Y: 每个主程序循环内执行loop2次数 (Y &amp;gt;= 1)
HZ: 每秒执行多少次cron
qps：qps为key的过期速度，不考虑流量的波动的话，约等于当时的过期操作的请求数
&lt;/pre&gt;
&lt;p&gt;得出如下关系:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
X = qps / (20 * HZ * Y)
&lt;/pre&gt;
&lt;p&gt;因为 &lt;tt class="docutils literal"&gt;Y &amp;gt;= 1&lt;/tt&gt;, 所以上面公式给出了一个 &lt;tt class="docutils literal"&gt;脏key率 X&lt;/tt&gt; 的上限, 比如:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
HZ=10  =&amp;gt; X&amp;lt;=pqs/200.
HZ=100 =&amp;gt; X&amp;lt;=pqs/2000.
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;调大HZ会导致redis空闲时的cpu占用上升, 我们的场景下单实例CPU占用大约增加 &lt;tt class="docutils literal"&gt;1%&lt;/tt&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;其它:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;aof rewrite和rdb不会包括已过期的key&lt;/li&gt;
&lt;li&gt;从库不执行过期操作, 主库过期一个key时，会生成一个DEL操作，该操作会同步到从库。&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="hz-antirez"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;关于hz, antirez 的一个解释&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://groups.google.com/forum/#!topic/redis-db/6kILekxQXBM"&gt;https://groups.google.com/forum/#!topic/redis-db/6kILekxQXBM&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Redis HZ was 10 in 2.4
Redis HZ is 100 in 2.6
2.8 里面增加HZ配置, 默认10.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;对于快速淘汰的cache集群, 应该设置较大的hz, 100是一个无害值.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>twemproxy-deadlock-on-signal_handler</title><link href="/twemproxy-deadlock-on-signal_handler.html" rel="alternate"></link><updated>2014-06-14T05:54:42+08:00</updated><author><name>ning</name></author><id>tag:,2014-06-14:twemproxy-deadlock-on-signal_handler.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;现象&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#localtime" id="id8"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;localtime() 的实现&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#tz-convert-is-not-signal-safe" id="id9"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;__tz_convert is not signal-safe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#free-signal-safe" id="id10"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;类似的, free()也不是signal-safe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;模拟复现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id12"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;修复&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#signal-safe-thread-safe" id="id13"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;signal-safe/thread safe/可重入&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#sprintfasync-signal-safe" id="id14"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;sprintf不是async-signal-safe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#async-signal-safe" id="id15"&gt;5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;确定一个函数是否 async-signal-safe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id16"&gt;5.3&amp;nbsp;&amp;nbsp;&amp;nbsp;其它系统中&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#as-safe" id="id17"&gt;5.4&amp;nbsp;&amp;nbsp;&amp;nbsp;这些函数是AS-SAFE的&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id18"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#nginx" id="id19"&gt;6.1&amp;nbsp;&amp;nbsp;&amp;nbsp;nginx为什么没有这个问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mysql" id="id20"&gt;6.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id21"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#reference" id="id22"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;现象&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;我们的 &lt;a class="reference external" href="https://github.com/idning/redis-mgr"&gt;redis-mgr&lt;/a&gt; 会默认对集群中的第一个twemproxy使用 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-v&lt;/span&gt; 5&lt;/tt&gt; 打印 &lt;tt class="docutils literal"&gt;notice&lt;/tt&gt; 级别的日志, 切日志使用的是, &lt;tt class="docutils literal"&gt;kill &lt;span class="pre"&gt;-HUP&lt;/span&gt;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;线上发现两次切日志之后twemproxy停止响应, gdb:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Loaded symbols for /lib64/ld-linux-x86-64.so.2
__lll_lock_wait_private () at ../nptl/sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:97
97      ../nptl/sysdeps/unix/sysv/linux/x86_64/lowlevellock.S: No such file or directory.
        in ../nptl/sysdeps/unix/sysv/linux/x86_64/lowlevellock.S
(gdb) bt
#0  __lll_lock_wait_private () at ../nptl/sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:97
#1  0x00007f0393918b2d in _L_lock_1934 () at tzset.c:138
#2  0x00007f03939188e7 in __tz_convert (timer=0x7f0393bfd9f4, use_localtime=1, tp=0x7f0393c00360) at tzset.c:619
#3  0x0000000000410fba in _log (file=0x431036 &amp;quot;nc_signal.c&amp;quot;, line=122, panic=0, fmt=0x43101c &amp;quot;signal %d (%s) received%s&amp;quot;) at nc_log.c:140
#4  0x000000000041016c in signal_handler (signo=&amp;lt;value optimized out&amp;gt;) at nc_signal.c:122
#5  &amp;lt;signal handler called&amp;gt;

#6  0x00007f03939552d5 in *__GI___xstat (vers=&amp;lt;value optimized out&amp;gt;, name=&amp;lt;value optimized out&amp;gt;, buf=0x7fff2a266fc0) at ../sysdeps/unix/sysv/linux/wordsize-64/xstat.c:38
#7  0x00007f03939193f0 in __tzfile_read (file=0x7f03939c5b7c &amp;quot;/etc/localtime&amp;quot;, extra=0, extrap=&amp;lt;value optimized out&amp;gt;) at tzfile.c:173
#8  0x00007f03939187a4 in tzset_internal (always=&amp;lt;value optimized out&amp;gt;, explicit=&amp;lt;value optimized out&amp;gt;) at tzset.c:439
#9  0x00007f0393918909 in __tz_convert (timer=0x7fff2a267158, use_localtime=1, tp=0x7f0393c00360) at tzset.c:624
#10 0x0000000000410fba in _log (file=0x42ed0c &amp;quot;nc_server.c&amp;quot;, line=645, panic=0, fmt=0x42ece0 &amp;quot;key '%.*s' on dist %d maps to server '%.*s'&amp;quot;) at nc_log.c:140

#11 0x000000000040887e in server_pool_server (ctx=0x1c0e090, pool=0x1c0e360, key=0x1c150c2 &amp;quot;key:__rand_int__\r\n&amp;quot;, keylen=16) at nc_server.c:644
#12 server_pool_conn (ctx=0x1c0e090, pool=0x1c0e360, key=0x1c150c2 &amp;quot;key:__rand_int__\r\n&amp;quot;, keylen=16) at nc_server.c:668
#13 0x000000000040ae04 in req_forward (ctx=0x1c0e090, conn=0x1c14e70, msg=0x1c14f70, nmsg=&amp;lt;value optimized out&amp;gt;) at nc_request.c:482
#14 req_recv_done (ctx=0x1c0e090, conn=0x1c14e70, msg=0x1c14f70, nmsg=&amp;lt;value optimized out&amp;gt;) at nc_request.c:524
#15 0x0000000000409f00 in msg_parsed (ctx=0x1c0e090, conn=0x1c14e70) at nc_message.c:451
#16 msg_parse (ctx=0x1c0e090, conn=0x1c14e70) at nc_message.c:581
#17 msg_recv_chain (ctx=0x1c0e090, conn=0x1c14e70) at nc_message.c:642
#18 msg_recv (ctx=0x1c0e090, conn=0x1c14e70) at nc_message.c:681
#19 0x0000000000406179 in core_recv (arg=0x1c14e70, events=&amp;lt;value optimized out&amp;gt;) at nc_core.c:158
#20 core_core (arg=0x1c14e70, events=&amp;lt;value optimized out&amp;gt;) at nc_core.c:293
#21 0x000000000041bbb8 in event_wait (evb=0x1c0e570, timeout=&amp;lt;value optimized out&amp;gt;) at nc_epoll.c:269
#22 0x0000000000405f89 in core_loop (ctx=0x1c0e090) at nc_core.c:316
#23 0x0000000000412a38 in nc_run (argc=&amp;lt;value optimized out&amp;gt;, argv=0x7fff2a267690) at nc.c:531
#24 main (argc=&amp;lt;value optimized out&amp;gt;, argv=0x7fff2a267690) at nc.c:580
(gdb)
&lt;/pre&gt;
&lt;p&gt;both of the &lt;tt class="docutils literal"&gt;normal Program flow&lt;/tt&gt; and the &lt;tt class="docutils literal"&gt;signal_handler&lt;/tt&gt; call &lt;tt class="docutils literal"&gt;__tz_convert()&lt;/tt&gt;, it looks that __tz_convert use a lock and this make the signal_handler never return, let's have a look &lt;tt class="docutils literal"&gt;__tz_convert&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;nc_signal.c:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void
signal_handler(int signo)
{
    struct signal *sig;
    void (*action)(void);
    char *actionstr;
    bool done;

    switch (signo) {
    case SIGHUP:
        actionstr = &amp;quot;, reopening log file&amp;quot;;
        action = log_reopen;
        break;
    }

    loga(&amp;quot;signal %d (%s) received%s&amp;quot;, signo, sig-&amp;gt;signame, actionstr);

    if (action != NULL) {
        action();
    }

    if (done) {
        exit(1);
    }
}
&lt;/pre&gt;
&lt;p&gt;loga 打印日志的时候, 会调用localtime():&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void
_log(const char *file, int line, int panic, const char *fmt, ...)
{
    ...
    t = time(NULL);
    local = localtime(&amp;amp;t);
    timestr = asctime(local);

    len += nc_scnprintf(buf + len, size - len, &amp;quot;[%.*s] %s:%d &amp;quot;,
                        strlen(timestr) - 1, timestr, file, line);

    va_start(args, fmt);
    len += nc_vscnprintf(buf + len, size - len, fmt, args);
    va_end(args);

    buf[len++] = '\n';

    n = nc_write(l-&amp;gt;fd, buf, len);
}
&lt;/pre&gt;
&lt;p&gt;首先 &lt;tt class="docutils literal"&gt;localtime()&lt;/tt&gt; 不是线程安全的, 同时它也不是signal-safe的, 所以在signal_handler里面使用localtime()就可能造成死锁.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="localtime"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;localtime() 的实现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;glibc/time/localtime.c:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
22  struct tm _tmbuf;
23
24
25  /* Return the `struct tm' representation of *T in local time,
26     using *TP to store the result.  */
27  struct tm *
28  __localtime_r (t, tp)
29       const time_t *t;
30       struct tm *tp;
31  {
32    return __tz_convert (t, 1, tp);
33  }
34  weak_alias (__localtime_r, localtime_r)
35
36
37  /* Return the `struct tm' representation of *T in local time.  */
38  struct tm *
39  localtime (t)
40       const time_t *t;
41  {
42    return __tz_convert (t, 1, &amp;amp;_tmbuf);
43  }
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;localtime()&lt;/tt&gt; 和 &lt;tt class="docutils literal"&gt;localtime_r()&lt;/tt&gt; 都是简单的调用 &lt;tt class="docutils literal"&gt;__tz_convert()&lt;/tt&gt;, 区别只是在于 &lt;tt class="docutils literal"&gt;localtime()&lt;/tt&gt; 使用了一个全局变量 &lt;tt class="docutils literal"&gt;_tmbuf&lt;/tt&gt; , 所以不是线程安全的.&lt;/p&gt;
&lt;p&gt;但是 &lt;tt class="docutils literal"&gt;__tz_convert()&lt;/tt&gt; 不是 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;signal-safe&lt;/span&gt;&lt;/tt&gt; 的.&lt;/p&gt;
&lt;div class="section" id="tz-convert-is-not-signal-safe"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;__tz_convert is not signal-safe&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;glibc/time/tzset.c:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
39  /* This locks all the state variables in tzfile.c and this file.  */
40  __libc_lock_define_initialized (static, tzset_lock)

...

613 /* Return the `struct tm' representation of *TIMER in the local timezone.
614    Use local time if USE_LOCALTIME is nonzero, UTC otherwise.  */
615 struct tm *
616 __tz_convert (const time_t *timer, int use_localtime, struct tm *tp)
617 {
618   long int leap_correction;
619   int leap_extra_secs;
620
621   if (timer == NULL)
622     {
623       __set_errno (EINVAL);
624       return NULL;
625     }
626
627   __libc_lock_lock (tzset_lock);
628
629   /* Update internal database according to current TZ setting.
630      POSIX.1 8.3.7.2 says that localtime_r is not required to set tzname.
631      This is a good idea since this allows at least a bit more parallelism.  */
632   tzset_internal (tp == &amp;amp;_tmbuf &amp;amp;&amp;amp; use_localtime, 1);
&lt;/pre&gt;
&lt;p&gt;这里用了一个锁 &lt;tt class="docutils literal"&gt;tzset_lock&lt;/tt&gt;, 它是用来保护对 &lt;tt class="docutils literal"&gt;tzset_internal()&lt;/tt&gt; 的调用的, &lt;tt class="docutils literal"&gt;tzset_internal&lt;/tt&gt; 是一个类似单态的模式, 第一次调用这个函数的时候初始化一些变量:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
399 static void
400 internal_function
401 tzset_internal (always, explicit)
402      int always;
403      int explicit;
404 {
405   static int is_initialized;
406   const char *tz;
407
408   if (is_initialized &amp;amp;&amp;amp; !always)
409     return;
410   is_initialized = 1;
      ...
465   __tzset_parse_tz (tz);
466 }
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;tzset_internal&lt;/tt&gt; 是用于初始化这个程序的时区设置, 并设置到 &lt;tt class="docutils literal"&gt;tz_rules&lt;/tt&gt; 这个全局变量:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
48  /* This structure contains all the information about a
49     timezone given in the POSIX standard TZ envariable.  */
50  typedef struct
51    {
52      const char *name;
53
54      /* When to change.  */
55      enum { J0, J1, M } type;    /* Interpretation of:  */
56      unsigned short int m, n, d; /* Month, week, day.  */
57      int secs;                   /* Time of day.  */
58
59      long int offset;            /* Seconds east of GMT (west if &amp;lt; 0).  */
60
61      /* We cache the computed time of change for a
62         given year so we don't have to recompute it.  */
63      time_t change;      /* When to change to this zone.  */
64      int computed_for;   /* Year above is computed for.  */
65    } tz_rule;
66
67  /* tz_rules[0] is standard, tz_rules[1] is daylight.  */
68  static tz_rule tz_rules[2];
&lt;/pre&gt;
&lt;p&gt;glibc作为一个库, 其实有三个地方可以初始化一些变量:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;程序启动的时候&lt;/li&gt;
&lt;li&gt;第一次调用的时候&lt;/li&gt;
&lt;li&gt;每次调用时再计算&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;第1个方法会造成不必要的开销(如果这个程序没调用过 &lt;tt class="docutils literal"&gt;localtime&lt;/tt&gt; , 也得初始化)&lt;/li&gt;
&lt;li&gt;第3个方法在每次调用时计算, 效率低,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以glibc的 &lt;tt class="docutils literal"&gt;localtime()&lt;/tt&gt; 选择在第一次调用时初始化, 熟悉单态模式的话就了解, 这里必须加一个锁. 就是这个锁导致 &lt;tt class="docutils literal"&gt;localtime()&lt;/tt&gt; 不是signal-safe的.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="free-signal-safe"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;类似的, free()也不是signal-safe&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;free/malloc也用了锁:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
2907        __libc_free (void *mem)
2908        {
          ...
2942          _int_free (ar_ptr, p, 0);
2943        }

3798        static void
3799        _int_free (mstate av, mchunkptr p, int have_lock)
3919          else if (!chunk_is_mmapped(p)) {
3920            if (! have_lock) {
3921              (void)mutex_lock(&amp;amp;av-&amp;gt;mutex);
3922              locked = 1;
3923            }
        ...
4052            if (! have_lock) {
4053              assert (locked);
4054              (void)mutex_unlock(&amp;amp;av-&amp;gt;mutex);
4055            }
4056          }
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id11"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;模拟复现&lt;/a&gt;&lt;/h2&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning/langtest/c/signal-safe$ cat test.c
#include &amp;lt;signal.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;time.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

void handler(int signum)
{
    char result[100];
    time_t now;
    struct tm time1;

    now = time(NULL);
    localtime_r(&amp;amp;now, &amp;amp;time1);
    strftime(result, 100, &amp;quot;%T&amp;quot;, &amp;amp;time1);
    printf(&amp;quot;At %s, user pressed Ctrl-C\n&amp;quot;, result);
}

int main (void)
{
    time_t now;
    struct tm ltime;
    int i;

    if (signal(SIGHUP, handler) == SIG_IGN){
        return;
    }

    now = time(NULL);
    for(i=0 ; ; i++){
        localtime_r(&amp;amp;now, &amp;amp;ltime);
        if(i%1000 == 0){
            printf(&amp;quot;%d\n&amp;quot;, i);
        }
    }

    return 0;
}
ning&amp;#64;ning-laptop ~/idning/langtest/c/signal-safe$ cat Makefile
all:
    cc test.c
    ./a.out  &amp;amp;
    sleep 1
    pkill -HUP -f 'a.out'
    ps aux | grep a.out
    gdb -p `pidof a.out`
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
(gdb) bt
#0  __lll_lock_wait_private () at ../nptl/sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:97
#1  0x00002b928c8bfb2d in _L_lock_1934 () at tzset.c:138
#2  0x00002b928c8bf8e7 in __tz_convert (timer=0x2b928cba49f4, use_localtime=1, tp=0x7fff5cef1840) at tzset.c:619
#3  0x0000000000400708 in handler ()
#4  &amp;lt;signal handler called&amp;gt;
#5  _IO_str_init_static_internal (sf=0x7fff5cef1d90, ptr=0x7de354 &amp;quot;8&amp;quot;, size=&amp;lt;value optimized out&amp;gt;, pstart=0x0)
    at strops.c:63
#6  0x00002b928c88d265 in _IO_vsscanf (string=0x7de354 &amp;quot;8&amp;quot;, format=0x2b928c96cb58 &amp;quot;%hu%n:%hu%n:%hu%n&amp;quot;,
    args=0x7fff5cef1eb0) at iovsscanf.c:44
#7  0x00002b928c87a5b8 in __sscanf (s=0x0, format=0x7de354 &amp;quot;8&amp;quot;) at sscanf.c:34
#8  0x00002b928c8bee32 in __tzset_parse_tz (tz=0x7de354 &amp;quot;8&amp;quot;) at tzset.c:212
#9  0x00002b928c8c00ac in __tzfile_compute (timer=1402735871, use_localtime=&amp;lt;value optimized out&amp;gt;,
    leap_correct=0x7fff5cef2090, leap_hit=0x7fff5cef209c, tp=0x7fff5cef20c0) at tzfile.c:682
#10 0x00002b928c8bf9a7 in __tz_convert (timer=0x7fff5cef2100, use_localtime=1, tp=0x7fff5cef20c0) at tzset.c:627
#11 0x00000000004007a1 in main ()
&lt;/pre&gt;
&lt;p&gt;这个栈和twemproxy出现的栈是一样的.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id12"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;修复&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;有没有``signal-safe`` + &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;thread-safe&lt;/span&gt;&lt;/tt&gt; 的localtime实现?&lt;/p&gt;
&lt;p&gt;至少是可以自己来实现这样一个逻辑的.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;修改signal_handler, 只使用signal-safe的函数:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;pull request 在此: &lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/231"&gt;https://github.com/twitter/twemproxy/pull/231&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="signal-safe-thread-safe"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;signal-safe/thread safe/可重入&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pubs.opengroup.org/onlinepubs/000095399/basedefs/xbd_chap03.html"&gt;http://pubs.opengroup.org/onlinepubs/000095399/basedefs/xbd_chap03.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;定义&lt;/p&gt;
&lt;pre class="literal-block"&gt;
3.313 Reentrant Function

A function whose effect, when called by two or more threads, is guaranteed to be as if the threads each executed the function one after another in an undefined order, even if the actual execution is interleaved.

Thread-Safe

A function that may be safely invoked concurrently by multiple threads. Each function defined in the System Interfaces volume of IEEE Std 1003.1-2001 is thread-safe unless explicitly stated otherwise. Examples are any &amp;quot;pure&amp;quot; function, a function which holds a mutex locked while it is accessing static storage, or objects shared among threads.

3.26 Async-Signal-Safe Function

A function that may be invoked, without restriction, from signal-catching functions. No function is async-signal-safe unless explicitly described as such.
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Reentrant:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不使用全局变量.&lt;/li&gt;
&lt;li&gt;不调用non-reentrant函数.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Thread-safe:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;要求较低,&lt;/li&gt;
&lt;li&gt;可以访问全局变量，不过需要加锁&lt;/li&gt;
&lt;li&gt;每次调用它返回不同的结果也没关系&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Async-Signal-Safe:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;只有几个固定的函数是 signal-safe的&lt;/li&gt;
&lt;li&gt;使用了锁的一定不是信号安全的（除非屏蔽了信号）&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可重入函数一定是线程安全的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可重入函数一定是Async-Signal-Safe的.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="sprintfasync-signal-safe"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;sprintf不是async-signal-safe&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;因为malloc/free不是signal-safe, 而gblic 的 vsnprintf用了malloc, 所以sprintf也不是signal-safe&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="async-signal-safe"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;5.2&amp;nbsp;&amp;nbsp;&amp;nbsp;确定一个函数是否 async-signal-safe&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;最好严格遵循 &lt;tt class="docutils literal"&gt;man 7 signal&lt;/tt&gt; 的列表, 注意不同系统中async-signal-safe函数列表不同, 比如这里是FreeBSD的库中 signal-safe情况:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.openbsd.org/cgi-bin/man.cgi?query=signal"&gt;http://www.openbsd.org/cgi-bin/man.cgi?query=signal&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里有glibc 的各个函数列表:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.gnu.org/software/libc/manual/html_node/Library-Summary.html#Library-Summary"&gt;http://www.gnu.org/software/libc/manual/html_node/Library-Summary.html#Library-Summary&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;下面文档定义了glibc中几种safe概念:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.gnu.org/software/libc/manual/html_node/POSIX-Safety-Concepts.html"&gt;http://www.gnu.org/software/libc/manual/html_node/POSIX-Safety-Concepts.html&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;cite&gt;MT-Safe&lt;/cite&gt; : Thread-Safe functions are safe to call in the presence of other threads&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;cite&gt;AS-Safe&lt;/cite&gt; :  Async-Signal-Safe functions are safe to call from asynchronous signal handlers. AS, in AS-Safe, stands for Asynchronous Signal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;cite&gt;AC-Safe&lt;/cite&gt; &lt;span class="classifier-delimiter"&gt;:&lt;/span&gt; &lt;span class="classifier"&gt;Async-Cancel-Safe functions are safe to call when asynchronous cancellation is enabled. AC in AC-Safe stands for Asynchronous Cancellation.&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;The POSIX standard defines only three functions to be AC-Safe: pthread_cancel, pthread_setcancelstate, and pthread_setcanceltype&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;下面文档定义了glibc中, 导致unsafe的原因:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.gnu.org/software/libc/manual/html_node/Unsafe-Features.html"&gt;http://www.gnu.org/software/libc/manual/html_node/Unsafe-Features.html&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;lock&lt;/tt&gt; Functions marked with lock as an AS-Unsafe feature may be interrupted by a signal while holding a non-recursive lock. If the signal handler calls another such function that takes the same lock, the result is a deadlock.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;corrupt&lt;/tt&gt; Functions marked with corrupt as an AS-Unsafe feature may corrupt data structures and misbehave when they interrupt,&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;heap&lt;/tt&gt; Functions marked with heap may call heap memory management functions from the malloc/free family of functions and are only as safe as those functions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如 &lt;tt class="docutils literal"&gt;vsnprintf&lt;/tt&gt; 就是AS-Unsafe, 因为它用了malloc/free这样的heap函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
— Function: int vsnprintf (char *s, size_t size, const char *template, va_list ap)
Preliminary: | MT-Safe locale | AS-Unsafe heap | AC-Unsafe mem | See POSIX Safety Concepts.
&lt;/pre&gt;
&lt;p&gt;所有printf系列函数都是 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;AS-Unsafe&lt;/span&gt;&lt;/tt&gt; 的.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id16"&gt;5.3&amp;nbsp;&amp;nbsp;&amp;nbsp;其它系统中&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;FreeBSD中更多的signal-safe函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ffs, htonl, htons, memccpy, memchr, memcmp, memcpy, memmove, memset, ntohl, ntohs, stpcpy, stpncpy, strcat, strchr, strcmp, strcpy, strcspn, strlen, strncat, strncmp, strncpy, strnlen, strpbrk, strrchr, strspn, strstr, strtok_r, wcpcpy, wcpncpy, wcscat, wcschr, wcscmp, wcscpy, wcscspn, wcslen, wcsncat, wcsncmp, wcsncpy, wcsnlen, wcspbrk, wcsrchr, wcsspn, wcsstr, wcstok, wmemchr, wmemcmp, wmemcpy, wmemmove, wmemset
&lt;/pre&gt;
&lt;p&gt;上面这些函数在目前已知的实现中, 都是signal-safe的, 参考下文, 这些函数已经加到signal-safe函数列表中, 参见: &lt;a class="reference external" href="http://austingroupbugs.net/view.php?id=692#c1609"&gt;http://austingroupbugs.net/view.php?id=692#c1609&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="as-safe"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;5.4&amp;nbsp;&amp;nbsp;&amp;nbsp;这些函数是AS-SAFE的&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;strtol&lt;/tt&gt; (参考http://www.gnu.org/software/libc/manual/html_node/Parsing-of-Integers.html#Parsing-of-Integers)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id18"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="nginx"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;6.1&amp;nbsp;&amp;nbsp;&amp;nbsp;nginx为什么没有这个问题&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;nginx自己实现了一套printf:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
u_char *
ngx_vslprintf(u_char *buf, u_char *last, const char *fmt, va_list args)
{
    u_char                *p, zero;
    ngx_uint_t             width, sign, hex, max_width, frac_width, n;

    while (*fmt &amp;amp;&amp;amp; buf &amp;lt; last) {

        /*
         * &amp;quot;buf &amp;lt; last&amp;quot; means that we could copy at least one character:
         * the plain character, &amp;quot;%%&amp;quot;, &amp;quot;%c&amp;quot;, and minus without the checking
         */

        if (*fmt == '%') {

            i64 = 0;
            ui64 = 0;
&lt;/pre&gt;
&lt;p&gt;ngx还使用了时间cache, 从而能够在打日志的时候使用正确的时间字符串.&lt;/p&gt;
&lt;p&gt;ngx 中时间cache是通过timer信号来更新的, 略复杂.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mysql"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id20"&gt;6.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mysql&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;也是实现了一族safe函数.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
size_t my_safe_snprintf(char* to, size_t n, const char* fmt, ...)
  ATTRIBUTE_FORMAT(printf, 3, 4);

/**
  A (very) limited version of snprintf, which writes the result to STDERR.
  &amp;#64;sa my_safe_snprintf
  Implemented with simplicity, and async-signal-safety in mind.
  &amp;#64;note Has an internal buffer capacity of 512 bytes,
  which should suffice for our signal handling routines.
*/
size_t my_safe_printf_stderr(const char* fmt, ...)
  ATTRIBUTE_FORMAT(printf, 1, 2);
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id21"&gt;7&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;记住linux中, localtime, vsnprintf, malloc/free都是 AS-Unsafe的.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="reference"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id22"&gt;8&amp;nbsp;&amp;nbsp;&amp;nbsp;Reference&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;linux signal-safe函数列表: &lt;a class="reference external" href="http://man7.org/linux/man-pages/man7/signal.7.html"&gt;http://man7.org/linux/man-pages/man7/signal.7.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;FreeBSD signal-safe 函数列表: &lt;a class="reference external" href="http://www.openbsd.org/cgi-bin/man.cgi?query=signal"&gt;http://www.openbsd.org/cgi-bin/man.cgi?query=signal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;FreeBSD 中 其它可以认为signal-safe的函数(目前已知实现都是safe的): &lt;a class="reference external" href="http://austingroupbugs.net/view.php?id=692#c1609"&gt;http://austingroupbugs.net/view.php?id=692#c1609&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;glibc 中所有函数是否signal-safe: &lt;a class="reference external" href="http://www.gnu.org/software/libc/manual/html_node/Library-Summary.html#Library-Summary"&gt;http://www.gnu.org/software/libc/manual/html_node/Library-Summary.html#Library-Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;va_start 是宏&lt;/li&gt;
&lt;li&gt;glibc代码(这个网站不错): &lt;a class="reference external" href="http://code.woboq.org/userspace/glibc/time/tzset.c.html"&gt;http://code.woboq.org/userspace/glibc/time/tzset.c.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一个libc free时内存溢出后死锁的问题(这个和信号无关, 分析很赞): &lt;a class="reference external" href="http://www.cnblogs.com/hokyhu/archive/2012/09/14/2685437.html"&gt;http://www.cnblogs.com/hokyhu/archive/2012/09/14/2685437.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://pubs.opengroup.org/onlinepubs/000095399/basedefs/xbd_chap03.html"&gt;http://pubs.opengroup.org/onlinepubs/000095399/basedefs/xbd_chap03.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;reentrant，thread-safe 和 async-signal-safe: &lt;a class="reference external" href="http://wangcong.org/blog/archives/506"&gt;http://wangcong.org/blog/archives/506&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;redis源码中之前也存在这个问题: &lt;a class="reference external" href="https://github.com/antirez/redis/issues/213"&gt;https://github.com/antirez/redis/issues/213&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-slow-query-20140528</title><link href="/slow-query-20140528.html" rel="alternate"></link><updated>2014-05-29T22:38:30+08:00</updated><author><name>ning</name></author><id>tag:,2014-05-29:slow-query-20140528.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;表现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;后续工作&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;表现&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;昨天, 我们优化过之后的twemproxy终于全流量上线了, 这个上线是通过数据迁移的方式, 把老的单实例redis上的数据导到redis集群的方式完成的.&lt;/p&gt;
&lt;p&gt;上线后, 发现切流量到集群后, 前端响应时间从7ms左右上升到15ms左右. 这和我们线下测试的结果严重不符.&lt;/p&gt;
&lt;p&gt;为此, 给proxy增加了一条notice日志, 用于观察响应时间.&lt;/p&gt;
&lt;p&gt;通过日志观察, 多数请求在proxy上看的响应时间都在1ms以下(从收到第一个包, 到最后响应发送完成):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ tail -f log/nutcracker.log  | grep nc_request.c:59 | grep MGET
[Thu May 29 22:45:13 2014] nc_request.c:59 req 2794795960 done on c 160 req_time: 0.274 type: MGET narg: 2 mlen: 48 key0: ccccccc_5965730729490562984, done: 1, error:0
[Thu May 29 22:45:13 2014] nc_request.c:59 req 2794795741 done on c 238 req_time: 2.230 type: MGET narg: 3 mlen: 82 key0: ccccccc_8781424545207799628, done: 1, error:0
[Thu May 29 22:45:13 2014] nc_request.c:59 req 2794795846 done on c 965 req_time: 1.635 type: MGET narg: 9 mlen: 284 key0: ccccccc_8734244876870904753, done: 1, error:0
&lt;/pre&gt;
&lt;p&gt;同时很多MGET, set, get等请求变得很慢. 而且, &lt;strong&gt;慢请求总是集中出现&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;分析&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;鉴于刚修改了proxy, 所以问题很可能出在 proxy上.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;会不会是被某种慢请求拖累.&lt;/p&gt;
&lt;p&gt;proxy是单进程模型, 如果某个连接上的一个请求慢, 那么后续的请求都会受到影响. 这比较符合我们观察到的 慢请求集中出现的特点.&lt;/p&gt;
&lt;p&gt;在日志中, 观察一批慢请求中, 第一个拖慢大家的请求是什么, 并未发现明显特点.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;会不会是因为客户端随机选择proxy不均匀?
这个问题之前出现过, 客户端使用time取模的方式选proxy, 于是同一秒内, 所有客户端都选择同一个proxy.&lt;/p&gt;
&lt;p&gt;针对今天的情况, 发现确实有不均匀的现象:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ tail -200000 log/nutcracker.log  | grep nc_request.c:59 | grep cou |  awk '{print $4}' | sort | uniq -c
    269 22:54:41
   2199 22:54:42
   1098 22:54:43
    578 22:54:44
   1448 22:54:45
   2720 22:54:46
    558 22:54:47
    507 22:54:48
   3084 22:54:49
   1677 22:54:50
    991 22:54:51
    396 22:54:52
    561 22:54:53
    423 22:54:54
    341 22:54:55
   1945 22:54:56
    727 22:54:57
    585 22:54:58
    453 22:54:59
    523 22:55:00
    520 22:55:01
    394 22:55:02
   2373 22:55:03
   3421 22:55:04
   3254 22:55:05
    595 22:55:06
&lt;/pre&gt;
&lt;p&gt;于是, 这个原因成了重点怀疑对象, 我甚至写了个脚本, 把每秒请求数和每秒慢请求化成图, 观察两者的相关性, 结果发现并无直接的相关.&lt;/p&gt;
&lt;p&gt;而且, 3000/s 的请求对proxy来说压力不算大, 看cpu也只占20%左右, 我们线下压力, cpu100%的时候大约能撑5w/s.&lt;/p&gt;
&lt;p&gt;到这时, 半天已然过去, 依然毫无头绪&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;第二天一大早, 开始着手从网络上去分析, 通过抓包, 观察客户端发给proxy, proxy再转给后端请求和响应, 这样可以确定是redis会给proxy慢呢, 还是proxy接收到响应后, 迟迟不回复给客户端.&lt;/p&gt;
&lt;p&gt;我先从proxy日志中找到一条慢日志, 然后到tcpdump的文件中通过key找, 找到:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
20:21:10.517897 IP 10.57.92.61.13766 &amp;gt; 10.57.85.40.2108: Flags [P.], ack 8852, win 4878, options [nop,nop,TS val 1266302405 ecr 1266305407], length 48
..A... ..+....E..d.i&amp;#64;.&amp;#64;..S
9\=
9U(5..&amp;lt;...x.........-.....
Kz=.KzI.*2^M
$4^M
mget^M
$27^M
ccccccc_1421521409803306481^M
20:21:10.518978 IP 10.57.92.61.13766 &amp;gt; 10.57.85.40.2108: Flags [P.], ack 8852, win 4878, options [nop,nop,TS val 1266302406 ecr 1266305408], length 48
..A... ..+....E..d.j&amp;#64;.&amp;#64;..R
9\=
9U(5..&amp;lt;.............-.....
Kz=.KzI.*2^M
$4^M
mget^M
$27^M
ccccccc_4472738999812611775^M
20:21:10.519474 IP 10.57.92.61.13766 &amp;gt; 10.57.85.40.2108: Flags [P.], ack 8852, win 4878, options [nop,nop,TS val 1266302406 ecr 1266305409], length 48
..A... ..+....E..d.k&amp;#64;.&amp;#64;..Q
9\=
9U(5..&amp;lt;.............-.....
Kz=.KzI.*2^M
$4^M
mget^M
$27^M
ccccccc_6172459129631416052^M
20:21:10.564537 IP 10.57.85.40.2108 &amp;gt; 10.57.92.61.13766: Flags [P.], ack 14768, win 4878, options [nop,nop,TS val 1266305454 ecr 1266302445], length 119
 ..+....A.....E...?Z&amp;#64;.=.8.
9U(
9\=.&amp;lt;5.............A......
KzI.Kz=.*1^M
$2^M
86^M      通过直接查询proxy, 发现ccccccc_1421521409803306481对应的value是86, 所以这里应该是前面第一个mget对应的response, 此时已经过去47ms.
*1^M
$-1^M
*1^M
$-1^M
*1^M
$3^M
287^M
*1^M
$-1^M
*1^M
$-1^M
:1^M
&lt;/pre&gt;
&lt;p&gt;我们发现这些请求的响应是一起回来的, 所以很有可能是因为后端hang住没有及时发回response.&lt;/p&gt;
&lt;p&gt;但是, 同一个tcp-stream上的前一个请求, 却是很快就响应的. 没有抓住有力证据.&lt;/p&gt;
&lt;p&gt;再用同样的方法, 就没有发现类似的case. 因为有的key很热, 没法定位到向后端转发的请求, 而且这基本靠肉眼, 太费劲了.&lt;/p&gt;
&lt;p&gt;还发现有一个case是proxy收到包之后过了5ms才转发给客户端的.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;从前在http服务上也遇到不少慢请求的问题, 记得有一次把一小时的tcpdump用脚本分成了1,000,000 多个流, 然后对每个流里面相邻两个包的时间做度量, 如果超过xx ms, 就说明有慢请求.
翻了一下脚本, 是把 tcpdump 出来的一行一行的文件用正则式做分析, 每个流切到一个文件去:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def deal(cap_file = '20110629-2000.all.txt'):
    all_line = int( system('cat %s | wc -l ' % cap_file))
    print all_line, 'lines'
    i = 0;
    for line in file(cap_file):
        if len(line) &amp;lt; 10: continue
        a = line.split(' ')[2].replace(':', '')
        b = line.split(' ')[4].replace(':', '')
        if (a.endswith('.80')):
            server = a
            client = b
            type = 'server-&amp;gt;client'
        else:
            server = b
            client = a
            type = 'client-&amp;gt;server'
        #print '##', client, server

        path = 'rst/' + client.replace('.', '/', 2)
        dirname = os.path.dirname(path)

        if not os.path.exists(dirname):
           os.makedirs(dirname)
        #print path
    #os.system('mkdir -p %s' % os.path.dirname(path))
        print &amp;gt;&amp;gt; file(path, 'a') , line,

        i += 1;
        if i % 10000 == 0:
            print i, 'lines finished'
&lt;/pre&gt;
&lt;p&gt;各种正则式... 无比费心.&lt;/p&gt;
&lt;p&gt;后来还用过一个tcpflow的工具, 可以帮助做这个切流的动作, 切完了之后再用一个脚本来分析.
重新下了个tcpfolw, 发现新版完全没法编译, 失去信心...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;打算自己解pcap文件算了.
尝试了一下pypcap, 发现真是难用..&lt;/p&gt;
&lt;p&gt;于是乎, 自己python实现了一个pcap文件的解析库, 代码: &lt;a class="reference external" href="https://github.com/idning/py-pcap-parser"&gt;py-pcap-parser&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;然后利用这个库做分析, 分析代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def dump():  #全量导出.
    pcap = PcapFile('a.pcap')
    cnt = 0
    for p in pcap.tcp_packets():
        cnt += 1
        if cnt % 100000 == 0:
            print '%d done' % cnt

        if not p.body:
            continue
        if filter(p):
            continue

        p.body = p.body.replace('\r\n', ' ')

        print TT('$ts $source:$source_port-&amp;gt;$dest:$dest_port  # $body', vars(p))

def findslow(): 找到慢的req-response对.
    pcap = PcapFile('a.pcap')
    cnt = 0
    for p in pcap.tcp_packets():
        cnt += 1
        if cnt % 100000 == 0:
            print '%d done' % cnt

        if not p.body:
            continue
        if filter(p):
            continue

        p.body = p.body.replace('\r\n', ' ')
        #print TT('$ts $source:$source_port-$dest:$dest_port  # $body', vars(p))

        key = gen_key(p)
        if key in last_active:
            diff = p.ts - last_active[gen_key(p)]
            #print diff
            if diff &amp;gt; 0.03 and not isreq(p):
                print '===========', TT('$ts $source:$source_port-&amp;gt;$dest:$dest_port  # $body', vars(last_pack[key]))
                print 'diff: %.3f' % diff,  TT('$ts $source:$source_port-&amp;gt;$dest:$dest_port  # $body', vars(p))
        else:
            #print 'nodiff: ',  TT('$ts $source:$source_port-$dest:$dest_port  # $body', vars(p))
            pass
&lt;/pre&gt;
&lt;p&gt;分析结果, 在 &lt;tt class="docutils literal"&gt;findslow&lt;/tt&gt; 输出里面, 慢请求一目了然:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
=========== 1401353285.95 10.57.27.53:56267-10.57.92.61:4101  # *4 $4 MGET $27 ccccccc_2111745379895909519 $27 ccccccc_4657069178215479939 $27 ccccccc_9137275223978700551
diff: 0.048 1401353285.99 10.57.92.61:4101-10.57.27.53:56267  # *3 $-1 $-1 $-1
=========== 1401353285.95 10.50.20.40:22796-10.57.92.61:4101  # *2 $4 MGET $27 ccccccc_5103351455575634229
diff: 0.047 1401353285.99 10.57.92.61:4101-10.50.20.40:22796  # *1 $-1
=========== 1401353285.96 10.38.12.42:42076-10.57.92.61:4101  # *2 $4 MGET $27 ccccccc_8030835834922447023
diff: 0.039 1401353285.99 10.57.92.61:4101-10.38.12.42:42076  # *1 $1 0
&lt;/pre&gt;
&lt;p&gt;上面这三个请求在不同时间点开始, 但是都是 &lt;tt class="docutils literal"&gt;1401353285.99&lt;/tt&gt; 才完成.&lt;/p&gt;
&lt;p&gt;在把这个慢请求(ccccccc_2111745379895909519)放到全量的 &lt;tt class="docutils literal"&gt;dump&lt;/tt&gt; 文件里面去找:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1401353285.95 10.57.27.53:56267-&amp;gt;10.57.92.61:4101  # *4 $4 MGET $27 ccccccc_2111745379895909519 $27 ccccccc_4657069178215479939 $27 ccccccc_9137275223978700551
1401353285.95 10.57.92.61:44471-&amp;gt;10.42.194.43:2111  # *2 $4 mget $27 ccccccc_2111745379895909519
1401353285.96 10.57.92.61:44471-&amp;gt;10.42.194.43:2111  # *2 $4 mget $27 ccccccc_8030835834922447023
1401353285.97 10.57.92.61:44471-&amp;gt;10.42.194.43:2111  # *2 $4 mget $27 ccccccc_7981749853668200998
1401353285.98 10.57.92.61:44471-&amp;gt;10.42.194.43:2111  # *2 $4 mget $27 ccccccc_8204274828390831284
&lt;/pre&gt;
&lt;p&gt;下面用 &lt;tt class="docutils literal"&gt;10.57.92.61:44471&lt;/tt&gt; 去找, 我们又发现大量请求在同一时间点回来了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1401353285.99 10.42.194.43:2111-&amp;gt;10.57.92.61:44471  # *1 $-1 *1 $-1 *1 $1 0 *1 $1 2 $303
&lt;/pre&gt;
&lt;p&gt;类似, 可以找到不少case, 说明确实是redis回的慢, 之前居然一直没有考虑过这个原因.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;查redis为什么慢. 很快就定位到SLOWLOG. 发现很多redis每秒有几个SLOWLOG, 每次耗时20-40ms, 这和proxy上看到的数值很吻合:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./bin/deploy.py cluster1 mastercmd 'slowlog get 10'
...

1016892
1401377576
24807
HGETALL
xxxxxxxxxxxxxxxxxxxxxxx:1194330698
1016891
1401377576
24523
HGETALL
xxxxxxxxxxxxxxxxxxxxxxx:1194330698
1016890
1401377576
25147
HGETALL
xxxxxxxxxxxxxxxxxxxxxxx:1194330698

这些key很多都是2w+ hash
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;后续工作&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;把slowlog监控加入到 &lt;a class="reference external" href="https://github.com/idning/redis-mgr"&gt;redis-mgr&lt;/a&gt; 常规监控&lt;/li&gt;
&lt;li&gt;遇到响应时间问题, 优先排查SLOWLOG.&lt;/li&gt;
&lt;li&gt;向业务限制HGETALL的使用&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ps: HGETALL果然是个坑, 虽然早有耳闻, 一直未引起重视.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>twemproxy-core-20140523</title><link href="/twemproxy-core-20140523.html" rel="alternate"></link><updated>2014-05-25T12:56:48+08:00</updated><author><name>ning</name></author><id>tag:,2014-05-25:twemproxy-core-20140523.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#what-happend" id="id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;what happend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#repetition" id="id2"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;Repetition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#explain" id="id3"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;explain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#add-a-testcase" id="id4"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;add-a-testcase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fix" id="id5"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;fix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#more-bugs" id="id6"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;more bugs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="what-happend"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;what happend&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;today we got a core of twemproxy:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ gdb -c core.14420 ./bin/nutcracker

(gdb) bt
#0  0x000000302af2e2ed in raise () from /lib64/tls/libc.so.6
#1  0x000000302af2fa3e in abort () from /lib64/tls/libc.so.6
#2  0x0000000000419c82 in nc_assert (cond=0x444dc0 &amp;quot;!TAILQ_EMPTY(&amp;amp;send_msgq) &amp;amp;&amp;amp; nsend != 0&amp;quot;, file=0x444aa8 &amp;quot;nc_message.c&amp;quot;, line=745, panic=1) at nc_util.c:308
#3  0x000000000040d0d6 in msg_send_chain (ctx=0x553090, conn=0x55b380, msg=0x0) at nc_message.c:745
#4  0x000000000040d568 in msg_send (ctx=0x553090, conn=0x55b380) at nc_message.c:820
#5  0x00000000004059af in core_send (ctx=0x553090, conn=0x55b380) at nc_core.c:173
#6  0x0000000000405ffe in core_core (arg=0x55b380, events=65280) at nc_core.c:301
#7  0x0000000000429297 in event_wait (evb=0x5652e0, timeout=389) at nc_epoll.c:269
#8  0x000000000040606f in core_loop (ctx=0x553090) at nc_core.c:316
#9  0x000000000041b109 in nc_run (nci=0x7fbfffea80) at nc.c:530
#10 0x000000000041b20d in main (argc=14, argv=0x7fbfffecc8) at nc.c:579
(gdb) f 3
#3  0x000000000040d0d6 in msg_send_chain (ctx=0x553090, conn=0x55b380, msg=0x0) at nc_message.c:745
745         ASSERT(!TAILQ_EMPTY(&amp;amp;send_msgq) &amp;amp;&amp;amp; nsend != 0);
(gdb) l
740             if (msg == NULL) {
741                 break;
742             }
743         }
744
745         ASSERT(!TAILQ_EMPTY(&amp;amp;send_msgq) &amp;amp;&amp;amp; nsend != 0);
746
747         conn-&amp;gt;smsg = NULL;
748
749         n = conn_sendv(conn, &amp;amp;sendv, nsend);
&lt;/pre&gt;
&lt;p&gt;it is caused by this &lt;tt class="docutils literal"&gt;ASSERT&lt;/tt&gt; at nc_message.c:745,&lt;/p&gt;
&lt;p&gt;this core is not always raise when we do the same request again,&lt;/p&gt;
&lt;p&gt;if we use -v 9 to debug, it never raise.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="repetition"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id2"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;Repetition&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;use gdb, we found that the msg we want to send is:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(gdb) p * (send_msgq.tqh_first )
$6 = {c_tqe = {tqe_next = 0x0, tqe_prev = 0x0, trace = {lastfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, lastline = 291, prevfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, prevline = 270}}, s_tqe = {tqe_next = 0x0, tqe_prev = 0x0,
    trace = {lastfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, lastline = 302, prevfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, prevline = 279}}, m_tqe = {tqe_next = 0x0, tqe_prev = 0x7fbfffe8c0, trace = {
      lastfile = 0x444aa8 &amp;quot;nc_message.c&amp;quot;, lastline = 712, prevfile = 0x444aa8 &amp;quot;nc_message.c&amp;quot;, prevline = 196}}, id = 6515, peer = 0x810cc0, owner = 0x55ae00, tmo_rbe = {left = 0x0, right = 0x0,
    parent = 0x0, key = 0, data = 0x0, color = 0 '\0'}, mhdr = {stqh_first = 0x82ecc0, stqh_last = 0x82ecc8}, mlen = 0, state = 0,
  pos = 0x82eaf4 &amp;quot;:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n:0\r\n&amp;quot;,
  token = 0x0, parser = 0x42713b &amp;lt;redis_parse_rsp&amp;gt;, result = MSG_PARSE_OK, pre_splitcopy = 0x427e1d &amp;lt;redis_pre_splitcopy&amp;gt;, post_splitcopy = 0x427f8a &amp;lt;redis_post_splitcopy&amp;gt;,
  pre_coalesce = 0x42816a &amp;lt;redis_pre_coalesce&amp;gt;, post_coalesce = 0x428557 &amp;lt;redis_post_coalesce&amp;gt;, type = MSG_RSP_REDIS_INTEGER, key_start = 0x0, key_end = 0x0, vlen = 0, end = 0x0, narg_start = 0x0,
  narg_end = 0x0, narg = 0, rnarg = 0, rlen = 0, integer = 0, frag_owner = 0x0, nfrag = 0, frag_id = 0, err = 0, error = 0, ferror = 0, request = 0, quit = 0, noreply = 0, done = 0, fdone = 0,
  first_fragment = 0, last_fragment = 0, swallow = 0, redis = 1}
&lt;/pre&gt;
&lt;p&gt;this is the only msg( and the last msg) in send_msgq, &lt;tt class="docutils literal"&gt;mlen=0&lt;/tt&gt; ,&lt;/p&gt;
&lt;p&gt;and it's peer request is a fragment of a delete cmd:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(gdb) p * (send_msgq.tqh_first -&amp;gt; peer )
$5 = {c_tqe = {tqe_next = 0x75e140, tqe_prev = 0x55b400, trace = {lastfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, lastline = 270, prevfile = 0x0, prevline = 0}}, s_tqe = {tqe_next = 0x0, tqe_prev = 0x0, trace = {
      lastfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, lastline = 302, prevfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, prevline = 279}}, m_tqe = {tqe_next = 0x0, tqe_prev = 0x0, trace = {lastfile = 0x444aa8 &amp;quot;nc_message.c&amp;quot;,
      lastline = 758, prevfile = 0x444aa8 &amp;quot;nc_message.c&amp;quot;, prevline = 712}}, id = 4515, peer = 0x5fe2c0, owner = 0x55b380, tmo_rbe = {left = 0x0, right = 0x0, parent = 0x0, key = 0, data = 0x0,
    color = 0 '\0'}, mhdr = {stqh_first = 0x6c1090, stqh_last = 0x6c1098}, mlen = 47, state = 0,
  pos = 0x6c0eef &amp;quot;*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_393307809209&amp;quot;..., token = 0x0, parser = 0x421279 &amp;lt;redis_parse_req&amp;gt;, result = MSG_PARSE_OK, pre_splitcopy = 0x427e1d &amp;lt;redis_pre_splitcopy&amp;gt;,
  post_splitcopy = 0x427f8a &amp;lt;redis_post_splitcopy&amp;gt;, pre_coalesce = 0x42816a &amp;lt;redis_pre_coalesce&amp;gt;, post_coalesce = 0x428557 &amp;lt;redis_post_coalesce&amp;gt;, type = MSG_REQ_REDIS_DEL,
  key_start = 0x6c0ed2 &amp;quot;rrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nD&amp;quot;...,
  key_end = 0x6c0eed &amp;quot;\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092&amp;quot;..., vlen = 0, end = 0x0,
  narg_start = 0x6c0ec0 &amp;quot;*2\r\n$3\r\ndel\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_566362775949&amp;quot;...,
  narg_end = 0x6c0ec2 &amp;quot;\r\n$3\r\ndel\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_56636277594915&amp;quot;..., narg = 2, rnarg = 0, rlen = 0, integer = 0, frag_owner = 0x75e4f0, nfrag = 0, frag_id = 1256, err = 0, error = 0, ferror = 0, request = 1, quit = 0,
  noreply = 0, done = 1, fdone = 1, first_fragment = 0, last_fragment = 1, swallow = 0, redis = 1}
&lt;/pre&gt;
&lt;p&gt;the orig msg is:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(gdb) p * (send_msgq.tqh_first -&amp;gt; peer -&amp;gt;frag_owner )
$23 = {c_tqe = {tqe_next = 0x0, tqe_prev = 0x0, trace = {lastfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, lastline = 291, prevfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, prevline = 270}}, s_tqe = {tqe_next = 0x0, tqe_prev = 0x0,
    trace = {lastfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, lastline = 302, prevfile = 0x444e28 &amp;quot;nc_request.c&amp;quot;, prevline = 279}}, m_tqe = {tqe_next = 0x5f9740, tqe_prev = 0x551f80, trace = {
      lastfile = 0x444aa8 &amp;quot;nc_message.c&amp;quot;, lastline = 360, prevfile = 0x444aa8 &amp;quot;nc_message.c&amp;quot;, prevline = 758}}, id = 4514, peer = 0x0, owner = 0x55b380, tmo_rbe = {left = 0x0, right = 0x0, parent = 0x0,
    key = 0, data = 0x0, color = 1 '\001'}, mhdr = {stqh_first = 0x0, stqh_last = 0x75e5c8}, mlen = 34, state = 27,
  pos = 0x74f15f &amp;quot;$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n&amp;quot;..., token = 0x0, parser = 0x421279 &amp;lt;redis_parse_req&amp;gt;, result = MSG_PARSE_FRAGMENT, pre_splitcopy = 0x427e1d &amp;lt;redis_pre_splitcopy&amp;gt;,
  post_splitcopy = 0x427f8a &amp;lt;redis_post_splitcopy&amp;gt;, pre_coalesce = 0x42816a &amp;lt;redis_pre_coalesce&amp;gt;, post_coalesce = 0x428557 &amp;lt;redis_post_coalesce&amp;gt;, type = MSG_REQ_REDIS_DEL,
  key_start = 0x74f142 &amp;quot;rrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\ncoun&amp;quot;...,
  key_end = 0x74f15d &amp;quot;\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3&amp;quot;..., vlen = 0, end = 0x0,
  narg_start = 0x74ed80 &amp;quot;*2\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r&amp;quot;,
  narg_end = 0x74ed82 &amp;quot;\r\n$3\r\nDEL\r\n$27\r\nrrr_kkk_3933078092091789232\r\n$27\r\nrrr_kkk_5663627759491506624\r\n*3\r\n$3\r\nDEL\r&amp;quot;, narg = 3, rnarg = 1, rlen = 0, integer = 0, frag_owner = 0x75e4f0,
  nfrag = 2, frag_id = 1256, err = 0, error = 0, ferror = 0, request = 1, quit = 0, noreply = 0, done = 1, fdone = 1, first_fragment = 1, last_fragment = 0, swallow = 0, redis = 1}
&lt;/pre&gt;
&lt;p&gt;we found that it's a DEL cmd with narg=3. the orig cmd is:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DEL rrr_kkk_3933078092091789232 rrr_kkk_5663627759491506624
&lt;/pre&gt;
&lt;p&gt;so we try to repetition this bug with lot's of MULTI-DEL.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="explain"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id3"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;explain&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;a MULTI-DEL cmd will split into many &lt;tt class="docutils literal"&gt;DEL&lt;/tt&gt; in nutcracker,&lt;/p&gt;
&lt;p&gt;response will coalesce. (all fragment except the first one will be rewrite to empty msg), following pic show the split and coalesce of msg:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-core-201405-001.png" /&gt;
&lt;p&gt;ok, let's check this code:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static rstatus_t
msg_send_chain(struct context *ctx, struct conn *conn, struct msg *msg)
{
    ...
    TAILQ_INIT(&amp;amp;send_msgq);
    array_set(&amp;amp;sendv, iov, sizeof(iov[0]), NC_IOV_MAX);
    nsend = 0;
    for (;;) {
        ASSERT(conn-&amp;gt;smsg == msg);

        TAILQ_INSERT_TAIL(&amp;amp;send_msgq, msg, m_tqe);

        for (mbuf = STAILQ_FIRST(&amp;amp;msg-&amp;gt;mhdr);
             mbuf != NULL &amp;amp;&amp;amp; array_n(&amp;amp;sendv) &amp;lt; NC_IOV_MAX &amp;amp;&amp;amp; nsend &amp;lt; limit;
             mbuf = nbuf) {
            nbuf = STAILQ_NEXT(mbuf, next);

            if (mbuf_empty(mbuf)) {
                continue;
            }

            mlen = mbuf_length(mbuf);
            if ((nsend + mlen) &amp;gt; limit) {
                mlen = limit - nsend;
            }

            ciov = array_push(&amp;amp;sendv);
            ciov-&amp;gt;iov_base = mbuf-&amp;gt;pos;
            ciov-&amp;gt;iov_len = mlen;

            nsend += mlen;
        }

        if (array_n(&amp;amp;sendv) &amp;gt;= NC_IOV_MAX || nsend &amp;gt;= limit) {
            break;
        }

        msg = conn-&amp;gt;send_next(ctx, conn);
        if (msg == NULL) {
            break;
        }
    }

    //log_debug(LOG_VVERB, &amp;quot;conn-&amp;gt;client: %d, len_sendv: %d nsend: %d&amp;quot;, conn-&amp;gt;client, array_n(&amp;amp;sendv), nsend);
    ASSERT(!TAILQ_EMPTY(&amp;amp;send_msgq) &amp;amp;&amp;amp; nsend != 0);
    conn-&amp;gt;smsg = NULL;
    n = conn_sendv(conn, &amp;amp;sendv, nsend);
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;conn_send&lt;/tt&gt; send no more than &lt;tt class="docutils literal"&gt;NC_IOV_MAX(128)&lt;/tt&gt; pieces in this function,&lt;/p&gt;
&lt;p&gt;if the first fragment of MULTI-DEL response is send on last batch. and this is the last msg in send queue, the next call of &lt;tt class="docutils literal"&gt;msg_send_chain&lt;/tt&gt; will got &lt;tt class="docutils literal"&gt;nsend == 0&lt;/tt&gt;:&lt;/p&gt;
&lt;p&gt;following img show such a case:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;mget on 126 keys&lt;/li&gt;
&lt;li&gt;a mutli-del cmd&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="" src="/imgs/twemproxy-core-201405-002.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="add-a-testcase"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;add-a-testcase&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;the test case with &lt;a class="reference external" href="https://github.com/idning/test-twemproxy"&gt;test-twemproxy&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def test_multi_delete_20140525():
    conn = redis.Redis('127.0.0.5', 4100)
    cnt = 126
    keys = ['key-%s'%i for i in range(cnt)]
    pipe = conn.pipeline(transaction=False)
    pipe.mget(keys)
    pipe.delete(*keys)
    print pipe.execute()
&lt;/pre&gt;
&lt;p&gt;see: &lt;a class="reference external" href="https://github.com/idning/test-twemproxy/blob/master/test_redis/test_del.py#L56-L63"&gt;https://github.com/idning/test-twemproxy/blob/master/test_redis/test_del.py#L56-L63&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fix"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;fix&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;we do not need this comment here:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ASSERT(!TAILQ_EMPTY(&amp;amp;send_msgq) &amp;amp;&amp;amp; nsend != 0);
&lt;/pre&gt;
&lt;p&gt;and we should eat all the fragment of MULTI-DEL in &lt;tt class="docutils literal"&gt;msg_send_chain&lt;/tt&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="more-bugs"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;more bugs&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;current master (8a4f5c0)can not pass following cases:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
test_redis.test_mget_mset.test_mget_special_key ... ERROR
test_redis.test_mget_mset.test_mget_special_key_2 ... ERROR
&lt;/pre&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>fatcache-cr</title><link href="/fatcache-cr.html" rel="alternate"></link><updated>2014-05-21T14:17:46+08:00</updated><author><name>ning</name></author><id>tag:,2014-05-21:fatcache-cr.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id8"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;设计理念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id9"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fc-request-c" id="id10"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fc_request.c 中的请求处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mmap-map-anonymous" id="id11"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mmap 的和 MAP_ANONYMOUS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#device-size" id="id12"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;如何获取device_size&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slab" id="id13"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;slab逻辑&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id14"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;启动&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id15"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;启动日志如下&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id16"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;写操作过程中对slab的使用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id17"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;性能测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id18"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#todo" id="id19"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;TODO&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;设计理念&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Eliminate small, random disk writes&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;batched write&lt;/li&gt;
&lt;li&gt;如果用mmap的方式使用ssd(比如mongo), 就会产生很多随机写.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Minimize disk reads on cache hit&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Fatcache reduces disk reads by maintaining an in-memory index for all on-disk data.&lt;/li&gt;
&lt;li&gt;no disk accesses on cache miss and only a single disk access on cache hit.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;定期gc, 对所有在磁盘上, 而不在内存索引中的元素清掉.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;内存index&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;所有key放在内存中, 内存中hash表记录value在磁盘上的位置.&lt;/li&gt;
&lt;li&gt;拉链式hash表&lt;/li&gt;
&lt;li&gt;为了减少key放在内存中的大小, 使用sha1, (冲突在读的时候会检测, 写的时候覆盖.)&lt;/li&gt;
&lt;li&gt;The index entry (struct itemx) on a 64-bit system is 44 bytes in size&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;代码&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;量不大:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop ~/idning-github/fatcache/src$ cat *.c *.h|wc -l
9830
&lt;/pre&gt;
&lt;p&gt;util:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc_queue.h
fc_array.c
fc_array.h
fc_log.c
fc_log.h
fc_sha1.c
fc_sha1.h
fc_signal.c
fc_signal.h
fc_string.c
fc_string.h
fc_time.c
fc_time.h
fc_util.c
fc_util.h
&lt;/pre&gt;
&lt;p&gt;事件和连接处理:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc_event.c
fc_event.h
fc_connection.c
fc_connection.h
fc_mbuf.c
fc_mbuf.h
fc_core.c
fc_core.h
fc_client.c
fc_client.h
fc_server.c
fc_server.h
&lt;/pre&gt;
&lt;p&gt;请求处理:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc.c
fc_memcache.c           协议解析.
fc_memcache.h
fc_message.c
fc_message.h
fc_request.c            #处理请求, 转化为itemx/slab 存储. 读取.
fc_response.c           #如何发送response
&lt;/pre&gt;
&lt;p&gt;cache模型:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fc_item.c
fc_item.h
fc_itemx.c
fc_itemx.h
fc_slab.c
fc_slab.h
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;util&lt;/tt&gt; 和 &lt;tt class="docutils literal"&gt;事件处理&lt;/tt&gt; 部分和twemproxy有极大复用度. 请求处理部分主要是协议的解析.&lt;/p&gt;
&lt;p&gt;fc_request是负责将解析出来的请求转化为存储层的函数调用(操作item/itemx/slab)&lt;/p&gt;
&lt;p&gt;概念:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;item: 一个kv对,&lt;/li&gt;
&lt;li&gt;itemx: 索引项&lt;/li&gt;
&lt;li&gt;slab: 用来存储item, 一个slab默认是1M(最大可配为512M), 可以存放多个item. slab有内存和磁盘两种类型.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;item:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct item {
    uint32_t          magic;      /* item magic (const) */
    uint32_t          offset;     /* raw offset from owner slab base (const) */
    uint32_t          sid;        /* slab id (const) */
    uint8_t           cid;        /* slab class id (const) */
    uint8_t           unused[2];  /* unused */
    uint8_t           nkey;       /* key length */
    uint32_t          ndata;      /* date length */
    rel_time_t        expiry;     /* expiry in secs */
    uint32_t          flags;      /* flags opaque to the server */
    uint8_t           md[20];     /* key sha1*/
    uint32_t          hash;       /* key hash */
    uint8_t           end[1];     /* item data */
};

uint8_t * item_key(struct item *it) { return it-&amp;gt;end; }                                     //获得item-&amp;gt;key
uint8_t * item_data(struct item *it) { return it-&amp;gt;end + it-&amp;gt;nkey; }                         //获得item-&amp;gt;value
size_t item_ntotal(uint8_t nkey, uint32_t ndata) { return ITEM_HDR_SIZE + nkey + ndata; }   //获得item大小.

struct itemx {
    STAILQ_ENTRY(itemx) tqe;    /* link in index / free q */
    uint8_t             md[20]; /* sha1 */
    uint32_t            sid;    /* owner slab id */
    uint32_t            offset; /* item offset from owner slab base */
    uint64_t            cas;    /* cas */
} __attribute__ ((__packed__));

struct slab {
    uint32_t  magic;     /* slab magic (const) */
    uint32_t  sid;       /* slab id */
    uint8_t   cid;       /* slab class id */
    uint8_t   unused[3]; /* unused */
    uint8_t   data[1];   /* opaque data */
};
&lt;/pre&gt;
&lt;div class="section" id="fc-request-c"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;fc_request.c 中的请求处理&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
static void
req_process_get(struct context *ctx, struct conn *conn, struct msg *msg)
{
    struct itemx *itx;
    struct item *it;

    itx = itemx_getx(msg-&amp;gt;hash, msg-&amp;gt;md);
    if (itx == NULL) {
        msg_type_t type;

        /*
         * On a miss, we send a &amp;quot;END\r\n&amp;quot; response, unless the request
         * is an intermediate fragment in a fragmented request.
         */
        if (msg-&amp;gt;frag_id == 0 || msg-&amp;gt;last_fragment) {
            type = MSG_RSP_END;
        } else {
            type = MSG_EMPTY;
        }

        rsp_send_status(ctx, conn, msg, type);
        return;
    }

    /*
     * On a hit, we read the item with address [sid, offset] and respond
     * with item value if the item hasn't expired yet.
     */
    it = slab_read_item(itx-&amp;gt;sid, itx-&amp;gt;offset);
    if (it == NULL) {
        rsp_send_error(ctx, conn, msg, MSG_RSP_SERVER_ERROR, errno);
        return;
    }
    if (item_expired(it)) {
        rsp_send_status(ctx, conn, msg, MSG_RSP_NOT_FOUND);
        return;
    }

    rsp_send_value(ctx, conn, msg, it, itx-&amp;gt;cas);
}

static void
req_process_set(struct context *ctx, struct conn *conn, struct msg *msg)
{
    uint8_t *key, nkey, cid;
    struct item *it;

    key = msg-&amp;gt;key_start;
    nkey = (uint8_t)(msg-&amp;gt;key_end - msg-&amp;gt;key_start);

    cid = item_slabcid(nkey, msg-&amp;gt;vlen);
    if (cid == SLABCLASS_INVALID_ID) {
        rsp_send_error(ctx, conn, msg, MSG_RSP_CLIENT_ERROR, EINVAL);
        return;
    }

    itemx_removex(msg-&amp;gt;hash, msg-&amp;gt;md);

    it = item_get(key, nkey, cid, msg-&amp;gt;vlen, time_reltime(msg-&amp;gt;expiry),
                  msg-&amp;gt;flags, msg-&amp;gt;md, msg-&amp;gt;hash);
    if (it == NULL) {
        rsp_send_error(ctx, conn, msg, MSG_RSP_SERVER_ERROR, ENOMEM);
        return;
    }

    mbuf_copy_to(&amp;amp;msg-&amp;gt;mhdr, msg-&amp;gt;value, item_data(it), msg-&amp;gt;vlen);

    rsp_send_status(ctx, conn, msg, MSG_RSP_STORED);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="mmap-map-anonymous"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id11"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;mmap 的和 MAP_ANONYMOUS&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;代码中看到下面这种用法, 不理解是什么意思, 于是查了一下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
void *
_fc_mmap(size_t size, const char *name, int line)
{
    p = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS,
             -1, 0);
}
&lt;/pre&gt;
&lt;p&gt;man:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
MAP_ANONYMOUS
  The mapping is not backed by any file; its contents are initialized to zero.  The fd and offset arguments are ignored; however, some implementations require fd to be  -1  if  MAP_ANONYMOUS
  (or MAP_ANON) is specified, and portable applications should ensure this.  The use of MAP_ANONYMOUS in conjunction with MAP_SHARED is only supported on Linux since kernel 2.4.
&lt;/pre&gt;
&lt;p&gt;mmap 的 &lt;tt class="docutils literal"&gt;MAP_ANONYMOUS&lt;/tt&gt; 相当于malloc一片内存:&lt;/p&gt;
&lt;p&gt;MAP_ANONYMOUS is commonly used for two things on systems that implement it:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;To share a memory region between a parent and a child, as you said.  However, it requires that the child does not execve(), since it must have the pointer to the mmap()ed address.&lt;/li&gt;
&lt;li&gt;To simply get memory pages from the kernel. That's how most malloc() implementations work nowadays. (The glibc malloc() uses brk() for small allocations and mmap() with MAP_ANONYMOUS for big ones.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
itemx_init:
    /* init item index memory */
    itx = fc_mmap(settings.max_index_memory);
    if (itx == NULL) {
        return FC_ENOMEM;
    }
    istart = itx;
    iend = itx + n;

slab_init:
    /* init nmslab, mstart and mend */
    nmslab = MAX(nctable, settings.max_slab_memory / settings.slab_size);
    mspace = nmslab * settings.slab_size;
    mstart = fc_mmap(mspace);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="device-size"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id12"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;如何获取device_size&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
fc_device_size(const char *path, size_t *size)
{
    fd = open(path, O_RDONLY, 0644);
    status = ioctl(fd, BLKGETSIZE64, size);
    return FC_OK;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="slab"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;slab逻辑&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;fatcache 有两种slab: &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;mem-slab&lt;/span&gt;&lt;/tt&gt; 和 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;disk-slab&lt;/span&gt;&lt;/tt&gt;, 大小相同,&lt;/p&gt;
&lt;p&gt;mem-slab作为disk-slab的写buffer.&lt;/p&gt;
&lt;p&gt;一个slab里面可以包含多个item. 写操作都是写到mem-slab, 写满一个, 就交换到disk-slab, 能做到顺序写, 随机读, 从而最大化ssd利用率.&lt;/p&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;启动&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
struct settings {
    size_t   max_slab_memory;              /* maximum memory allowed for slabs in bytes */
    size_t   max_index_memory;             /* maximum memory allowed for in bytes */
    size_t   slab_size;                    /* slab size */

    size_t   chunk_size;                   /* minimum item chunk size */
    size_t   max_chunk_size;               /* maximum item chunk size */
    double   factor;                       /* item chunk size growth factor */
};
&lt;/pre&gt;
&lt;p&gt;启动后, 先从配置中获得slab_size, 根据配置的mem-slab大小和磁盘大小, 计算总共有多少个slab, 分别初始化 ctable和stable:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slab_init(void)
{

    status = slab_init_ctable();                //根据factor, 初始化一系列slab-class, 每个slab-class的item-size呈递增关系.

    //计算有多少个mem-slab
    nmslab = MAX(nctable, settings.max_slab_memory / settings.slab_size);

    //计算有多少个disk-slab
    status = fc_device_size(settings.ssd_device, &amp;amp;size);
    ndchunk = size / settings.slab_size;        //整个device能放多少个slab?
    ASSERT(settings.server_n &amp;lt;= ndchunk);
    ndslab = ndchunk / settings.server_n;

    status = slab_init_stable();
}
&lt;/pre&gt;
&lt;p&gt;slab的总个数就是nmslab+ndslab.  slab总数, mslab, dslab 的个数都是不会变的.&lt;/p&gt;
&lt;p&gt;初始化完成后, 所有的mem-slab和disk-slab都被标记为free(放到free_xxx_q里面)&lt;/p&gt;
&lt;p&gt;初始化完成后, 如下图所示:&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-001.png" style="width: 800px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;启动日志如下&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
$ ./src/fatcache -D /dev/sdb -p 11211 -s 0/8
[Wed May 21 21:51:51 2014] fc.c:683 fatcache-0.1.1 started on pid 1721
[Wed May 21 21:51:51 2014] fc.c:688 configured with debug logs disabled, asserts disabled, panic disabled
[Wed May 21 21:51:51 2014] fc_slab.c:85 slab size 1048576, slab hdr size 12, item hdr size 52, item chunk size 88
[Wed May 21 21:51:51 2014] fc_slab.c:88 index memory 0, slab memory 67108864, disk space 239498952704
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   0: items   11915  size      88  data      36  slack      44
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   1: items    9362  size     112  data      60  slack      20
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   2: items    7281  size     144  data      92  slack     100
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   3: items    5698  size     184  data     132  slack     132
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   4: items    4519  size     232  data     180  slack     156
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   5: items    3542  size     296  data     244  slack     132
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   6: items    2788  size     376  data     324  slack     276
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   7: items    2221  size     472  data     420  slack     252
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   8: items    1771  size     592  data     540  slack     132
[Wed May 21 21:51:51 2014] fc_slab.c:94 class   9: items    1409  size     744  data     692  slack     268
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  10: items    1120  size     936  data     884  slack     244
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  11: items     891  size    1176  data    1124  slack     748
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  12: items     712  size    1472  data    1420  slack     500
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  13: items     569  size    1840  data    1788  slack    1604
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  14: items     455  size    2304  data    2252  slack     244
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  15: items     364  size    2880  data    2828  slack     244
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  16: items     291  size    3600  data    3548  slack     964
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  17: items     232  size    4504  data    4452  slack    3636
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  18: items     186  size    5632  data    5580  slack    1012
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  19: items     148  size    7040  data    6988  slack    6644
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  20: items     119  size    8800  data    8748  slack    1364
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  21: items      95  size   11000  data   10948  slack    3564
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  22: items      76  size   13752  data   13700  slack    3412
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  23: items      60  size   17192  data   17140  slack   17044
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  24: items      48  size   21496  data   21444  slack   16756
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  25: items      39  size   26872  data   26820  slack     556
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  26: items      31  size   33592  data   33540  slack    7212
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  27: items      24  size   41992  data   41940  slack   40756
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  28: items      19  size   52496  data   52444  slack   51140
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  29: items      15  size   65624  data   65572  slack   64204
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  30: items      12  size   82032  data   81980  slack   64180
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  31: items      10  size  102544  data  102492  slack   23124
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  32: items       8  size  128184  data  128132  slack   23092
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  33: items       6  size  160232  data  160180  slack   87172
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  34: items       5  size  200296  data  200244  slack   47084
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  35: items       4  size  250376  data  250324  slack   47060
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  36: items       3  size  312976  data  312924  slack  109636
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  37: items       2  size  391224  data  391172  slack  266116
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  38: items       2  size  489032  data  488980  slack   70500
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  40: items       1  size  764120  data  764068  slack  284444
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  41: items       1  size  955152  data  955100  slack   93412
[Wed May 21 21:51:51 2014] fc_slab.c:94 class  42: items       1  size 1048564  data 1048512  slack       0
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id16"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;写操作过程中对slab的使用&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
req_process_set
    cid = item_slabcid(nkey, msg-&amp;gt;vlen)     //计算需要一个多大的item
    itemx_removex(msg-&amp;gt;hash, msg-&amp;gt;md);      //如果索引里面已有, 删掉
    item_get                                //获得一个klen+vlen大小的item.
        slab_get_item
            1. 尝试从ctable[cid]-&amp;gt;partial_msinfoq 里面获取.  如果获取到则返回
            2. 尝试从free_msinfoq中获取一个free的mslab挂到 ctable[cid]-&amp;gt;partial_msinfoq, to 1.
            3. 如果上面两步都失败, 则 slab_drain()
                如果还有空闲的dslab, 直接把这个mslab刷到dslab.
                如果没有:
                slab_evict //先回收一块磁盘上的空间. (这会导致写操作的时候有读)
                _slab_drain //把一个写满的mem_slab刷盘.
                    - pwrite
&lt;/pre&gt;
&lt;p&gt;这里我主要分析mem-slab和disk-slab交换的过程, 在如下时刻都是转折点:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;启动后第一个插入操作.&lt;/li&gt;
&lt;li&gt;mem-slab用光, 开始启用第一个disk-slab&lt;/li&gt;
&lt;li&gt;disk-slab用光, 开始会对disk-slab做回收.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面举例:&lt;/p&gt;
&lt;p&gt;在获取slab的过程中, 我们假设 假设每次写操作都希望获得一个size为100的item, 这样就只会涉及到一个slab class.( &lt;tt class="docutils literal"&gt;ctable[1]&lt;/tt&gt; )&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;第一次写, 发现 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ctable[1]-&amp;gt;partial_msinfoq&lt;/span&gt;&lt;/tt&gt; 为空, 于是从 &lt;tt class="docutils literal"&gt;free_msinfoq&lt;/tt&gt; 中拿一个挂到 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ctable[cid]-&amp;gt;partial_msinfoq&lt;/span&gt;&lt;/tt&gt; , 并从这个slab中分配一个item, 写入数据,
这样一直写, 直到这个slab写满, 就把它移到full_msinfoq, 并获取下一个free_msinfoq&lt;/p&gt;
&lt;p&gt;这个过程如下图:&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-002.png" style="width: 500px;" /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;当mem-slab用光后, 就会开始使用disk-slab, 这是通过一次drain实现的, drain 会找到一个free 的disk-slab, 把它刷到这个disk-slab对应的磁盘上,
这样就产生了一个free-mem-slab 和一个full-disk-slab.&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-003.png" style="width: 500px;" /&gt;
&lt;p&gt;此后full_msinfoq 就一直处于空的状态, 每次需要一个slab, 都发生一次drain, 每次drain都会消耗一个disk-slab, 如下图:&lt;/p&gt;
&lt;img alt="" src="/imgs/fatcache-004.png" style="width: 500px;" /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;再过了一段时间, disk-slab用光, 此时mem-slab 和disk-slab都full,
此时为了获得一个disk-slab, 就会发生一次 evict, 驱逐掉一个disk-slab中的数据(最老的) 获得一个free-disk-slab, 然后回到2, 获得一个free-mem-slab&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;这里是一种fifo的淘汰, 比较悲剧?&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;img alt="" src="/imgs/fatcache-005.png" style="width: 500px;" /&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;性能测试&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;我的性能测试, 先set 10亿条100字节的数据, 再来get:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
num = 1000000000 #10亿
cmd = 'mc-benchmark  -p 11211 -n %s -r %s -d 100' % (num, num)
&lt;/pre&gt;
&lt;p&gt;发现, fatcache始终能维持5w+的 写入和读取, 但是问题是, 读压力的时候, 磁盘的read-iops才不到100, 这很不合理. 具体原因没有仔细追查.&lt;/p&gt;
&lt;p&gt;因为 -n 1000000000 -r 100000000000 的话, 命中率只有1%. 很多查询通过内存就能发现key不存在, 根本不需要访问ssd.&lt;/p&gt;
&lt;p&gt;benchmark的结果(图中前半段是写入, 后半段是读取, 读取时的r/s很低, 不能解释):&lt;/p&gt;
&lt;img alt="" src="/imgs/stat_ssd_fat_1.log.png" style="width: 800px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id18"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;限制: item (key+value必须小于一个slab)&lt;/li&gt;
&lt;li&gt;disk-slab的回收是fifo, 这不好.&lt;/li&gt;
&lt;li&gt;裸写设备的方法, 虽然能更好的利用磁盘的iops, 但是我不太喜欢.&lt;/li&gt;
&lt;li&gt;fc 不会持久化, 虽然它写磁盘, 但是它重启的时候, 是默认把所有slab都标记为free.&lt;/li&gt;
&lt;li&gt;用 &lt;tt class="docutils literal"&gt;sha1&lt;/tt&gt; 做index里面的key, 也是一个不好的地方&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="todo"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id19"&gt;6&amp;nbsp;&amp;nbsp;&amp;nbsp;TODO&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;问题:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;从代码看, 应该是现有twemproxy, 后有fatcache.&lt;/li&gt;
&lt;li&gt;如何处理expire, 参看 req_process_get&lt;/li&gt;
&lt;li&gt;目测get的时候一个kv, 只能放在一个mbuf里面 rsp_send_value?&lt;/li&gt;
&lt;li&gt;没有主从同步等机制.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;小结:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;自己管理实现存储引擎, 需要关注空间分配, 回收, 索引等, 略复杂, 用levelDB是比较好的方案. 不用关注这一层的细节.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>ssd-cache</title><link href="/ssd-cache.html" rel="alternate"></link><updated>2014-05-13T06:56:03+08:00</updated><author><name>ning</name></author><id>tag:,2014-05-13:ssd-cache.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id25"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;需求&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#why" id="id26"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;why&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id27"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;具体需求&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#index" id="id28"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;index&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ssd" id="id29"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 特性&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id30"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;成本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id31"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;接口&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id32"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;比较典型的ssd参数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id33"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id34"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;现有系统调研&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis" id="id35"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基于redis修改&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-vm" id="id36"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-vm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-storage" id="id37"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id38"&gt;4.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id39"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;单机存储引擎&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#leveldb" id="id40"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#rocksdb-facebook" id="id41"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RocksDB(facebook)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#berkley-db" id="id42"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Berkley DB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#nessdb" id="id43"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;nessDB(国人开发)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id44"&gt;4.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id45"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;备选项目&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id46"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssdb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id47"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fatcache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ardb" id="id48"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;ardb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ledisdb" id="id49"&gt;4.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;ledisdb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id18" id="id50"&gt;4.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id19" id="id51"&gt;4.3.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id20" id="id52"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;成熟分布式存储系统&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#tair" id="id53"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;淘宝tair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aerospike" id="id54"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;aerospike&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#facebook-apollo" id="id55"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook Apollo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#facebook-mcdipper" id="id56"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook-McDipper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ckv" id="id57"&gt;4.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;#腾讯CKV海量分布式存储系统&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id21" id="id58"&gt;4.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id22" id="id59"&gt;4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它思路&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id23" id="id60"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id24" id="id61"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;关于目前的很多系统&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;style type="text/css"&gt;
      table {
        width: 30%
      }
&lt;/style&gt;&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id25"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;需求&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="why"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id26"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;why&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;用redis内存实在太贵了, 假设要存1T数据双副本:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;内存: 1000*2 / 64 = 32台机器.&lt;/li&gt;
&lt;li&gt;2T盘机器:  2-4台&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id27"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;具体需求&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;数据存放在ssd.&lt;/li&gt;
&lt;li&gt;性能要求: 6台机器的集群10w/s, (单机2w/s)&lt;/li&gt;
&lt;li&gt;有expire功能.&lt;/li&gt;
&lt;li&gt;使用redis协议 (twemproxy, client-lib可以复用)&lt;/li&gt;
&lt;li&gt;数据类型仅支持kv, 以后可以考虑支持hash.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其它:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;事务或script支持.&lt;/li&gt;
&lt;li&gt;主从, failover&lt;/li&gt;
&lt;li&gt;集群.&lt;/li&gt;
&lt;li&gt;redis-mgr 部署支持&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="index"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id28"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;index&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;主要涉及下面几个方面:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;ssd特性.&lt;/li&gt;
&lt;li&gt;存储引擎,  如LevelDB, RocksDB, BDB等.&lt;/li&gt;
&lt;li&gt;现有系统的调研和benchmark, 主要关注SSDB和fatcache.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文是这个调研系列的目录和结论, 相关调研:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="/coding-for-ssd.html"&gt;coding-for-ssd笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LevelDB 调研 TODO&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/cr-ssdb.html"&gt;SSDB代码阅读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/ssdb-benchmark.html"&gt;SSDB benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/fatcache-cr.html"&gt;fatcache 代码阅读&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="ssd"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id29"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;ssd 特性&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id30"&gt;3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;成本&lt;/a&gt;&lt;/h3&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="11%" /&gt;
&lt;col width="18%" /&gt;
&lt;col width="56%" /&gt;
&lt;col width="15%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;--&lt;/th&gt;
&lt;th class="head"&gt;国外&lt;/th&gt;
&lt;th class="head"&gt;国内&lt;/th&gt;
&lt;th class="head"&gt;2T成本&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;ssd&lt;/td&gt;
&lt;td&gt;$0.6/GB&lt;/td&gt;
&lt;td&gt;京东价格(400元/128G=3.1元/GB)&lt;/td&gt;
&lt;td&gt;6000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hdd:&lt;/td&gt;
&lt;td&gt;$0.12/GB&lt;/td&gt;
&lt;td&gt;京东价格(400元/1T=0.4元/GB)&lt;/td&gt;
&lt;td&gt;800&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;实际上, 我们买服务器的时候, 价格会更便宜些, 不过还是这个数量级.&lt;/li&gt;
&lt;li&gt;考虑到一台1U服务器价格 在3-5w, 使用2T ssd带来的成本上升: 5200/30000 = 18%左右, 并不算太贵, 加之后续电费等消耗, 可以认为使用ssd带来的成本上升小于15%&lt;/li&gt;
&lt;li&gt;当然, 我们不能用ssd来存文件之类的大/冷的数据, 这是明显的浪费.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id31"&gt;3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;接口&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;目前ssd主要2种接口:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;sata&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;pci-e, 性能更高.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;典型产品如:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Fusion-io ioScale Gen2  (w: 4w, r:5w)&lt;/li&gt;
&lt;li&gt;Fusion-io ioMemory (w: 32w, r:19w)&lt;/li&gt;
&lt;li&gt;华为ES3000 (w: 10w,  r:15w)&lt;/li&gt;
&lt;li&gt;MemblazeQ520 (w:7w, r:3w)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;sata 带宽6Gbps, pci-e 常见带宽 3.2G*8 = 24Gbps.&lt;/p&gt;
&lt;img alt="" src="/imgs/fusionio.png" style="width: 310px;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id32"&gt;3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;比较典型的ssd参数&lt;/a&gt;&lt;/h3&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="33%" /&gt;
&lt;col width="20%" /&gt;
&lt;col width="20%" /&gt;
&lt;col width="27%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Product&lt;/th&gt;
&lt;th class="head"&gt;Intel SSD 320&lt;/th&gt;
&lt;th class="head"&gt;Intel SSD 530&lt;/th&gt;
&lt;th class="head"&gt;ioMemory PX600&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Components&lt;/td&gt;
&lt;td&gt;MLC&lt;/td&gt;
&lt;td&gt;MLC&lt;/td&gt;
&lt;td&gt;MLC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Launch Date&lt;/td&gt;
&lt;td&gt;2011&lt;/td&gt;
&lt;td&gt;2013&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Sequential Read&lt;/td&gt;
&lt;td&gt;270 MB/s&lt;/td&gt;
&lt;td&gt;540 MB/s&lt;/td&gt;
&lt;td&gt;2700 MB/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Sequential Write&lt;/td&gt;
&lt;td&gt;220 MB/s&lt;/td&gt;
&lt;td&gt;490 MB/s&lt;/td&gt;
&lt;td&gt;1500MB/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Random Read (8GB Span)&lt;/td&gt;
&lt;td&gt;39,500 IOPS&lt;/td&gt;
&lt;td&gt;48,000 IOPS&lt;/td&gt;
&lt;td&gt;196,000 IOPS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Random Write (8GB Span)&lt;/td&gt;
&lt;td&gt;23,000 IOPS&lt;/td&gt;
&lt;td&gt;80,000 IOPS&lt;/td&gt;
&lt;td&gt;320,000 IOPS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Latency - Read&lt;/td&gt;
&lt;td&gt;75 us&lt;/td&gt;
&lt;td&gt;80 us&lt;/td&gt;
&lt;td&gt;92 us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Latency - Write&lt;/td&gt;
&lt;td&gt;90 us&lt;/td&gt;
&lt;td&gt;80 us&lt;/td&gt;
&lt;td&gt;15 us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;interface&lt;/td&gt;
&lt;td&gt;SATA 6.0 Gb/s&lt;/td&gt;
&lt;td&gt;SATA 6.0 Gb/s&lt;/td&gt;
&lt;td&gt;PCI-Express 2.0 x8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;数据来源:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Intel-SSD-320: &lt;a class="reference external" href="http://ark.intel.com/products/56569/Intel-SSD-320-Series-600GB-2_5in-SATA-3Gbs-25nm-ML"&gt;http://ark.intel.com/products/56569/Intel-SSD-320-Series-600GB-2_5in-SATA-3Gbs-25nm-ML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Intel-SSD-530: &lt;a class="reference external" href="http://ark.intel.com/products/75336/Intel-SSD-530-Series-480GB-2_5in-SATA-6Gbs-20nm-MLC"&gt;http://ark.intel.com/products/75336/Intel-SSD-530-Series-480GB-2_5in-SATA-6Gbs-20nm-MLC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fusion-io: &lt;a class="reference external" href="http://www.fusionio.com/data-sheets/iomemory-px600-atomic-series/"&gt;http://www.fusionio.com/data-sheets/iomemory-px600-atomic-series/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;这里选的 Fusion-io ioMemory系列, 写可以达到32w/s, 写延迟只有15us, 很明显写操作都是先写buffer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;对三块Intel-SSD-530 做raid0后, 用fio进行了测试, 数据和标称数据差不多:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;random-write: 5.5w/s&lt;/li&gt;
&lt;li&gt;random-read: 7.3w/s&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id33"&gt;3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;随机读性能好&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;随机写性能较差&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;写放大: 写一个字节也会导致整个page的read-modify-write&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;应该尽量避免small-write&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;很多ssd会通过 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt; 来做写merge. 从而减轻写放大,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这相当于把Log-Structure的一些算法在ssd控制器这一层实现了, 从而实现较高的随机写性能.&lt;/li&gt;
&lt;li&gt;但是即便有了 &lt;tt class="docutils literal"&gt;hybrid &lt;span class="pre"&gt;log-block&lt;/span&gt; mapping&lt;/tt&gt;, 也应该尽量避免small-write(因为需要多次操作映射关系表)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;ssd在大量写压力下, 性能可能恶化到8000iops.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;因为很多update, GC可能跟不上, 如果每次写操作需要做一次erase整个block, 就悲剧了.&lt;/li&gt;
&lt;li&gt;正常情况下, GC利用后台的时间, 可以完成erase工作.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;顺序读写和hdd在同一量级.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;寿命有限&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ssd可以通过下面这些方式调优:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;调整page/block的大小, 较小的擦除块可以得到较高的wqps.&lt;/li&gt;
&lt;li&gt;gc策略: 可以通过不同的算法优化, 这是ssd控制器FTL的核心技术.&lt;/li&gt;
&lt;li&gt;Flash Translation Layer (FTL) 上做 hybrid log-block mapping 优化随机写.&lt;/li&gt;
&lt;li&gt;使用 &lt;tt class="docutils literal"&gt;TRIM&lt;/tt&gt; 命令, 会有少量优化.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细参考: &lt;a class="reference external" href="/coding-for-ssd.html"&gt;coding-for-ssd笔记&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id34"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;现有系统调研&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;针对我们的需求, 调研了一些现有的系统, 主要分三类:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;基于redis的修改如redis-vm.&lt;/li&gt;
&lt;li&gt;单机引擎如Berkley DB, LevelDB.&lt;/li&gt;
&lt;li&gt;一些和我们需求接近的现有系统, 如ssdb, fatcache等.&lt;/li&gt;
&lt;li&gt;成熟产品, 如淘宝tair, aerospike 等.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="redis"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id35"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;基于redis修改&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="redis-vm"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id36"&gt;4.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-vm&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://antirez.com/news/52"&gt;http://antirez.com/news/52&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://blog.nosqlfan.com/html/1047.html"&gt;http://blog.nosqlfan.com/html/1047.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;redis在2.2-2.4曾经做过vm功能, 来将内存扩展到磁盘, 但是不久就被废弃了, 原因主要是造成性能不稳定.&lt;/p&gt;
&lt;p&gt;存在的问题:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;slow restart: 重启太慢&lt;/li&gt;
&lt;li&gt;slow saving: 保存数据太慢&lt;/li&gt;
&lt;li&gt;slow replication: 上面两条导致 replication 太慢&lt;/li&gt;
&lt;li&gt;complex code: 代码过于复杂&lt;/li&gt;
&lt;li&gt;2.4 之后就已经从redis代码中移除了.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者的观点:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;have Redis do what it does best - very quickly serve data from RAM.&lt;/li&gt;
&lt;li&gt;估计当时的测试, 使用的磁盘都是hdd, 那当然性能糟糕, 如果换成ssd应该会好些.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-storage"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id37"&gt;4.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-storage&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;把leveldb嵌入到redis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;完成度较高, 新增了一些rl_开头的命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rl系列命令：(同时操作redis和leveldb系列命令)
=======string数据操作======
rl_get key            (从redis或leveldb取值, 优先顺序：redis &amp;gt; leveldb)
rl_getset key         (返回同rl_get, 当leveldb有值，redis无值时，会回写到redis)
...
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;读: 先从redis读取, 如果redis没有，则到leveldb读取。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;写: 先写到leveldb中，写成功了，再写到redis中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;问题:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;这个项目的目的是把redis的内存扩大2-5倍, 把redis作为leveldb的cache+store. 两份storage很诡异.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;作者设计的时候, 应该是考虑到兼容redis, 客户端尽量不需要改动, 冷key会自动淘汰,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;但是实际上提供了两套命令, 客户端需要根据情况, 指定只写redis/只写leveldb还是双写. 就很麻烦.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;没有expire支持, leveldb过大后, 怎么办?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;完全没有考虑到主从的设计.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/qiye/redis-storage"&gt;https://github.com/qiye/redis-storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.guangla.com/post/2014-03-17/40061277735"&gt;http://www.guangla.com/post/2014-03-17/40061277735&lt;/a&gt;  (shenzhe)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id38"&gt;4.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;基于redis的改进, 主要有这么几种:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;增加新命令&lt;/li&gt;
&lt;li&gt;在key被淘汰时写磁盘&lt;/li&gt;
&lt;li&gt;key一直在内存, 把某些value放磁盘(redis-vm的实现方案)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果基于redis来实现, 存在下面一些问题:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;主从同步很可能被破坏(现有全量同步机制需要重新改写)&lt;/li&gt;
&lt;li&gt;重启时加载数据的机制.&lt;/li&gt;
&lt;li&gt;不能支持全部命令, 容易造成混淆.&lt;/li&gt;
&lt;li&gt;不能被主流所接受&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果不基于redis代码来做:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;主从同步需要重做&lt;/li&gt;
&lt;li&gt;sentinel机制需要重做.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id39"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;单机存储引擎&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="leveldb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id40"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;LevelDB&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;LevelDB是BigTable的单机存储, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;LSM-Tree&lt;/span&gt;&lt;/tt&gt; 思想, 写操作都转化为顺序写.&lt;/p&gt;
&lt;p&gt;特点:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;KV引擎&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持SCAN(iteration)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Snappy压缩&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;随机读写能达到 10w/s 的性能&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;这里性能是小数据量下, 还不刷盘的情况&lt;/li&gt;
&lt;li&gt;实际写能到10w, 读取决于存储介质.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Bloom Filter, 能在一定程度上优化读性能.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="rocksdb-facebook"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id41"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;RocksDB(facebook)&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;基于LevelDB改进&lt;/li&gt;
&lt;li&gt;更好的利用多核等&lt;/li&gt;
&lt;li&gt;代码包比LevelDB复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="berkley-db"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id42"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;Berkley DB&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;历史悠久的嵌入式数据库&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持事务, 细粒度锁.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;支持多种算法&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;B+树&lt;/li&gt;
&lt;li&gt;Hash&lt;/li&gt;
&lt;li&gt;Heap(更节约空间)&lt;/li&gt;
&lt;li&gt;Recno&lt;/li&gt;
&lt;li&gt;Queue(定长record)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;对一些老的UNIX数据库, 如dbm, ndbm接口兼容.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="http://docs.oracle.com/cd/E17076_02/html/programmer_reference/am_conf.html"&gt;http://docs.oracle.com/cd/E17076_02/html/programmer_reference/am_conf.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nessdb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id43"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;nessDB(国人开发)&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;支持事务 &lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;自己实现存储引擎, 不是基于LevelDB&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;3.0 提供 Buffered-Tree index (Toku的FT-Tree)&lt;/li&gt;
&lt;li&gt;作者是TokuDB的贡献者.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;2011-2014持续开发, 目测代码质量很高.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;本身是一个库.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;还提供一个服务端，支持Redis的 PING, SET, MSET, GET, MGET, DEL, EXISTS, INFO, SHUTDOWN 命令，&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;现在已经专注于实现引擎, 不提供server功能了.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;整个引擎基于LSM-Tree思想开发，对随机写非常友好。为提高随机读，nessDB使用了Level LRU和Bloom Filter策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;引擎是自己开发的, 还需要时间验证.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id44"&gt;4.2.5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;较老的存储引擎都基于B+树或Hash实现, 写性能差.&lt;/li&gt;
&lt;li&gt;较新的存储引擎基于LSM-Tree, Log Structed Hash, FT-Tree之类新的数据结构, 针对写进行优化, 写性能能得到很大改善&lt;/li&gt;
&lt;li&gt;读操作主要取决于底层磁盘能提供的 &lt;strong&gt;随机读IOPS&lt;/strong&gt; , 通过Bloom Filter等能有一定的优化.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id45"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;备选项目&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id13"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id46"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;ssdb&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;ssdb 是一个基于leveldb的kv存储, 提供兼容redis的协议&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持String, Hash, Zset, Queue几种数据结构.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Expire和主从同步&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;ssd上写性能稳定在3.8wqps, 不会随着写数据增多而变差, 和hdd差不多,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;读性能稳定在5000qps, 不能充分发挥硬件性能, 这主要是由于读操作是单线程顺序执行.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;主要问题:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;读性能问题(多线程可达到15000)&lt;/li&gt;
&lt;li&gt;所有expire的key记录在内存&lt;/li&gt;
&lt;li&gt;兼容问题(expire/ttl/del都有问题, scan类设计上和redis不同)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细参考:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="/cr-ssdb.html"&gt;SSDB代码阅读笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/ssdb-benchmark.html"&gt;SSDB benchmark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id47"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;fatcache&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Memcache on SSD&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Log-Structure Hash结构.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;不能持久化(元数据不落盘, 重启后数据丢失)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;性能不错, Initial performance results with fatcache 100K sets/sec, 40K gets/sec on a single SSD&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;读不命中时效率高(所有key记录在内存中)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;写裸盘. 需要root.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;主要问题:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;不持久化&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;key都放在内存, 如果10亿条的话, 每条key 32字节, 就需要32G. 此时存的数据(100字节/kv) 大约100G.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;所以这适合value较大的情况, 比如1K, 这样32G内存就能管理1T数据.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细参考: &lt;a class="reference external" href="/fatcache-cr.html"&gt;fatcache代码阅读笔记&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ardb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id48"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;ardb&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/yinqiwen/ardb"&gt;https://github.com/yinqiwen/ardb&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Full redis-protocol compatible&lt;/li&gt;
&lt;li&gt;Most redis commands supported, and a few new commands&lt;/li&gt;
&lt;li&gt;Replication compatible with Redis 2.6/2.8&lt;/li&gt;
&lt;li&gt;Auto failover support by redis-sentinel&lt;/li&gt;
&lt;li&gt;存储引擎支持  LevelDB/LMDB/RocksDB&lt;/li&gt;
&lt;li&gt;空间索引.&lt;/li&gt;
&lt;li&gt;代码量5w, 很难想象是一个人的作品. (HUST)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看上去很不错, c++实现.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ledisdb"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id49"&gt;4.3.4&amp;nbsp;&amp;nbsp;&amp;nbsp;ledisdb&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;go 实现(金山 siddontang)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/siddontang/ledisdb"&gt;https://github.com/siddontang/ledisdb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;支持多种引擎: LevelDB, goleveldb, LMDB, RocksDB, BoltDB.&lt;/li&gt;
&lt;li&gt;支持expiration&lt;/li&gt;
&lt;li&gt;比GoRedis完善&lt;/li&gt;
&lt;li&gt;写的很细心&lt;/li&gt;
&lt;li&gt;lua&lt;/li&gt;
&lt;li&gt;redis 协议 +rest协议&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;设计:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://siddontang.com/2014/05/10/ledisdb-introduction/"&gt;http://siddontang.com/2014/05/10/ledisdb-introduction/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://siddontang.com/2014/05/30/ledisdb-design-1/"&gt;http://siddontang.com/2014/05/30/ledisdb-design-1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://siddontang.com/2014/06/14/ledisdb-design-2/"&gt;http://siddontang.com/2014/06/14/ledisdb-design-2/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id18"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id50"&gt;4.3.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;memcachedb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://gitorious.org/mdb/memcachedb/source/9f2e5415e4d9017889caf61c100a9b8652825319"&gt;https://gitorious.org/mdb/memcachedb/source/9f2e5415e4d9017889caf61c100a9b8652825319&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;redis-leveldb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;不是基于redis的代码,&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/KDr2/redis-leveldb"&gt;https://github.com/KDr2/redis-leveldb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;redis-protocol compatible&lt;/li&gt;
&lt;li&gt;libev, cpp实现.&lt;/li&gt;
&lt;li&gt;2000行代码, 简单实现的玩具, 代码中各种printf直接输出到终端. 代码质量差&lt;/li&gt;
&lt;li&gt;没有expire, 主从同步,&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;seqdb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;提供sql接口的kv.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;GoRedis&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;go实现, (陌陌)&lt;/li&gt;
&lt;li&gt;存储引擎使用RocksDB, redis接口.&lt;/li&gt;
&lt;li&gt;不支持expire&lt;/li&gt;
&lt;li&gt;slaveof-proxy为两个redis建立自定义的主从同步，包含限速、断线重试等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;rdisk 是一个hackathon项目, 提供兼容redis的协议.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;libuv做服务&lt;/li&gt;
&lt;li&gt;rangel 解析&lt;/li&gt;
&lt;li&gt;tokyocabinet 作为存储引擎(作为.so嵌入)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/Moodstocks/redisk"&gt;https://github.com/Moodstocks/redisk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;是一个不错的开始&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;lycadb&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;An experiment with InnoDB storage for a Redis-like key/value store&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;redis-land-go&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/xjdrew/redis-land-go"&gt;https://github.com/xjdrew/redis-land-go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;旁路监听，把redis数据存盘到leveldb&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id19"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id51"&gt;4.3.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;有很多尝试做兼容redis的磁盘存储的项目,&lt;/li&gt;
&lt;li&gt;在设计实现上都存在或多或少的问题.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id20"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id52"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;成熟分布式存储系统&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="tair"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id53"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;淘宝tair&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;淘宝开发的分布式 key/value 存储系统&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;模块&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;config-server (master+slave)&lt;/li&gt;
&lt;li&gt;data server (存储节点)&lt;/li&gt;
&lt;li&gt;客户端保存路由表, 有local cache&lt;/li&gt;
&lt;li&gt;一致性hash+数据迁移&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;存储引擎&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;mdb: 缓存, 支持kv,&lt;/li&gt;
&lt;li&gt;rdb: redis内存结构, kv, list, set, zset.&lt;/li&gt;
&lt;li&gt;ldb: 基于leveldb.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;需要专用的 client lib.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持多副本, 多版本.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;规模(2011):&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;共有20多个集群，400多台的服务器，其中300多台是cache的，每台提供22G的内存。其他的是持久化的Tair集群。&lt;/li&gt;
&lt;li&gt;存放了数百亿条记录，每秒百万级别的请求数。&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="http://code.taobao.org/p/tair/wiki/intro/"&gt;http://code.taobao.org/p/tair/wiki/intro/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="aerospike"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id54"&gt;4.4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;aerospike&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;商业产品, 开源.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;三层:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;client 感知数据存在哪里&lt;/li&gt;
&lt;li&gt;Distribution Layer&lt;/li&gt;
&lt;li&gt;Data Storage Layer: 单机引擎.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;API形式: 不是简单的key/value, 每个key需要指定 (namespace, set, key), 应该是为了控制锁粒度.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Indexes are always stored in RAM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;数据类型: map, list, integer, string, blob.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可配 expire&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持lua.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Secondary indexes, 不是简单kv, 更像mongo&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持Hot Analytics (distributed aggregations or indexed map-reduce)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/aerospike/aerospike-server"&gt;https://github.com/aerospike/aerospike-server&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="facebook-apollo"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id55"&gt;4.4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook Apollo&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.infoq.com/news/2014/06/facebook-apollo"&gt;http://www.infoq.com/news/2014/06/facebook-apollo&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Paxos-like NoSQL database&lt;/li&gt;
&lt;li&gt;C++&lt;/li&gt;
&lt;li&gt;低延迟, 特别是Flash and in-memory&lt;/li&gt;
&lt;li&gt;不是简单kv, 支持数据结构:  maps, queues, trees&lt;/li&gt;
&lt;li&gt;分布式, 有shard概念, 每个shard内基于RocksDB.&lt;/li&gt;
&lt;li&gt;Apollo isn't currently being used in production at Facebook&lt;/li&gt;
&lt;li&gt;The company is also looking at using Apollo as a reliable queuing system&lt;/li&gt;
&lt;li&gt;是分布式的ssdb&lt;/li&gt;
&lt;li&gt;还没开源.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="facebook-mcdipper"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id56"&gt;4.4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;#facebook-McDipper&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.facebook.com/notes/facebook-engineering/mcdipper-a-key-value-cache-for-flash-storage/10151347090423920"&gt;https://www.facebook.com/notes/facebook-engineering/mcdipper-a-key-value-cache-for-flash-storage/10151347090423920&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Compared with memory, flash provides up to 20 times the capacity per server and still supports tens of thousands of operations per second,&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;大约12年5月上线.&lt;/li&gt;
&lt;li&gt;cache替换策略: LRU或者FIFO&lt;/li&gt;
&lt;li&gt;you can enable bloom filters to avoid unnecessary reads&lt;/li&gt;
&lt;li&gt;主要用于图片服务器的缓存(cdn上) 后端是HayStack.&lt;/li&gt;
&lt;li&gt;We serve over 150 Gb/s from McDipper forward caches in our CDN.&lt;/li&gt;
&lt;li&gt;是一个cdn用的cache存储. memcache协议.&lt;/li&gt;
&lt;li&gt;不开源.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="ckv"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id57"&gt;4.4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;#腾讯CKV海量分布式存储系统&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;(闭源, 这里参考一个ppt)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.csdn.net/article/2014-03-11/2818723"&gt;http://www.csdn.net/article/2014-03-11/2818723&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;高性能、低延时、持久化、分布式KV存储服务, 日请求数: 超过万亿次 (那得看多少套集群)&lt;/p&gt;
&lt;p&gt;与Memcached和Redis等开源NoSQL相比，CKV具有以下优点.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;内存+SSD, 99%命中率(取决于应用)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可以扩展到1PB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;单表 千万qps&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;单台Cache服务器千兆网络环境支持50万/秒的访问，万兆网络环境支持超过100万/秒的访问 &amp;lt;redis也10个实例, 也可以做到&amp;gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;双机热备，主备切换对业务透明. redis一样.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;扩容: 需要停写&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;扩容过程如下：Master将禁止shard2数据写访问命令发送给Access&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;规模: 近万台服务器&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;万台, 每天万亿请求, 那就是说1亿/台, 每台只相当于1000qps.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id21"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id58"&gt;4.4.6&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;这里的几个系统, 都是类似GFS的架构, config-server + data server + 智能client&lt;/li&gt;
&lt;li&gt;支持动态数据迁移和路由更新.&lt;/li&gt;
&lt;li&gt;它们都有各自的接口, 相对来说比较复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id22"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id59"&gt;4.5&amp;nbsp;&amp;nbsp;&amp;nbsp;其它思路&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;HBase/Cassendra/MySQL on ssd?&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;可以利用现有hbase等系统良好的扩展性, 性能上也能有所保证&lt;/li&gt;
&lt;li&gt;接口不兼容.&lt;/li&gt;
&lt;li&gt;过于复杂.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id23"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id60"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;为了避免随机写, 现在很多存储引擎都是Write-optimized的, 基于LSM的思想来开发, 比如:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;fatcache/Riak: Log-Structure Hash table&lt;/li&gt;
&lt;li&gt;RethinkDB: Log-Structure B-tree&lt;/li&gt;
&lt;li&gt;LevelDB, Cassendra, HBase: Log-Structure merge tree.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;LevelDB 平均每次读大约需要1.3-1.5次IO, Log-Structure Hash 只需要1次, 但是不能scan.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;ssdb/ardb/nessDB/ledisdb 都是国人做的, 很赞, 值得持续关注.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;可以否决基于redis做的改造.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;基于LevelDB或者RocksDB封装提供redis协议比较简单, 难点主要是expire/replication/failover的实现.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id24"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id61"&gt;5.1&amp;nbsp;&amp;nbsp;&amp;nbsp;关于目前的很多系统&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;无论对redis改造或者是重新实现, 在数据结构/expire/主从同步上, 都延用了redis的做法, 比如:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;支持富数据结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;expire信息放在内存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;主从断掉全量同步.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;依然有rdb, 整个库占了1T磁盘, rdb出来也占1T =&amp;gt; 这些设计可能没考虑1T这个数据量级, 只考虑100G这个量级.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;比如ardb依然使用rdb做同步.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;甚至有的还会把磁盘操作计入aof, 再加上aof_rewrite,&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于数据规模变大(60G=&amp;gt;600G的级别) 这些设计就存在问题.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="2%" /&gt;
&lt;col width="11%" /&gt;
&lt;col width="4%" /&gt;
&lt;col width="16%" /&gt;
&lt;col width="17%" /&gt;
&lt;col width="24%" /&gt;
&lt;col width="25%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class="head"&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class="head"&gt;代码&lt;/th&gt;
&lt;th class="head"&gt;特点&lt;/th&gt;
&lt;th class="head"&gt;expire&lt;/th&gt;
&lt;th class="head"&gt;repl&lt;/th&gt;
&lt;th class="head"&gt;其它&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;redis-storage&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;redis+特定命令&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;专注于使内存成为磁盘的cache&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;ssdb&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;单独key存储&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;ardb&lt;/td&gt;
&lt;td&gt;5w&lt;/td&gt;
&lt;td&gt;cpp, 复杂, 地理索引&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;存储:&lt;/li&gt;
&lt;li&gt;同步: ?&lt;/li&gt;
&lt;li&gt;切换: ?&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td&gt;兼容性好, 沿用redis, 依然支持rdb&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;ledisdb(go)
金山&lt;/td&gt;
&lt;td&gt;2w&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;单独key存储, 定期elim&lt;/td&gt;
&lt;td&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;存储: 自定义binlog,fid+offset&lt;/li&gt;
&lt;li&gt;同步: 从拉,全量+增量&lt;/li&gt;
&lt;li&gt;切换: 全量同步&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;GoRedis&lt;/td&gt;
&lt;td&gt;2w&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>twemproxy-cfg-reload</title><link href="/twemproxy-cfg-reload.html" rel="alternate"></link><updated>2014-04-28T16:46:45+08:00</updated><author><name>ning</name></author><id>tag:,2014-04-28:twemproxy-cfg-reload.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#nginx" id="id9"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;nginx 怎么做的&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id10"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;配置修改&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id11"&gt;1.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;过程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id12"&gt;1.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;细节&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id13"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;热升级二进制&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id14"&gt;1.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;过程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id15"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;关键点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id16"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;应该做到怎样&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id17"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;配置热加载:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
case SIGUSR2:
&lt;/pre&gt;
&lt;div class="section" id="nginx"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;nginx 怎么做的&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;nginx 有两种情况:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;配置修改&lt;/li&gt;
&lt;li&gt;热升级二进制&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="id1"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id10"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;配置修改&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;难点在于:&lt;/p&gt;
&lt;p&gt;因为不能由各个子进程分别做监听, 只能父进程监听后, 确定监听sokcet列表, 然后fork出子进程, 由子进程继承监听socket.&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id11"&gt;1.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;过程&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;启动后:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
+-------------------------------+
|               0               |
+-------------------------------+
  |       |
+---+   +---+
|   |   |   |
| 1 |   | 2 |
|   |   |   |
+---+   +---+
&lt;/pre&gt;
&lt;p&gt;向父进程0发信号, 派生出新的子进程:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
+-------------------------------+
|               0               |
+-------------------------------+
  |       |         a|       |
+---+   +---+      +---+   +---+
|   |   |   |      |   |   |   |
| 1 |   | 2 |      | 3 |   | 4 |
|   |   |   |      |   |   |   |
+---+   +---+      +---+   +---+
&lt;/pre&gt;
&lt;p&gt;父进程收到信号后, 解析新的配置, 得到新的需要监听的列表, 以及每个监听socket对应的配置, 并派生新worker,
新worker启动后, 向老worker 发送优雅关闭的信号即可, 最后达到这样:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
+-------------------------------+
|               0               |
+-------------------------------+
                    a|       |
                   +---+   +---+
                   |   |   |   |
                   | 3 |   | 4 |
                   |   |   |   |
                   +---+   +---+
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id12"&gt;1.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;细节&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;考虑父进程收到信号后, 派生新worker的过程. 假设&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;旧配置监听8000, 8001, 8002几个port,&lt;/li&gt;
&lt;li&gt;新配置监听8000, 8001, 8003.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么父进程解析完新的配置文件后, 会对比监听列表, 决定关闭8002, 新开8003, 保留8000, 8001, 然后把这三个fd开着, fork出新worker.&lt;/p&gt;
&lt;p&gt;新worker 直接使用新的配置结构即可.&lt;/p&gt;
&lt;p&gt;这里父进程可以直接修改自己的老配置为新配置(不会影响到 老的worker自己的那一份老配置)&lt;/p&gt;
&lt;p&gt;对于twemporxy这样单进程模型, 就不能这样做, 如果在运行时修改自己的配置, 一个请求很可能跨两种不同的配置. 这就容易出问题.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id13"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;热升级二进制&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id5"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id14"&gt;1.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;过程&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
+-------------------------------+
|               0               |
+-------------------------------+
  |       |
+---+   +---+
|   |   |   |
| 1 |   | 2 |
|   |   |   |
+---+   +---+
&lt;/pre&gt;
&lt;p&gt;发信号:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
+-------------------------------+
|               0               |
+-------------------------------+
  |       |                 |
+---+   +---+    +----------------------+
|   |   |   |    |          3           |
| 1 |   | 2 |    +----------------------+
|   |   |   |          |       |
+---+   +---+        +---+   +---+
                     |   |   |   |
                     | 4 |   | 5 |
                     |   |   |   |
                     +---+   +---+
&lt;/pre&gt;
&lt;p&gt;发信号后0派生出一个新的master 3, 这个过程会把所有老的fd传给3, 由3来决定把哪些fd关掉. 新开哪些fd, 之后3会派生自己的worker.&lt;/p&gt;
&lt;p&gt;0和3之间传递fd是通过环境变量来做的, 0会向环境变量里面写:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fds=3:8:72
&lt;/pre&gt;
&lt;p&gt;这样的, 表示这三个listen fd, 子进程拿到这三个fd, 解析自己的配置, 看需要监听哪些端口, 和这些fd对比(这些fd可以通过getsockaddr获取所监听的端口)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id15"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;关键点&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;传递fd:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;像nginx,&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;子进程派生时, 保留父进程fd, 根据情况 关闭 开启新的listen fd.&lt;/li&gt;
&lt;li&gt;但是nginx是master和多worker的进程模型.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;用sendmsg 把fd发送过去.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;库: &lt;a class="reference external" href="http://www.normalesup.org/~george/comp/libancillary/"&gt;http://www.normalesup.org/~george/comp/libancillary/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id16"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;应该做到怎样&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;配置:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;增加pool&lt;/li&gt;
&lt;li&gt;pool属性变化.&lt;/li&gt;
&lt;li&gt;减少pool.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;思路1: 改造tw为master-worker模式.&lt;/li&gt;
&lt;li&gt;思路2: 派生新进程, 通过环境变量来传递fd.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;按照思路2, 实现: &lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/257"&gt;https://github.com/twitter/twemproxy/pull/257&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>twemproxy-mget-improve</title><link href="/twemproxy-mget-improve.html" rel="alternate"></link><updated>2014-04-01T17:22:35+08:00</updated><author><name>ning</name></author><id>tag:,2014-04-01:twemproxy-mget-improve.html</id><summary type="html">&lt;p&gt;I'm trying to import mget performance by rewrite it like this:&lt;/p&gt;
&lt;p&gt;orig:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
mget k1 k2 k3 k4 k5 k6 k7 k8 k9
&lt;/pre&gt;
&lt;p&gt;after rewrite:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
mget k1 k3 k6
mget k2 k4
mget k5 k7 k8 k9
&lt;/pre&gt;
&lt;p&gt;the code is here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/210"&gt;https://github.com/twitter/twemproxy/pull/210&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;benchmark result:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
mget_size=10 on 4001: pqs: 22831.05, rtime: 3
mget_size=10 on 4000: pqs: 36101.08, rtime: 1     =&amp;gt; 1.5x
mget_size=10 on 2000: pqs: 85470.09, rtime: 0

mget_size=100 on 4001: pqs: 1336.90, rtime: 45
mget_size=100 on 4000: pqs: 10526.32, rtime: 5    =&amp;gt; 7.8x
mget_size=100 on 2000: pqs: 27777.78, rtime: 2

mget_size=1000 on 4001: pqs: 58.89, rtime: 909
mget_size=1000 on 4000: pqs: 1063.83, rtime: 53   =&amp;gt; 18x
mget_size=1000 on 2000: pqs: 2777.78, rtime: 20

mget_size=10000 on 4001: pqs: 0.53, rtime: 3751
mget_size=10000 on 4000: pqs: 24.21, rtime: 48    =&amp;gt; 45x
mget_size=10000 on 2000: pqs: 256.41, rtime: 7
&lt;/pre&gt;
&lt;p&gt;flame-graph before:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-flame-mget.png" style="width: 600px; height: 145px;" /&gt;
&lt;p&gt;&lt;a class="reference external" href="imgs/twemproxy-flame-mget.svg"&gt;svg1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;flame-graph after:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-flame-mget-after-improve.png" style="width: 600px; height: 145px;" /&gt;
&lt;p&gt;&lt;a class="reference external" href="imgs/twemproxy-flame-mget-after-improve.svg"&gt;svg2&lt;/a&gt;&lt;/p&gt;
</summary><category term="all"></category></entry><entry><title>redis-aof-replay</title><link href="/redis-aof-replay.html" rel="alternate"></link><updated>2014-02-27T09:44:50+08:00</updated><author><name>ning</name></author><id>tag:,2014-02-27:redis-aof-replay.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof" id="id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;简单的重放aof&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aofredis" id="id14"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到redis实例&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aoftwemproxy" id="id15"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到twemproxy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id16"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;各种命令的aof格式&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mset" id="id17"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;mset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#del-key" id="id18"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;del 删除多个key&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id19"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id20"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;aof解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#aof-replay" id="id21"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现aof-replay&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id22"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;功能和注意&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#tail-f" id="id23"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fdselect" id="id24"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试在fd上做select&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#poll" id="id25"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;用poll 呢?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id26"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f 怎么做的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id27"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#twemproxypipeline" id="id28"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;twemproxy对pipeline支持不好和性能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#safe" id="id29"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;safe模式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id30"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;测试几种方式的性能&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#bench" id="id31"&gt;4.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞式简单bench&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#gprof" id="id32"&gt;4.3.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;gprof结果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#write-read" id="id33"&gt;4.3.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞改为直接write/read&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#pipeline" id="id34"&gt;4.3.2.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;改成pipeline:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id35"&gt;4.3.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;异步bench&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-benchmark" id="id36"&gt;4.3.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-benchmark 的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id37"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id38"&gt;4.3.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;具体实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#update-2014-03-13-10-13-19" id="id39"&gt;4.3.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;update &amp;#64;2014-03-13 10:13:19&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id40"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;ul class="auto-toc"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#clean" id="id41"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;clean脚本&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id42"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="aof"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;简单的重放aof&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="aofredis"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到redis实例&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;aof 文件有个优势:&lt;/p&gt;
&lt;p&gt;因为它的格式是和协议一致, 重放非常简单, 直接用如下命令即可:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cat data/appendonly.aof | nc localhost 22003
+OK
+OK
+OK
+OK
+OK
+OK
+OK
+OK
&lt;/pre&gt;
&lt;p&gt;或者用 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-cli&lt;/span&gt;&lt;/tt&gt; 提供的pipe功能:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat data/appendonly.aof | redis-cli --pipe  -h 127.0.0.5 -p 22003
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 115
&lt;/pre&gt;
&lt;p&gt;时间消耗, 在我的pc上 300M需要 120s, 速度大约2M/s, (6w条/s), 每天单进程可以重放156G(5亿条):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis-mgr$ ll /home/ning/Desktop/t/appendonly.aof
787171 -rw-r--r-- 1 ning ning 371M 2014-02-26 22:56 /home/ning/Desktop/t/appendonly.aof

ning&amp;#64;ning-laptop:~/idning-github/redis-mgr$ time cat /home/ning/Desktop/t/appendonly.aof | redis-cli --pipe -h 127.0.0.5 -p 22003
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 7339651

real    1m58.729s
user    0m8.700s
sys 0m1.780s
&lt;/pre&gt;
&lt;p&gt;实现: pipe功能就是简单的 把STDIN 的内容写到soket:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssize_t nread = read(STDIN_FILENO,obuf,sizeof(obuf));
ssize_t nwritten = write(fd,obuf+obuf_pos,obuf_len);
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="aoftwemproxy"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;重放aof到twemproxy&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;上面的方法不能通过twemproxy重放:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:/tmp/r/redis-22001$ cat data/appendonly.aof | redis-cli --pipe  -h 127.0.0.5 -p 24000
All data transferred. Waiting for the last reply...

No replies for 30 seconds: exiting.
errors: 1, replies: 0
&lt;/pre&gt;
&lt;p&gt;原因:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;proxy does not support mset/select ....&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了把它变成一个迁移工具, pipe工具性能已经满足要求, 功能上需要增加支持:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;兼容proxy(去掉select, 处理mset)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--filter&lt;/span&gt;&lt;/tt&gt; : key filter (这里需要解析命令)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--rewrite&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--tail&lt;/span&gt;&lt;/tt&gt; 支持 &lt;tt class="docutils literal"&gt;tail &lt;span class="pre"&gt;-f&lt;/span&gt;&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;最后发的echo命令要去掉&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ol class="arabic simple" start="6"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--check&lt;/span&gt;&lt;/tt&gt; check any command not supported&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id16"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;各种命令的aof格式&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#key-value
redis-cli -h 127.0.0.5 -p 22001 SET key0 v0
redis-cli -h 127.0.0.5 -p 22001 GETSET key0 v0
redis-cli -h 127.0.0.5 -p 22001 APPEND key0 v_a
redis-cli -h 127.0.0.5 -p 22001 STRLEN key0
#expire
redis-cli -h 127.0.0.5 -p 22001 EXPIRE key0 5
sleep 6
redis-cli -h 127.0.0.5 -p 22001 SETEX key0 5 v_a
sleep 6
#counter
redis-cli -h 127.0.0.5 -p 22001 INCR key1
#hash
redis-cli -h 127.0.0.5 -p 22001 HSET key3 h3 val3
#list
redis-cli -h 127.0.0.5 -p 22001 LPUSH key4 v4
redis-cli -h 127.0.0.5 -p 22001 LPOP key4
#set
redis-cli -h 127.0.0.5 -p 22001 SADD key5 v5
&lt;/pre&gt;
&lt;p&gt;对应关系如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
----------------------------------------------------------------------------------------------------------------

#key-value
redis-cli -h 127.0.0.5 -p 22001 SET key0 v0
                                                        *3
                                                        $3
                                                        SET
                                                        $4
                                                        key0
                                                        $2
                                                        v0

redis-cli -h 127.0.0.5 -p 22001 GETSET key0 v0
                                                        *3
                                                        $6
                                                        GETSET
                                                        $4
                                                        key0
                                                        $2
                                                        v0

redis-cli -h 127.0.0.5 -p 22001 APPEND key0 v_a
                                                        *3
                                                        $6
                                                        APPEND
                                                        $4
                                                        key0
                                                        $3
                                                        v_a

redis-cli -h 127.0.0.5 -p 22001 STRLEN key0 &amp;lt;nothing&amp;gt;

redis-cli -h 127.0.0.5 -p 22001 EXPIRE key0 5           (转变为PEXPIREAT)

                                                        *3
                                                        $9
                                                        PEXPIREAT
                                                        $4
                                                        key0
                                                        $13
                                                        1393467438683

sleep 6                                                 (5s后被删除)

                                                        *2
                                                        $3
                                                        DEL
                                                        $4
                                                        key0

redis-cli -h 127.0.0.5 -p 22001 SETEX key0 5 v_a        (SETEX转成两个命令)
                                                        *3
                                                        $3
                                                        SET
                                                        $4
                                                        key0
                                                        $3
                                                        v_a

                                                        *3
                                                        $9
                                                        PEXPIREAT
                                                        $4
                                                        key0
                                                        $13
                                                        1393467444711

sleep 6
                                                        *2
                                                        $3
                                                        DEL
                                                        $4
                                                        key0

redis-cli -h 127.0.0.5 -p 22001 INCR key1               &amp;lt;INCR记录的是变化, 不是结果&amp;gt;
                                                        *2
                                                        $4
                                                        INCR
                                                        $4
                                                        key1

redis-cli -h 127.0.0.5 -p 22001 HSET key3 h3 val3
                                                        *4
                                                        $4
                                                        HSET
                                                        $4
                                                        key3
                                                        $2
                                                        h3
                                                        $4
                                                        val3

redis-cli -h 127.0.0.5 -p 22001 LPUSH key4 v4
                                                        *3
                                                        $5
                                                        LPUSH
                                                        $4
                                                        key4
                                                        $2
                                                        v4

redis-cli -h 127.0.0.5 -p 22001 LPOP key4
                                                        *2
                                                        $4
                                                        LPOP
                                                        $4
                                                        key4

redis-cli -h 127.0.0.5 -p 22001 SADD key5 v5
                                                        *3
                                                        $4
                                                        SADD
                                                        $4
                                                        key5
                                                        $2
                                                        v5
&lt;/pre&gt;
&lt;div class="section" id="mset"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id17"&gt;2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;mset&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
$redis-cli -h 127.0.0.5 -p 22000 mset k1 v1 k2 v2

                                                            mset
                                                            $2
                                                            k1
                                                            $2
                                                            v1
                                                            $2
                                                            k2
                                                            $2
                                                            v2
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="del-key"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;del 删除多个key&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;不是记录3个del命令, 而是记录一个命令&lt;/li&gt;
&lt;li&gt;只要del生效(能删掉任何一条记录), 就会记录对命令中所有key的删除.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
$ redis-cli -h 127.0.0.5 -p 22001 set key1 3
OK
                                                                        *3
                                                                        $3
                                                                        set
                                                                        $4
                                                                        key1
                                                                        $1
                                                                        3

$ redis-cli -h 127.0.0.5 -p 22001 set key2 3
OK

                                                                        *3
                                                                        $3
                                                                        set
                                                                        $4
                                                                        key2
                                                                        $1
                                                                        3

#注意这里删除3个key, 只有2个key存在的情况下, 记录的aof是在一个del命令中删除3个key
$ redis-cli -h 127.0.0.5 -p 22001 del key1 key2 key3
(integer) 2
                                                                        *4
                                                                        $3
                                                                        del
                                                                        $4
                                                                        key1
                                                                        $4
                                                                        key2
                                                                        $4
                                                                        key3

$ redis-cli -h 127.0.0.5 -p 22001 del key1 key2 key3
(integer) 0
$ redis-cli -h 127.0.0.5 -p 22001 del key1 key2 key3
(integer) 0
                                                                        这里没有对应的aof
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;aof 中记录的命令可能是大写/小写. 用户怎么用就是怎么记录.&lt;/li&gt;
&lt;li&gt;mset, del比较记录的也是原始操作.&lt;/li&gt;
&lt;li&gt;incr等, 也是记录操作, 而不是记录结果.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id20"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;aof解析&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;aof解析非常简单, 从 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-check-aof&lt;/span&gt;&lt;/tt&gt; 中就可以看出来:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
off_t process(FILE *fp) {
    long argc;
    off_t pos = 0;
    int i, multi = 0;
    char *str;

    while(1) {
        if (!multi) pos = ftello(fp);
        if (!readArgc(fp, &amp;amp;argc)) break;

        for (i = 0; i &amp;lt; argc; i++) {
            readString(fp,&amp;amp;str);
        }
    }
}
&lt;/pre&gt;
&lt;p&gt;redis中解析, load aof 是这个函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* Replay the append log file. On error REDIS_OK is returned. On non fatal
 * error (the append only file is zero-length) REDIS_ERR is returned. On
 * fatal error an error Message is logged and the program exists. */
int loadAppendOnlyFile(char *filename) {
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="aof-replay"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id21"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;实现aof-replay&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;功能和注意&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;points:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;remove all &lt;tt class="docutils literal"&gt;select&lt;/tt&gt; / &lt;tt class="docutils literal"&gt;multi&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;change &lt;tt class="docutils literal"&gt;MSET/MSETNX/DEL&lt;/tt&gt; to many &lt;tt class="docutils literal"&gt;SET/SETNX/DEL&lt;/tt&gt; cmd;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--filter&lt;/span&gt;&lt;/tt&gt; : filter key by prefix&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--orig&lt;/span&gt;&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--rewrite&lt;/span&gt;&lt;/tt&gt;, rewrite key.&lt;/li&gt;
&lt;li&gt;follow aof modification like &lt;tt class="docutils literal"&gt;tail &lt;span class="pre"&gt;-f&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--check&lt;/span&gt;&lt;/tt&gt; check any command not supported&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;问题:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;如果解析到multi(后面可能有一个回滚, 不能简单丢弃multi)&lt;/li&gt;
&lt;li&gt;测试可以通过回回放一个现有库, 然后对比&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="tail-f"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id23"&gt;4.2&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这里要实现tail -f 的功能, 需要一个readline 的功能(因为fgets在EOF的时候直接返回, 不能用fgets)&lt;/p&gt;
&lt;p&gt;对 &lt;tt class="docutils literal"&gt;read&lt;/tt&gt; 做了几个测试, 发现:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;如果fd是文件, 文件在变化的情况下, 用read() 系统调用, 如果到达文件尾, 会直接返回, 而不会等待.&lt;/li&gt;
&lt;li&gt;如果fd是网络, read() 如果没有可读, 就会阻塞.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="fdselect"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id24"&gt;4.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;尝试在fd上做select&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;tail -f 有这样的逻辑, 但是我试了, select 就算在文件尾也总是返回可读. 查了一下:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://stackoverflow.com/questions/11901884/how-can-select-wait-on-regular-file-descriptors-non-sockets"&gt;http://stackoverflow.com/questions/11901884/how-can-select-wait-on-regular-file-descriptors-non-sockets&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Disk files are always ready to read (but the read might return 0 bytes if you're already at the end of the file), so you can't use select() on a disk file to find out when new data is added to the file.
&lt;/pre&gt;
&lt;p&gt;POSIX says:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
File descriptors associated with regular files shall always select true for ready to read, ready to write, and error conditions.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="poll"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id25"&gt;4.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;用poll 呢?&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;这里有一个详细的测试: &lt;a class="reference external" href="http://www.greenend.org.uk/rjk/tech/poll.html"&gt;http://www.greenend.org.uk/rjk/tech/poll.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;依然显示 对于regular file, 在到达EOF时, poll总是返回POLLIN.&lt;/p&gt;
&lt;p&gt;这就是说, select/poll 只对 pipes/sockets 这样会发生阻塞读写的介质有效.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id26"&gt;4.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;tail -f 怎么做的&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;看源码:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;coreutils-8.12/src/tail.c 用了 &lt;tt class="docutils literal"&gt;inotify&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;coreutils-8.12/src/tail.c 在用pipe方式 的时候(作为另一个程序的输出的下游), 用了 &lt;tt class="docutils literal"&gt;select&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;比较老的版本(7.4) 用sleep&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用sleep的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning/langtest/c$ tail --version
tail (GNU coreutils) 7.4

ning&amp;#64;ning-laptop:~/idning/langtest/c$ strace tail -f common.h
execve(&amp;quot;/usr/bin/tail&amp;quot;, [&amp;quot;tail&amp;quot;, &amp;quot;-f&amp;quot;, &amp;quot;common.h&amp;quot;], [/* 69 vars */]) = 0
brk(0)                                  = 0xd1a000
...
nanosleep({1, 0}, NULL)                 = 0
fstat(3, {st_mode=S_IFREG|0644, st_size=635, ...}) = 0
nanosleep({1, 0}, NULL)                 = 0
fstat(3, {st_mode=S_IFREG|0644, st_size=635, ...}) = 0
nanosleep({1, 0}, NULL)                 = 0
fstat(3, {st_mode=S_IFREG|0644, st_size=635, ...}) = 0
&lt;/pre&gt;
&lt;p&gt;用sleep的代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* Tail NFILES files forever, or until killed.
   The pertinent information for each file is stored in an entry of F.
   Loop over each of them, doing an fstat to see if they have changed size,
   and an occasional open/fstat to see if any dev/ino pair has changed.
   If none of them have changed size in one iteration, sleep for a
   while and try again.  Continue until the user interrupts us.  */


static void tail_forever (struct File_spec *f, int nfiles, double sleep_interval)
{

    ...

    if (fstat (fd, &amp;amp;stats) != 0)
    {
      f[i].fd = -1;
      f[i].errnum = errno;
      error (0, errno, &amp;quot;%s&amp;quot;, name);
      continue;
    }

      if (f[i].mode == stats.st_mode
      &amp;amp;&amp;amp; (! S_ISREG (stats.st_mode) || f[i].size == stats.st_size)
      &amp;amp;&amp;amp; timespec_cmp (f[i].mtime, get_stat_mtime (&amp;amp;stats)) == 0)
    {
        //not change
    }
    change
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id27"&gt;4.2.4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;通过sleep实现tail -f&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="twemproxypipeline"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id28"&gt;4.3&amp;nbsp;&amp;nbsp;&amp;nbsp;twemproxy对pipeline支持不好和性能&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-cli&lt;/span&gt; &lt;span class="pre"&gt;--pipe&lt;/span&gt;&lt;/tt&gt; 是使用pipeline 模式的, 只要server端可写, 就会不停的写,&lt;/p&gt;
&lt;p&gt;但是twemproxy总是尽最大能力的读, 把消息放在内存中, 这样消息都会堆在twemproxy, 并且超时.&lt;/p&gt;
&lt;p&gt;这个问题的讨论见: &lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/203"&gt;https://github.com/twitter/twemproxy/issues/203&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;解决方法:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;safe模式, 一条一条写，写成功再写下一条.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;batch模式, 为了保证尽量写成功, 此时需要&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;加大twemproxy 的timeout.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;有某种block机制, 确保不会有大量请求堆在twemproxy.&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first last"&gt;比如客户端计数, 发出的req - 收到的resp &amp;lt; 1024&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="safe"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id29"&gt;4.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;safe模式&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;用redisCommandArgv:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
while(1){
    msg = readMsg(fp);
    reply = redisCommandArgv(context, msg-&amp;gt;argc, (const char **)msg-&amp;gt;argv, msg-&amp;gt;argvlen);
    freeReplyObject(reply);
    freeMsg(msg);
}
&lt;/pre&gt;
&lt;p&gt;发现性能不好: 后端为twemproxy时大约7000/s, 后端为redis大约10000/s.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id30"&gt;4.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;测试几种方式的性能&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="bench"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id31"&gt;4.3.2.1&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞式简单bench&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;直接调用redisCommand 性能如何:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat bench1.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;

#include &amp;quot;hiredis.h&amp;quot;

int main(void) {
    unsigned int i;
    redisContext *c;
    redisReply *reply;

    struct timeval timeout = { 1, 500000 }; // 1.5 seconds
    c = redisConnectWithTimeout((char*)&amp;quot;127.0.0.5&amp;quot;, 22000, timeout);
    if (c-&amp;gt;err) {
        printf(&amp;quot;Connection error: %s\n&amp;quot;, c-&amp;gt;errstr);
        exit(1);
    }
    for(i=0; i&amp;lt;100*1000; i++){
        reply = redisCommand(c,&amp;quot;SET %s %s&amp;quot;, &amp;quot;foo&amp;quot;, &amp;quot;hello world&amp;quot;);
        freeReplyObject(reply);
    }
    return 0;
}
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cc bench1.c -I ./ -L ./ -l hiredis   (或cc bench1.c libhiredis.a)
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ time ./a.out

real        0m6.945s
user        0m0.710s
sys 0m1.710s
&lt;/pre&gt;
&lt;p&gt;100*1000/6.9 = 1.4w/s&lt;/p&gt;
&lt;div class="section" id="gprof"&gt;
&lt;h6&gt;&lt;a class="toc-backref" href="#id32"&gt;4.3.2.1.1&amp;nbsp;&amp;nbsp;&amp;nbsp;gprof结果&lt;/a&gt;&lt;/h6&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cc bench1.c libhiredis.a -pg
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ ./a.out
$ gprof  ./a.out ./gmon.out  | vim -

Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total
 time   seconds   seconds    calls  Ts/call  Ts/call  name
 22.23      0.04     0.04                             redisReaderGetReply
 16.67      0.07     0.03                             redisvFormatCommand
 11.12      0.09     0.02                             redisGetReply
 11.12      0.11     0.02                             sdscatlen
  5.56      0.12     0.01                             main
  5.56      0.13     0.01                             redisBufferRead
  5.56      0.14     0.01                             redisBufferWrite
  5.56      0.15     0.01                             sdsIncrLen
  5.56      0.16     0.01                             sdsempty
  5.56      0.17     0.01                             sdsnewlen
  2.78      0.18     0.01                             sdsMakeRoomFor
  2.78      0.18     0.01                             sdsRemoveFreeSpace
&lt;/pre&gt;
&lt;p&gt;总共7s, 为啥self seconds 加起来不是7s&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="write-read"&gt;
&lt;h6&gt;&lt;a class="toc-backref" href="#id33"&gt;4.3.2.1.2&amp;nbsp;&amp;nbsp;&amp;nbsp;阻塞改为直接write/read&lt;/a&gt;&lt;/h6&gt;
&lt;p&gt;依然很慢:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cat bench3.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;

#include &amp;quot;hiredis.h&amp;quot;

int main(void) {
    unsigned int i;
    redisContext *c;
    redisReply *reply;
    int ret;

    struct timeval timeout = { 1, 500000 }; // 1.5 seconds
    c = redisConnectWithTimeout((char*)&amp;quot;127.0.0.5&amp;quot;, 22000, timeout);
    if (c-&amp;gt;err) {
        printf(&amp;quot;Connection error: %s\n&amp;quot;, c-&amp;gt;errstr);
        exit(1);
    }

    char *cmd = &amp;quot;*3\r\n$3\r\nSET\r\n$3\r\nfoo\r\n$9\r\nbarbarbar\r\n&amp;quot;;
    int len = strlen(cmd);

    char buf[1024];
    for(i=0; i&amp;lt;100*1000; i++){
        ret = write(c-&amp;gt;fd, cmd, len);
        assert(len == ret);

        /*fprintf(stderr, &amp;quot;read\n&amp;quot;);*/
        ret = read(c-&amp;gt;fd, buf, 5);
        assert(5 == ret);

        buf[5] = 0;
        /*fprintf(stderr, &amp;quot;%d: %s\n&amp;quot;, i, buf);*/
        /*assert(0 == strcmp(buf, &amp;quot;+OK\r\n&amp;quot;));*/
    }
    return 0;
}
&lt;/pre&gt;
&lt;p&gt;还是要5s. (2w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pipeline"&gt;
&lt;h6&gt;&lt;a class="toc-backref" href="#id34"&gt;4.3.2.1.3&amp;nbsp;&amp;nbsp;&amp;nbsp;改成pipeline:&lt;/a&gt;&lt;/h6&gt;
&lt;pre class="literal-block"&gt;
for(i=0; i&amp;lt;100*1000; i++){
    ret = twrite(c-&amp;gt;fd, cmd, len);
    assert(len == ret);

}
for(i=0; i&amp;lt;100*1000; i++){
    ret = tread(c-&amp;gt;fd, buf, 5);
    assert(5 == ret);
}
&lt;/pre&gt;
&lt;p&gt;只需要0.4s&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id35"&gt;4.3.2.2&amp;nbsp;&amp;nbsp;&amp;nbsp;异步bench&lt;/a&gt;&lt;/h5&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cat bench2.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;quot;hiredis.h&amp;quot;
#include &amp;quot;async.h&amp;quot;
#include &amp;quot;adapters/ae.h&amp;quot;

/* Put event loop in the global scope, so it can be explicitly stopped */
static aeEventLoop *loop;

void setCallback(redisAsyncContext *c, void *r, void *privdata) {
    redisReply *reply = r;
    if (reply == NULL) return;
    int * pi = (int*) privdata;

    printf(&amp;quot;argv[%d]: %s\n&amp;quot;, *pi, reply-&amp;gt;str);

    (*pi)++;
    if (*pi &amp;gt; 100*1000)
        exit(0);

    redisAsyncCommand(c, setCallback, (char*)pi, &amp;quot;SET thekey %s&amp;quot;, &amp;quot;xxxxxxxxxxxxxx&amp;quot;);
}

void connectCallback(const redisAsyncContext *c, int status) {
    if (status != REDIS_OK) {
        printf(&amp;quot;Error: %s\n&amp;quot;, c-&amp;gt;errstr);
        return;
    }
    printf(&amp;quot;Connected...\n&amp;quot;);
}
void disconnectCallback(const redisAsyncContext *c, int status) {
    if (status != REDIS_OK) {
        printf(&amp;quot;Error: %s\n&amp;quot;, c-&amp;gt;errstr);
        return;
    }
    printf(&amp;quot;Disconnected...\n&amp;quot;);
}

int main() {
    signal(SIGPIPE, SIG_IGN);

    redisAsyncContext *c = redisAsyncConnect(&amp;quot;127.0.0.1&amp;quot;, 6379);
    if (c-&amp;gt;err) {
        /* Let *c leak for now... */
        printf(&amp;quot;Error: %s\n&amp;quot;, c-&amp;gt;errstr);
        return 1;
    }

    loop = aeCreateEventLoop(1000);
    redisAeAttach(loop, c);
    redisAsyncSetConnectCallback(c,connectCallback);
    redisAsyncSetDisconnectCallback(c,disconnectCallback);

    int i = 0;
    redisAsyncCommand(c, setCallback, (char*)&amp;amp;i, &amp;quot;SET thekey %s&amp;quot;, &amp;quot;xxxxxxxxxxxxxx&amp;quot;);
    aeMain(loop);
    return 0;
}
ning&amp;#64;ning-laptop:~/idning-github/redis/deps/hiredis$ cc -I../../src ../../src/ae.o ../../src/zmalloc.o bench2.c libhiredis.a ../jemalloc/lib/libjemalloc.a -lpthread
&lt;/pre&gt;
&lt;p&gt;still 6s.(差不多还是2w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-benchmark"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id36"&gt;4.3.2.3&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-benchmark 的实现&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;异步.&lt;/p&gt;
&lt;p&gt;创建一些client, 每个client注册如下事件:&lt;/p&gt;
&lt;blockquote&gt;
aeCreateFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_WRITABLE,writeHandler,c);&lt;/blockquote&gt;
&lt;p&gt;writeHandler:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void writeHandler(aeEventLoop *el, int fd, void *privdata, int mask) {
    client c = privdata;
    REDIS_NOTUSED(el);
    REDIS_NOTUSED(fd);
    REDIS_NOTUSED(mask);

    /* Initialize request when nothing was written. */
    if (c-&amp;gt;written == 0) {
        /* Enforce upper bound to number of requests. */
        if (config.requests_issued++ &amp;gt;= config.requests) {
            freeClient(c);
            return;
        }

        /* Really initialize: randomize keys and set start time. */
        if (config.randomkeys) randomizeClientKey(c);
        c-&amp;gt;start = ustime();
        c-&amp;gt;latency = -1;
    }

    if (sdslen(c-&amp;gt;obuf) &amp;gt; c-&amp;gt;written) {
        void *ptr = c-&amp;gt;obuf+c-&amp;gt;written;
        int nwritten = write(c-&amp;gt;context-&amp;gt;fd,ptr,sdslen(c-&amp;gt;obuf)-c-&amp;gt;written);
        if (nwritten == -1) {
            if (errno != EPIPE)
                fprintf(stderr, &amp;quot;Writing to socket: %s\n&amp;quot;, strerror(errno));
            freeClient(c);
            return;
        }
        c-&amp;gt;written += nwritten;
        if (sdslen(c-&amp;gt;obuf) == c-&amp;gt;written) {
            aeDeleteFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_WRITABLE);
            aeCreateFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_READABLE,readHandler,c);
        }
    }
}
&lt;/pre&gt;
&lt;p&gt;每写成功一个消息, 去掉AE_WRITABLE, 加上AE_READABLE:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void writeHandler(aeEventLoop *el, int fd, void *privdata, int mask) {
    if (sdslen(c-&amp;gt;obuf) == c-&amp;gt;written) {
        aeDeleteFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_WRITABLE);
        aeCreateFileEvent(config.el,c-&amp;gt;context-&amp;gt;fd,AE_READABLE,readHandler,c);
    }
}
&lt;/pre&gt;
&lt;p&gt;在read完之后, 重新用激活可写事件:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if (c-&amp;gt;pending == 0) {
    clientDone(c); //里面会加AE_WRITABLE
    break;
}
&lt;/pre&gt;
&lt;p&gt;redis-benchmark 默认是不用pipeline 的. 写一个, 读一个, 但是是用异步api.&lt;/p&gt;
&lt;p&gt;如果pipeline模式benchmark, 它在准备数据的时候就一次性把多个命令写道obuf里面去:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
for (j = 0; j &amp;lt; config.pipeline; j++)
    c-&amp;gt;obuf = sdscatlen(c-&amp;gt;obuf,cmd,len);
c-&amp;gt;pending = config.pipeline;
&lt;/pre&gt;
&lt;p&gt;发现用redis-benchmark性能能达到5w左右, 后来发现是因为redis-benchmark默认-c 50, 就是50个client并发, 如果用-c 1的话, 性能还是比较差:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/src$ time redis-benchmark -h 127.0.0.5 -p 22000 -c 1 -t set -n 100000
====== SET ======
  100000 requests completed in 8.64 seconds
  1 parallel clients
  3 bytes payload
  keep alive: 1

99.99% &amp;lt;= 1 milliseconds
100.00% &amp;lt;= 2 milliseconds
100.00% &amp;lt;= 3 milliseconds
100.00% &amp;lt;= 7 milliseconds
11579.44 requests per second



real        0m8.651s
user        0m0.570s
sys 0m2.390s
&lt;/pre&gt;
&lt;p&gt;大约8s, (1.2w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id37"&gt;4.3.3&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h4&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;为什么这里的非阻塞调用benchmark性能很差?&lt;/li&gt;
&lt;li&gt;问什么redis-benmark的写法, 性能好?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;三种方式:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;阻塞: 慢&lt;/li&gt;
&lt;li&gt;自己的非阻塞写法: 慢&lt;/li&gt;
&lt;li&gt;redis-benchmark写法: 慢&lt;/li&gt;
&lt;li&gt;redis-cli的pipe写法: 快&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;TODO: &lt;strong&gt;这里的原因, 还是不清楚..&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;难道是, 如果read系统调用时, 数据准备好, 则很快, 没准备好, 则很慢.&lt;/p&gt;
&lt;p&gt;同样都是发送, 等待响应, 解析响应.&lt;/p&gt;
&lt;p&gt;貌似只能理解为用阻塞方式等待响应很耗时.&lt;/p&gt;
&lt;p&gt;这个问题, 可以把服务器抽象为一个简单的echo-server, 此时客户端一问一答的形式, 最大能达到多大的qps.&lt;/p&gt;
&lt;p&gt;用strace发现一个共同点: 2,3都是用epoll异步, 一次epoll_wait 做一次write, 在epoll_wait, 再一次read:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
epoll_ctl(3, EPOLL_CTL_MOD, 4, {EPOLLIN, {u32=4, u64=4}}) = 0
epoll_ctl(3, EPOLL_CTL_DEL, 4, {0, {u32=4, u64=4}}) = 0
epoll_ctl(3, EPOLL_CTL_ADD, 4, {EPOLLOUT, {u32=4, u64=4}}) = 0
epoll_wait(3, {{EPOLLOUT, {u32=4, u64=4}}}, 10240, 240) = 1
write(4, &amp;quot;*3\r\n$3\r\nSET\r\n$16\r\nkey:__rand_int&amp;quot;..., 45) = 45
epoll_ctl(3, EPOLL_CTL_DEL, 4, {0, {u32=4, u64=4}}) = 0
epoll_ctl(3, EPOLL_CTL_ADD, 4, {EPOLLIN, {u32=4, u64=4}}) = 0
epoll_wait(3, {{EPOLLIN, {u32=4, u64=4}}}, 10240, 239) = 1
read(4, &amp;quot;+OK\r\n&amp;quot;, 16384)               = 5
&lt;/pre&gt;
&lt;p&gt;4是用pool, 而且一个pool就能做一次read, 一次write:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis/src$ strace ./redis-cli  -h 127.0.0.5 -p 22000 --replay ~/Desktop/t/appendonly.aof
poll([{fd=3, events=POLLIN|POLLOUT}], 1, 1000) = 1 ([{fd=3, revents=POLLIN|POLLOUT}])
read(3, &amp;quot;+OK\r\n&amp;quot;, 16384)               = 5
read(3, 0x7fff7d548f10, 16384)          = -1 EAGAIN (Resource temporarily unavailable)
write(3, &amp;quot;*3\r\n$3\r\nSET\r\n$13\r\nkkk-100000756\r&amp;quot;..., 53) = 53
poll([{fd=3, events=POLLIN|POLLOUT}], 1, 1000) = 1 ([{fd=3, revents=POLLIN|POLLOUT}])
read(3, &amp;quot;+OK\r\n&amp;quot;, 16384)               = 5
read(3, 0x7fff7d548f10, 16384)          = -1 EAGAIN (Resource temporarily unavailable)
write(3, &amp;quot;*3\r\n$3\r\nSET\r\n$13\r\nkkk-100000757\r&amp;quot;..., 53) = 53
&lt;/pre&gt;
&lt;div class="section" id="id10"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id38"&gt;4.3.3.1&amp;nbsp;&amp;nbsp;&amp;nbsp;具体实现&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;当前我的写法相当于长度为1的pipe, 本质和 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-cli&lt;/span&gt;&lt;/tt&gt; 写法一样. 性能挺好(5w/s)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="update-2014-03-13-10-13-19"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id39"&gt;4.3.3.2&amp;nbsp;&amp;nbsp;&amp;nbsp;update &amp;#64;2014-03-13 10:13:19&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;后来发现, 我当时写的--replay 有bug, 相当于用了长度为 100左右的pipe. 所以表现的性能很好. 代码是在这个commit:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/idning/redis/commit/b122ab0c749f2a93bb514ae07ba73739690ab46e"&gt;https://github.com/idning/redis/commit/b122ab0c749f2a93bb514ae07ba73739690ab46e&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;修改了这个bug后:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/idning/redis/commit/b956e2cf92feb510f7d1a2f158a8eafe907d9ae1"&gt;https://github.com/idning/redis/commit/b956e2cf92feb510f7d1a2f158a8eafe907d9ae1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发现如果定义pipe长度是1, 性能就在1w左右. 改为10, 就在5w左右(laptop测试)&lt;/p&gt;
&lt;p&gt;如果用线上机器:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pipesize    1    10  100  1000
loclhost:   1w   4w  5w   5w
online:     0.3  1w  10w  12w
&lt;/pre&gt;
&lt;p&gt;线上pipeline为1时, 只有0.3, 原因是线上网络RTT大, (这么看每个请求3ms), 用的是压力较大的线上机器.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id40"&gt;4.4&amp;nbsp;&amp;nbsp;&amp;nbsp;其它&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="clean"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id41"&gt;4.4.1&amp;nbsp;&amp;nbsp;&amp;nbsp;clean脚本&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;需要一个脚本, 如果重放到一半出错, 需要清除所有前缀为xxx的key&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id42"&gt;5&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;code:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
https://github.com/idning/redis/blob/replay/src/redis-cli.c
https://github.com/cen-li/redis/blob/redis-2.8.3_replay-aof/src/redis-replay-aof.c
&lt;/pre&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>redis-mgr 中redis实例的迁移</title><link href="/redis-instance-migrate.html" rel="alternate"></link><updated>2014-02-11T10:29:10+08:00</updated><author><name>ning</name></author><id>tag:,2014-02-11:redis-instance-migrate.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;两种方法:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-mgr" id="id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr中如何操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;实现细节:主从同步的步骤&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;两种扩容思路:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;一个是 redis-mgr 中redis实例的迁移, 迁到一个内存大的机器&lt;/li&gt;
&lt;li&gt;另外一个是新搭建集群, 把数据迁移过去.&lt;/li&gt;
&lt;li&gt;和2类似, 把旧集群中某个业务(一定前缀)的数据迁移到新集群.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里说的是思路1&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;两种方法:&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;冷迁移&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;步骤&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;拷贝rdb/aof文件,&lt;/li&gt;
&lt;li&gt;搭建新的master-slave&lt;/li&gt;
&lt;li&gt;更新twemproxy配置 重启&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;问题&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;丢失部分到老master/slave的写&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;热迁移&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;场景:&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;集群维护(如部分机器下线)&lt;/li&gt;
&lt;li&gt;集群扩容, 如2*32 实例原来部署在16 机器上,  可以扩容到 32/64 机器上.&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;步骤, 假设老的master/slave 为m,s, 新的为n1, n2&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;搭建n1, n1 SLAVEOF m, 等待同步完成.&lt;/li&gt;
&lt;li&gt;kill s&lt;/li&gt;
&lt;li&gt;kill m, n1成为master.&lt;/li&gt;
&lt;li&gt;搭建n2, n2 SLAVEOF n1&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果服务down了, 起不来(主从都down了起不来的可能性较小), 只能使用冷迁移&lt;/p&gt;
&lt;p&gt;下面是热迁移的方法.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-mgr"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;redis-mgr中如何操作&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;config中写操作步骤:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cluster0 = {
    'migrate' : [
        'host1:port' =&amp;gt; 'host2:port'
    ],
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;直接修改 cluster 中redis 这一节的配置.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;通过命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./bin/deploy.py cluster0 migrate xxxx  xxx
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最后选择了3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;实现细节:主从同步的步骤&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;通过观察 现在 集群中杀掉从库重启后, 通过redis 的INFO命令观察主/从的表现:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;slave 启动, load 本地的aof文件, load完成后:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
used_memory_peak_human CHANGE FROM 2.32G to 2.33G
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;收到sentinel 发来的SLAVEOF命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
master_host CHANGE FROM  to 127.0.0.5
master_port CHANGE FROM  to 22000
master_link_status CHANGE FROM  to down
slave_repl_offset CHANGE FROM  to -1
&lt;/pre&gt;
&lt;p&gt;此时 master 这边的状态变化:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slave0 CHANGE FROM  to ip=127.0.0.5,port=23000,state=wait_bgsave,offset=0,lag=0
&lt;/pre&gt;
&lt;p&gt;master 开始做一次bgsave.  slave 等待bgsave(wait_bgsave)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;master bgsave 完成, 开始传送数据:&lt;/p&gt;
&lt;p&gt;master:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slave0 CHANGE FROM ip=127.0.0.5,port=23000,state=wait_bgsave,offset=0,lag=0 to ip=127.0.0.5,port=23000,state=send_bulk,offset=0,lag=0
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;rdb 传送完成后, slave load 获得的数据:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
master_sync_left_bytes CHANGE FROM 47165401 to 0
mem_fragmentation_ratio CHANGE FROM 1.01 to 1.21
used_memory_human CHANGE FROM 2.33G to 18.79M


开始load 新的db:
used_memory_human CHANGE FROM 18.79M to 116.79M
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;load完成:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
aof_rewrite_in_progress CHANGE FROM 0 to 1
master_link_status CHANGE FROM down to up
slave_repl_offset CHANGE FROM -1 to 995178543
used_memory_human CHANGE FROM 2.29G to 2.33G
loading CHANGE FROM 1 to 0
&lt;/pre&gt;
&lt;p&gt;此时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
slave0 CHANGE FROM ip=127.0.0.5,port=23000,state=send_bulk,offset=0,lag=0 to ip=127.0.0.5,port=23000,state=online,offset=0,lag=1
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;基准数据同步完成的标志&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;master 上看对应slave的 &lt;tt class="docutils literal"&gt;status=online&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;slave 上看 &lt;tt class="docutils literal"&gt;master_link_status = up&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;实时同步跟上的标志&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;从master 上看 &lt;tt class="docutils literal"&gt;lag=0&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;master 的 &lt;tt class="docutils literal"&gt;master_repl_offset&lt;/tt&gt; : 和slave 的 &lt;tt class="docutils literal"&gt;slave_repl_offset&lt;/tt&gt;  一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;进度信息获取:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;slave 的内存/master 的内存&lt;/li&gt;
&lt;li&gt;db0:keys 在master/slave 上对比.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;小结&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最终实现了下面命令:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
migrate src dst : migrate a redis instance to another machine
&lt;/pre&gt;
&lt;p&gt;步骤:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pre_check,
force_src_be_slave,
deploy_dst,
add_dst_as_slave,
cleanup,
sentinel_reset,
update_config,
&lt;/pre&gt;
&lt;p&gt;使用方法:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/deploy.py cluster0 migrate cluster0-22000:127.0.0.5:23000:/tmp/r/redis-23000 cluster0-22000:127.0.0.5:50015:/tmp/r/redis-50015
...
2014-02-27 19:21:58,667 [MainThread] [INFO] deploy [redis:127.0.0.5:50015]
2014-02-27 19:21:59,774 [MainThread] [INFO] [redis:127.0.0.5:50015] start ok in 0.19 seconds
2014-02-27 19:21:59,775 [MainThread] [NOTICE] add_dst_as_slave
2014-02-27 19:21:59,790 [MainThread] [INFO] [redis:127.0.0.5:50015] /home/ning/idning-github/redis/src/redis-cli -h 127.0.0.5 -p 50015 SLAVEOF 127.0.0.5 22000
OK
2014-02-27 19:21:59,801 [MainThread] [INFO] [redis:127.0.0.5:50015]: {'used_memory': '342432', 'master_link_status': 'down', 'slave_repl_offset': '-1'}
2014-02-27 19:22:00,811 [MainThread] [INFO] [redis:127.0.0.5:50015]: {'used_memory': '342464', 'master_link_status': 'down', 'slave_repl_offset': '-1'}
2014-02-27 19:22:01,820 [MainThread] [INFO] [redis:127.0.0.5:50015]: {'used_memory': '363456', 'master_link_status': 'up', 'slave_repl_offset': '5998625'}
2014-02-27 19:22:01,821 [MainThread] [NOTICE] cleanup
2014-02-27 19:22:02,156 [MainThread] [INFO] [redis:127.0.0.5:23000] stop ok in 0.11 seconds
2014-02-27 19:22:02,156 [MainThread] [NOTICE] sentinel_reset
2014-02-27 19:22:02,165 [MainThread] [NOTICE] update_config
2014-02-27 19:22:02,166 [MainThread] [INFO] AppendConfig:cluster0['migration'] = []
2014-02-27 19:22:02,166 [MainThread] [INFO] AppendConfig:cluster0['migration'].append('cluster0-22000:127.0.0.5:23000:/tmp/r/redis-23000=&amp;gt;cluster0-22000:127.0.0.5:50015:/tmp/r/redis-50015')
&lt;/pre&gt;
&lt;p&gt;它会修改conf.py, 在末尾增加替换信息:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cluster0['migration'] = []
cluster0['migration'].append('cluster0-22000:127.0.0.5:23000:/tmp/r/redis-23000=&amp;gt;cluster0-22000:127.0.0.5:50015:/tmp/r/redis-50015')
&lt;/pre&gt;
&lt;p&gt;当下一次用redis-mgr操作这个集群时, 老的instace信息就会被新instance替代:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/deploy.py cluster0 status
2014-02-27 19:24:24,815 [MainThread] [NOTICE] start running: ./bin/deploy.py -v cluster0 status
2014-02-27 19:24:24,820 [MainThread] [NOTICE] status redis
2014-02-27 19:24:24,825 [MainThread] [INFO] [redis:127.0.0.5:22000] uptime 29815 seconds
2014-02-27 19:24:24,831 [MainThread] [INFO] [redis:127.0.0.5:50015] uptime 145 seconds
...
2014-02-27 19:24:24,893 [MainThread] [NOTICE] status master-slave
cluster0-22000 [redis:127.0.0.5:22000] &amp;lt;- 127.0.0.5:50015
cluster0-22001 [redis:127.0.0.5:22001] &amp;lt;- 127.0.0.5:23001
cluster0-22002 [redis:127.0.0.5:22002] &amp;lt;- 127.0.0.5:23002
cluster0-22003 [redis:127.0.0.5:22003] &amp;lt;- 127.0.0.5:23003
&lt;/pre&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>twemproxy-benchmark</title><link href="/twemproxy-benchmark.html" rel="alternate"></link><updated>2014-02-10T16:04:26+08:00</updated><author><name>ning</name></author><id>tag:,2014-02-10:twemproxy-benchmark.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id5"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id6"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;过程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id7"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id8"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;具体性能分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;问题&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;在我们用 redis-mgr 部署的集群里面, 使用 benchmark测试:&lt;/p&gt;
&lt;p&gt;以比较典型的部署:&lt;/p&gt;
&lt;p&gt;4台机器,&lt;/p&gt;
&lt;p&gt;每台机器2个redis-master, 2个nutcracker:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
'redis': [
    ('m-01:2200', '/home/ning/redis-sandbox2/redis-2200'), ('m-02:3200', '/home/ning/redis-sandbox2/redis-3200'),
    ('m-01:2201', '/home/ning/redis-sandbox2/redis-2201'), ('m-02:3201', '/home/ning/redis-sandbox2/redis-3201'),
    ('m-02:2202', '/home/ning/redis-sandbox2/redis-2202'), ('m-03:3202', '/home/ning/redis-sandbox2/redis-3202'),
    ('m-02:2203', '/home/ning/redis-sandbox2/redis-2203'), ('m-03:3203', '/home/ning/redis-sandbox2/redis-3203'),
    ('m-03:2204', '/home/ning/redis-sandbox2/redis-2204'), ('m-04:3204', '/home/ning/redis-sandbox2/redis-3204'),
    ('m-03:2205', '/home/ning/redis-sandbox2/redis-2205'), ('m-04:3205', '/home/ning/redis-sandbox2/redis-3205'),
    ('m-04:2206', '/home/ning/redis-sandbox2/redis-2206'), ('m-01:3206', '/home/ning/redis-sandbox2/redis-3206'),
    ('m-04:2207', '/home/ning/redis-sandbox2/redis-2207'), ('m-01:3207', '/home/ning/redis-sandbox2/redis-3207'),
],
'nutcracker': [
    ('m-01:4200', '/home/ning/redis-sandbox2/nutcracker-4200'),
    ('m-01:4201', '/home/ning/redis-sandbox2/nutcracker-4201'),
    ('m-02:4200', '/home/ning/redis-sandbox2/nutcracker-4200'),
    ('m-02:4201', '/home/ning/redis-sandbox2/nutcracker-4201'),
    ('m-03:4200', '/home/ning/redis-sandbox2/nutcracker-4200'),
    ('m-03:4201', '/home/ning/redis-sandbox2/nutcracker-4201'),
    ('m-04:4200', '/home/ning/redis-sandbox2/nutcracker-4200'),
    ('m-04:4201', '/home/ning/redis-sandbox2/nutcracker-4201'),
],
&lt;/pre&gt;
&lt;p&gt;使用如下benchmark:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/deploy.py cluster_sandbox2 nbench 1000000
2014-02-10 16:15:52,758 [MainThread] [INFO] start running: ./bin/deploy.py -v cluster_sandbox2 nbench 1000000
2014-02-10 16:15:52,783 [Thread-1] [INFO] ssh -n -f ning&amp;#64;10.65.19.52 &amp;quot;cd /home/ning/redis-sandbox2/redis-2200 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.19.52 -p 4200 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
2014-02-10 16:15:52,799 [Thread-2] [INFO] ssh -n -f ning&amp;#64;10.65.19.26 &amp;quot;cd /home/ning/redis-sandbox2/redis-2202 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.19.52 -p 4201 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
2014-02-10 16:15:52,814 [Thread-3] [INFO] ssh -n -f ning&amp;#64;10.65.19.52 &amp;quot;cd /home/ning/redis-sandbox2/redis-2200 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.19.26 -p 4200 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
2014-02-10 16:15:52,831 [Thread-4] [INFO] ssh -n -f ning&amp;#64;10.65.19.52 &amp;quot;cd /home/ning/redis-sandbox2/redis-2201 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.19.26 -p 4201 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
2014-02-10 16:15:52,843 [Thread-5] [INFO] ssh -n -f ning&amp;#64;10.65.19.52 &amp;quot;cd /home/ning/redis-sandbox2/redis-2201 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.19.27 -p 4200 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
2014-02-10 16:15:52,855 [Thread-6] [INFO] ssh -n -f ning&amp;#64;10.65.19.26 &amp;quot;cd /home/ning/redis-sandbox2/redis-2202 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.19.27 -p 4201 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
2014-02-10 16:15:52,870 [Thread-7] [INFO] ssh -n -f ning&amp;#64;10.65.19.26 &amp;quot;cd /home/ning/redis-sandbox2/redis-2203 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.15.234 -p 4200 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
2014-02-10 16:15:52,887 [Thread-8] [INFO] ssh -n -f ning&amp;#64;10.65.19.52 &amp;quot;cd /home/ning/redis-sandbox2/redis-2201 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.15.234 -p 4201 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
&lt;/pre&gt;
&lt;p&gt;想当于起8个worker, 随机登录到这4台机器上, 用redis-benchmark向随机一个nutcracker 发:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
bin/redis-benchmark --csv -h 10.65.19.52 -p 4200 -r 100000 -t set,get -n 1000000 -c 100
&lt;/pre&gt;
&lt;p&gt;实际效果, 从redis-master 观察到的 qps 如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
_2200  2201  2202  2203  2204  2205  2206  2207
31070 31187 31330 31143 31129 30843 30561 31198 16:10:27
28709 28226 28184 28054 27960 27934 27763 28227 16:10:28
28039 28104 28076 28148 28140 28065 28108 28429 16:10:29
28060 28026 27791 27938 28006 27968 27901 28236 16:10:31
27277 27314 27120 26693 27308 26892 26961 27100 16:10:32
&lt;/pre&gt;
&lt;p&gt;这些redis-benchmark跑完结果如下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Warning: Permanently added '10.65.19.26' (RSA) to the list of known hosts.
&amp;quot;SET&amp;quot;,&amp;quot;32128.51&amp;quot;
&amp;quot;GET&amp;quot;,&amp;quot;32101.70&amp;quot;
Warning: Permanently added '10.65.19.26' (RSA) to the list of known hosts.
&amp;quot;SET&amp;quot;,&amp;quot;28050.49&amp;quot;
&amp;quot;GET&amp;quot;,&amp;quot;37503.75&amp;quot;
&lt;/pre&gt;
&lt;p&gt;此时目标机器上nutcracker进程占cpu 50%左右&lt;/p&gt;
&lt;p&gt;总的来说, 单个redis实例, qps只能到2.5w左右, 并不能发挥全部潜力&lt;/p&gt;
&lt;p&gt;如果直接向redis-master 发benchmark:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./bin/deploy.py cluster_sandbox2 mbench 1000000

_2200  2201  2202  2203  2204  2205  2206  2207
65403 52966 72511 59942 56849 67403 73925 73807 16:14:29
59207 59013 72661 59847 62023 70425 73797 73419 16:14:30
61209 64150 72458 59782 61011 71315 73880 57140 16:14:31
61558 69808 63582 57293 58958 71804 73205 70450 16:14:32
61728 70484 60712 61016 58986 64976 73757 73305 16:14:33

Warning: Permanently added '10.65.19.26' (RSA) to the list of known hosts.
&amp;quot;SET&amp;quot;,&amp;quot;63123.34&amp;quot;
&amp;quot;GET&amp;quot;,&amp;quot;72854.44&amp;quot;
&lt;/pre&gt;
&lt;p&gt;看到每个redis实例的qps约7w/s.&lt;/p&gt;
&lt;p&gt;为什么经过了一个nutcracker, pqs就从 7w下降到2.5w呢?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;2&amp;nbsp;&amp;nbsp;&amp;nbsp;过程&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;试试单个benchmark进程:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssh -n -f ning&amp;#64;10.65.19.52 &amp;quot;cd /home/ning/redis-sandbox2/redis-2200 &amp;amp;&amp;amp; bin/redis-benchmark --csv -h 10.65.19.52 -p 4200 -r 100000 -t set,get -n 1000000 -c 100 &amp;quot;
&amp;quot;SET&amp;quot;,&amp;quot;70185.29&amp;quot;
&amp;quot;GET&amp;quot;,&amp;quot;67449.08&amp;quot;
每个master上的压力大约9k, 总压力能到7w左右
 2200  2201  2202  2203  2204  2205  2206  2207
 9320  9233  9144  9256  9128  9191  9296  9239 16:19:56
&lt;/pre&gt;
&lt;p&gt;能到7w左右, 是没有问题的, 此时目标机器上nutcracker进程占cpu 90%-99%.&lt;/p&gt;
&lt;p&gt;发现问题, 用自己的nbench命令, 是随机选择一个机器作为压力发起的机器, 存在很大的不均匀现象:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssh -n -f ning&amp;#64;10.65.19.52
ssh -n -f ning&amp;#64;10.65.19.52
ssh -n -f ning&amp;#64;10.65.19.52
ssh -n -f ning&amp;#64;10.65.19.52
ssh -n -f ning&amp;#64;10.65.19.52
ssh -n -f ning&amp;#64;10.65.19.26
ssh -n -f ning&amp;#64;10.65.19.26
ssh -n -f ning&amp;#64;10.65.19.26
&lt;/pre&gt;
&lt;p&gt;因为每台机器上有4个redis, 2个proxy, 再开2个benchmark 进程, 就会打满8个核(总共就8个核)&lt;/p&gt;
&lt;p&gt;如果有3个benchmark进程在同一个机器上, 多余的benchmark进程的压力就上不来 (benchmark进程也占87%左右的cpu)&lt;/p&gt;
&lt;p&gt;原来发benchmark的任务实现:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def nbench(self, cnt=100000):
    '''
    run benchmark against nutcracker
    '''
    for s in self.all_nutcracker:
        args = copy.deepcopy(s.args)
        args['cnt'] = cnt
        cmd = TT('bin/redis-benchmark --csv -h $host -p $port -r 100000 -t set,get -n $cnt -c 100 ', args)
        BenchThread(random.choice(self._active_masters()), cmd).start()
&lt;/pre&gt;
&lt;p&gt;修改了一下:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def nbench(self, cnt=100000):
    '''
    run benchmark against nutcracker
    '''
    i = 0
    masters= self._active_masters()
    for s in self.all_nutcracker:
        args = copy.deepcopy(s.args)
        args['cnt'] = cnt
        cmd = TT('bin/redis-benchmark --csv -h $host -p $port -r 100000 -t set,get -n $cnt -c 100 ', args)

        BenchThread(masters[i], cmd).start()
        i += 1
        i %= len(masters)
&lt;/pre&gt;
&lt;p&gt;保证均匀的在各个机器上起benchmark进程, 就能得到很高的qps, 和直连差别已经很小:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
_2200  2201  2202  2203  2204  2205  2206  2207
63227 62220 63270 63240 61574 62673 62855 62078 16:43:34
63889 64202 64157 63754 63181 63986 64152 64234 16:43:35
66386 66852 66858 66445 66835 66672 66700 67084 16:43:36
&lt;/pre&gt;
&lt;p&gt;此时几个核的压力分布:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PID   USER     PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
14903 ning     16   0 18928 1908  708 R 90.4  0.0   6:05.93 nutcracker
14865 ning     16   0 22328 2968  712 R 88.8  0.0  10:53.54 nutcracker
517   ning     16   0 22924 6432  680 S 87.8  0.0   0:09.84 redis-benchmark
519   ning     16   0 22924 6136  680 R 87.1  0.0   0:09.33 redis-benchmark
30753 ning     16   0  118m  82m 1116 S 70.9  0.1  18:31.10 redis-server
10746 ning     16   0  126m  87m 1112 R 70.0  0.1  13:40.51 redis-server
21287 ning     16   0 52196  17m 1132 R 38.6  0.0  12:24.57 redis-server
28560 ning     16   0 55420  17m 1240 R 37.0  0.0  17:27.72 redis-server
&lt;/pre&gt;
&lt;p&gt;可以看出, 满负荷的时候, nutcracker占满cpu, benchmark也很消耗cpu,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;3&amp;nbsp;&amp;nbsp;&amp;nbsp;结论&lt;/a&gt;&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;看到的nutcracker导致集群性能下降, 其实是自己的benchmark方法不合理, 客户端性能受限导致&lt;/li&gt;
&lt;li&gt;如果在cpu很空闲的机器上发benchmark, qps应该更高.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;4&amp;nbsp;&amp;nbsp;&amp;nbsp;具体性能分析&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;火焰图:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy_flame.png" style="width: 600px; height: 145px;" /&gt;
&lt;p&gt;&lt;a class="reference external" href="imgs/twemproxy-flame.svg"&gt;svg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看出:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;程序逻辑:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;event_wait&lt;/li&gt;
&lt;li&gt;msg_recv&lt;/li&gt;
&lt;li&gt;msg_send&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;conn_recv: 18.4% , conn_sendv 36.9% 这基本等于调用系统调用read/write 的时间
总共占 55%. 这一部分时间是不可能被优化的了&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;event_add_out, event_del_out, 下面都是epoll_ctl, 在不同场景下调用, 大约有4种情况,
占用时间18%左右&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;event_wait 占用 &lt;tt class="docutils literal"&gt;2.9%&lt;/tt&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;redis_parse_req &lt;tt class="docutils literal"&gt;2.6%&lt;/tt&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;parse_req, 队列的enqueue, dequeue 操作合起来占5%左右.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;其它&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可优化的空间较小了.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>twemproxy</title><link href="/twemproxy.html" rel="alternate"></link><updated>2014-01-03T17:33:27+08:00</updated><author><name>ning</name></author><id>tag:,2014-01-03:twemproxy.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="auto-toc simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#twemporxy-nutcracker" id="id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Twemporxy(nutcracker) 介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;twemproxy 是一个 redis/memcache 代理. 实现sharding逻辑&lt;/p&gt;
&lt;div class="section" id="twemporxy-nutcracker"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id1"&gt;1&amp;nbsp;&amp;nbsp;&amp;nbsp;Twemporxy(nutcracker) 介绍&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;2012.2月由twitter 开源:&lt;/li&gt;
&lt;li&gt;刚开始是只做 memcached 协议&lt;/li&gt;
&lt;li&gt;主要目标是作为分布式连接池, 减少后端连接.(数千前端, 都要连后端的memcached) =&amp;gt; 几个前端聚合用一个proxy.&lt;/li&gt;
&lt;li&gt;后端长连接&lt;/li&gt;
&lt;li&gt;config by YAML&lt;/li&gt;
&lt;li&gt;Use multiple hashing modes, including consistent hashing&lt;/li&gt;
&lt;li&gt;stats 统计信息.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry><entry><title>twemproxy代码分析</title><link href="/twemproxy-src.html" rel="alternate"></link><updated>2013-12-15T15:12:02+08:00</updated><author><name>ning</name></author><id>tag:,2013-12-15:twemproxy-src.html</id><summary type="html">&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title first"&gt;Table of Contents&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id1" id="id47"&gt;调研&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id48"&gt;文章调研&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-twemproxy-a-redis-proxy-from-twitter" id="id49"&gt;Redis 作者:Twemproxy, a Redis proxy from Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id50"&gt;存储分片和Twemproxy核心解读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-twemproxy-benchmark" id="id51"&gt;redis-twemproxy-benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id52"&gt;这个文章总结不错&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hash" id="id53"&gt;hash函数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id54"&gt;配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#user" id="id55"&gt;user&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id56"&gt;不支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id57"&gt;代码分析&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id58"&gt;模块划分&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#event" id="id59"&gt;event&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id60"&gt;请求处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#main" id="id61"&gt;main&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#os-utils" id="id62"&gt;os utils&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ds-utils" id="id63"&gt;ds utils&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id64"&gt;协议&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id65"&gt;hash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id66"&gt;event 机制&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#epool" id="id67"&gt;epool 实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#event-create" id="id68"&gt;上层对event_create 的使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#event-wait" id="id69"&gt;上层对event_wait的使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#libevent" id="id70"&gt;和libevent 对比&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id71"&gt;重要结构&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#server-poolserver" id="id72"&gt;server_pool和server.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#conn-msg-mbuf" id="id73"&gt;conn, msg, mbuf&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#conn" id="id74"&gt;conn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#msg" id="id75"&gt;msg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mbuf" id="id76"&gt;mbuf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id14" id="id77"&gt;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id15" id="id78"&gt;请求处理&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#core-core" id="id79"&gt;读写总控函数 core_core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#accept" id="id80"&gt;accept连接&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#nc-connection-c" id="id81"&gt;nc_connection.c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#messsage-c" id="id82"&gt;messsage.c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id83"&gt;一个请求被处理的流程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id17" id="id84"&gt;初始状态&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id18" id="id85"&gt;1.读取请求&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id19" id="id86"&gt;2.转发到后端&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id20" id="id87"&gt;3.接收后端响应&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#client" id="id88"&gt;4.把响应回给client&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#buf" id="id89"&gt;buf处理上的特点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id21" id="id90"&gt;后端如何处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id22" id="id91"&gt;协议&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id23" id="id92"&gt;hash&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id24" id="id93"&gt;具体hash函数&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#crc32" id="id94"&gt;crc32&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hsieh" id="id95"&gt;hsieh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#jenkins-lookup3" id="id96"&gt;Jenkins lookup3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#jenkins-one-at-a-time" id="id97"&gt;Jenkins one_at_a_time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fnv-xxx" id="id98"&gt;FNV-XXX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#murmur" id="id99"&gt;murmur&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id25" id="id100"&gt;小结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dispatch" id="id101"&gt;dispatch方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#rbtree" id="id102"&gt;rbtree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mget" id="id103"&gt;如何处理mget&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#nginx" id="id104"&gt;代码严重受nginx影响&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id26" id="id105"&gt;(代码)小结&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id27" id="id106"&gt;注意&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id28" id="id107"&gt;使用&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id29" id="id108"&gt;编译&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#debug" id="id109"&gt;debug级别&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#core" id="id110"&gt;core的问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id30" id="id111"&gt;使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id31" id="id112"&gt;配置参数&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#hashdistribution" id="id113"&gt;hash和distribution见前面分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#auto-eject-hosts" id="id114"&gt;auto_eject_hosts相关&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#timeout" id="id115"&gt;timeout&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#log" id="id116"&gt;log&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mbuf-size" id="id117"&gt;mbuf size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#max-key-lenght" id="id118"&gt;max key lenght&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#server-connections-1" id="id119"&gt;server_connections: &amp;gt; 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id32" id="id120"&gt;监控&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#redis-mgr" id="id121"&gt;使用redis-mgr部署&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id33" id="id122"&gt;日志级别&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id34" id="id123"&gt;修改日志级别:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id35" id="id124"&gt;2.动态调整日志级别:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id36" id="id125"&gt;3.切日志&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id37" id="id126"&gt;自己实现一个自动的主从切换?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#sentinel" id="id127"&gt;sentinel验证&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id38" id="id128"&gt;配置和优化&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#m-512" id="id129"&gt;-m 512&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id39" id="id130"&gt;问题&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#preconnect-true-redis-core" id="id131"&gt;preconnect: true 的时候, 如果后端redis挂掉, 会core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#pipeline-replay" id="id132"&gt;pipeline/replay时消耗大量内存:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mgetcase" id="id133"&gt;mget慢这个case&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id40" id="id134"&gt;应该允许释放mbuf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id41" id="id135"&gt;#一轮完了再集中加事件, 不要多次加, 重复加&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id42" id="id136"&gt;#可能的优化:mget&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id43" id="id137"&gt;改造&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#key" id="id138"&gt;key过长回错误&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id44" id="id139"&gt;社区情况&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id45" id="id140"&gt;小结&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id46" id="id141"&gt;期望&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id47"&gt;调研&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id48"&gt;文章调研&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="redis-twemproxy-a-redis-proxy-from-twitter"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id49"&gt;Redis 作者:Twemproxy, a Redis proxy from Twitter&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="http://antirez.com/news/44"&gt;http://antirez.com/news/44&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;计划中的redis-cluster: Multiple instances is a share-nothing architecture.&lt;/li&gt;
&lt;li&gt;2.6 中实现了Redis Sentinel, 即将实现 partial resynchronization&lt;/li&gt;
&lt;li&gt;Twemproxy 是 single-threaded proxy&lt;/li&gt;
&lt;li&gt;What's awesome about Twemproxy is that it can be configured both to disable nodes on failure, and retry after some time&lt;/li&gt;
&lt;li&gt;失败时, 可以disable 或者 retry
- 作为data store : retry
- 作为cache: disable(node-ejection)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同样的一组后端, 可以配成两种:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
redis1:
  listen: 0.0.0.0:9999
  redis: true
  hash: fnv1a_64
  distribution: ketama
  auto_eject_hosts: true
  timeout: 400
  server_retry_timeout: 2000
  server_failure_limit: 1
  servers:
   - 127.0.0.1:6379:1
   - 127.0.0.1:6380:1
   - 127.0.0.1:6381:1
   - 127.0.0.1:6382:1

redis2:
  listen: 0.0.0.0:10000
  redis: true
  hash: fnv1a_64
  distribution: ketama
  auto_eject_hosts: false
  timeout: 400
  servers:
   - 127.0.0.1:6379:1
   - 127.0.0.1:6380:1
   - 127.0.0.1:6381:1
   - 127.0.0.1:6382:1
&lt;/pre&gt;
&lt;p&gt;限制:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;不支持 mset, transaction:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
I think that twemproxy do it right, not supporting multiple keys commands nor transactions. Currently is AFAIK even more strict than Redis Cluster that instead allows MULTI/EXEC blocks if all the commands are about the same key.
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;对mget, mdel 支持, 性能待测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
However there is some support for commands with multiple keys. MGET and DEL are handled correctly. Interestingly MGET will split the request among different servers and will return the reply as a single entity. This is pretty cool even if I don't get the right performance numbers with this feature (see later).

So I expected to see almost the same numbers with an MGET as I see when I run the MGET against a single instance
but I get only 50% of the operations per second. Maybe it's the time to reconstruct the reply, I'm not sure.

mget 只有50%
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;不支持EVAL,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;错误处理: (antirez 测试还挺认真)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;non supported command: closes the connection.&lt;/li&gt;
&lt;li&gt;sending just a &amp;quot;GET&amp;quot;: hang&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;希望: 支持HA&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;能直接做主从切换.&lt;/li&gt;
&lt;li&gt;配置热加载也可以啊~ (checking the Sentinel configuration regularly to upgrade the servers table if a failover happened.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;性能: 好!!!&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;This Thing Is Fast. Really fast, it is almost as fast as talking directly with Redis. I would say you lose 20% of performances at worst.&lt;/li&gt;
&lt;li&gt;MGET可以优化 (目前性能降低50%)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结论:
- I strongly suggest Redis users to give it a try.&lt;/p&gt;
&lt;p&gt;人们的讨论:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;对于MGET: The response time will then be &lt;em&gt;at least&lt;/em&gt; as slow as the slowest node&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id50"&gt;存储分片和Twemproxy核心解读&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.wzxue.com/%E5%AD%98%E5%82%A8%E5%88%86%E7%89%87%E5%92%8Ctwemproxy%E6%A0%B8%E5%BF%83%E8%A7%A3%E8%AF%BB/"&gt;http://www.wzxue.com/%E5%AD%98%E5%82%A8%E5%88%86%E7%89%87%E5%92%8Ctwemproxy%E6%A0%B8%E5%BF%83%E8%A7%A3%E8%AF%BB/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;antirez(Redis作者)写过一篇对twemproxy的介绍http://antirez.com/news/44, 他认为twemproxy是目前Redis 分片管理的最好方案，虽然antirez的Redis cluster正在实现并且对其给予厚望&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;涉及到三个重要的结构:server, connection, message。&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;每个server其实就是一个后端的缓存服务程序&lt;/li&gt;
&lt;li&gt;connection在Twemproxy中非常重要，它分为三种类型的connection:proxy，client和server&lt;/li&gt;
&lt;li&gt;struct msg是连接建立后的消息内容发送载体，这个复杂的msg结构很大程度是因为需要实现pipeline的效果，多个msg属于同一个conn，conn通过接收到内容解析来发现几个不同的msg。&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Twemproxy的架构比较清晰，对Twemproxy源码印象较深的是对logging的合理布局和错误处理的清晰，这是第一次看大公司开源出来的代码，非常重视logging和错误处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;我的fork: 由于Twitter开源的Twemproxy直接使用epoll驱动，导致其他不支持epoll的系统无法使用，因此我fork了一个版本，加入了kqueue支持，让FreeBSD和Mac os x能够成功编译运行&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这位同学2013.10 还是一个大四学生.
github 上人气挺高: &lt;a class="reference external" href="https://github.com/yuyuyu101"&gt;https://github.com/yuyuyu101&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-twemproxy-benchmark"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id51"&gt;redis-twemproxy-benchmark&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="http://blog.jpush.cn/redis-twemproxy-benchmark/"&gt;http://blog.jpush.cn/redis-twemproxy-benchmark/&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;twemproxy 可以开http监控端口: &lt;a class="reference external" href="http://ip:22222"&gt;http://ip:22222&lt;/a&gt; json格式&lt;/li&gt;
&lt;li&gt;性能基本和单台一样.&lt;/li&gt;
&lt;li&gt;多个twemproxy 实例, 性能可以更好.&lt;/li&gt;
&lt;li&gt;不支持除mget，del之外的redis批处理命令，如取多个集合交集等等&lt;/li&gt;
&lt;li&gt;不支持脚本eval&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id52"&gt;这个文章总结不错&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="http://cloudaice.com/twemproxy-explore/"&gt;http://cloudaice.com/twemproxy-explore/&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;redis-proxy&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;使用node写的redis代理层。&lt;/li&gt;
&lt;li&gt;支持主从节点的失败处理（可以仔细研究）&lt;/li&gt;
&lt;li&gt;测试后发现性能为原生的1/3&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;twemproxy&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;p class="first"&gt;支持失败节点自动删除&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;可以设置重新连接该节点的时间&lt;/li&gt;
&lt;li&gt;可以设置连接多少次之后删除该节点&lt;/li&gt;
&lt;li&gt;该方式适合作为cache存储&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持设置HashTag&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;通过HashTag可以自己设定将两个KEYhash到同一个实例上去。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;减少与redis的直接连接数&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;保持与redis的长连接&lt;/li&gt;
&lt;li&gt;可设置代理与后台每个redis连接的数目&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;自动分片到后端多个redis实例上&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;多种hash算法（部分还没有研究明白)&lt;/li&gt;
&lt;li&gt;可以设置后端实例的权重&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;避免单点问题&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;可以平行部署多个代理层.client自动选择可用的一个&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持redis pipelining request&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持状态监控&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;可设置状态监控ip和端口，访问ip和端口可以得到一个json格式的状态信息串&lt;/li&gt;
&lt;li&gt;可设置监控信息刷新间隔时间&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;高吞吐量&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;连接复用，内存复用。&lt;/li&gt;
&lt;li&gt;将多个连接请求，组成reids pipelining统一向redis请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;配置部署建议: 编译时候打开logging模块。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="hash"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id53"&gt;hash函数&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;hash:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;one_at_a_time&lt;/li&gt;
&lt;li&gt;md5&lt;/li&gt;
&lt;li&gt;crc16&lt;/li&gt;
&lt;li&gt;crc32 (crc32 implementation compatible with libmemcached)&lt;/li&gt;
&lt;li&gt;crc32a (correct crc32 implementation as per the spec)&lt;/li&gt;
&lt;li&gt;fnv1_64&lt;/li&gt;
&lt;li&gt;fnv1a_64&lt;/li&gt;
&lt;li&gt;fnv1_32&lt;/li&gt;
&lt;li&gt;fnv1a_32&lt;/li&gt;
&lt;li&gt;hsieh&lt;/li&gt;
&lt;li&gt;murmur&lt;/li&gt;
&lt;li&gt;jenkins&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id54"&gt;配置&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
delta:
  listen: 127.0.0.1:22124
  hash: fnv1a_64
  distribution: ketama
  timeout: 100
  auto_eject_hosts: true
  server_retry_timeout: 2000
  server_failure_limit: 1
  servers:
   - 127.0.0.1:11214:1
   - 127.0.0.1:11215:1
   - 127.0.0.1:11216:1
   - 127.0.0.1:11217:1
   - 127.0.0.1:11218:1
   - 127.0.0.1:11219:1
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="user"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id55"&gt;user&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Twitter&lt;/li&gt;
&lt;li&gt;Pinterest&lt;/li&gt;
&lt;li&gt;Tumblr&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id56"&gt;不支持&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;auth&lt;/li&gt;
&lt;li&gt;mset&lt;/li&gt;
&lt;li&gt;eval&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id57"&gt;代码分析&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id58"&gt;模块划分&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;核心是 &lt;tt class="docutils literal"&gt;event&lt;/tt&gt; , &lt;tt class="docutils literal"&gt;请求处理&lt;/tt&gt; 这两块&lt;/p&gt;
&lt;div class="section" id="event"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id59"&gt;event&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
./event
./event/Makefile.am
./event/nc_epoll.c
./event/nc_event.h
./event/nc_evport.c
./event/nc_kqueue.c
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id60"&gt;请求处理&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
./nc_proxy.c
./nc_proxy.h

./nc_connection.c
./nc_connection.h
./nc_client.c
./nc_client.h
./nc_server.c
./nc_server.h

./nc_message.c
./nc_message.h
./nc_request.c
./nc_response.c

./nc_mbuf.c
./nc_mbuf.h
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="main"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id61"&gt;main&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;./nc.c, 处理daemon, pidfile, args, config, 最后:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nc_run(struct instance *nci)
{
    ctx = core_start(nci);
    for (;;) {
        status = core_loop(ctx);
        if (status != NC_OK) {
            break;
        }
    }
    core_stop(ctx);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="os-utils"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id62"&gt;os utils&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
./nc_conf.c
./nc_conf.h
./nc_core.c
./nc_core.h
./nc_log.c
./nc_log.h
./nc_signal.c
./nc_signal.h
./nc_stats.c
./nc_stats.h
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="ds-utils"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id63"&gt;ds utils&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
./nc_array.c
./nc_array.h
./nc_util.c
./nc_util.h
./nc_queue.h
./nc_rbtree.c
./nc_rbtree.h
./nc_string.c
./nc_string.h
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id64"&gt;协议&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
./proto/nc_proto.h
./proto/nc_memcache.c
./proto/nc_redis.c
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id65"&gt;hash&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
./hashkit/nc_crc16.c
./hashkit/nc_crc32.c
./hashkit/nc_fnv.c
./hashkit/nc_hashkit.h
./hashkit/nc_hsieh.c
./hashkit/nc_jenkins.c
./hashkit/nc_ketama.c
./hashkit/nc_md5.c
./hashkit/nc_modula.c
./hashkit/nc_murmur.c
./hashkit/nc_one_at_a_time.c
./hashkit/nc_random.c
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id66"&gt;event 机制&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
struct event_base {
    int                ep;      /* epoll descriptor */
    struct epoll_event *event;  /* event[] - events that were triggered */
    int                nevent;  /* # event */
    event_cb_t         cb;      /* event callback */
};


struct event_base *event_base_create(int size, event_cb_t cb);
void event_base_destroy(struct event_base *evb);

int event_add_in(struct event_base *evb, struct conn *c);
int event_del_in(struct event_base *evb, struct conn *c);
int event_add_out(struct event_base *evb, struct conn *c);
int event_del_out(struct event_base *evb, struct conn *c);
int event_add_conn(struct event_base *evb, struct conn *c);
int event_del_conn(struct event_base *evb, struct conn *c);
int event_wait(struct event_base *evb, int timeout);
void event_loop_stats(event_stats_cb_t cb, void *arg);
&lt;/pre&gt;
&lt;div class="section" id="epool"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id67"&gt;epool 实现&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;event_base_create:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct event_base *
event_base_create(int nevent, event_cb_t cb)
{
    struct event_base *evb = nc_alloc(sizeof(*evb));
    int ep = epoll_create(nevent);
    struct epoll_event *event = nc_calloc(nevent, sizeof(*event));

    evb-&amp;gt;ep = ep;
    evb-&amp;gt;event = event;
    evb-&amp;gt;nevent = nevent;
    evb-&amp;gt;cb = cb;

    return evb;
}

int
event_add_in(struct event_base *evb, struct conn *c)
{
    struct epoll_event event;
    event.events = (uint32_t)(EPOLLIN | EPOLLET);
    event.data.ptr = c;

    status = epoll_ctl(evb-&amp;gt;ep, EPOLL_CTL_MOD, c-&amp;gt;sd, &amp;amp;event);
}

int
event_wait(struct event_base *evb, int timeout)
{
    int ep = evb-&amp;gt;ep;
    struct epoll_event *event = evb-&amp;gt;event;
    int nevent = evb-&amp;gt;nevent;

    for (;;) {
        int i, nsd;

        nsd = epoll_wait(ep, event, nevent, timeout);
        if (nsd &amp;gt; 0) {
            for (i = 0; i &amp;lt; nsd; i++) {
                struct epoll_event *ev = &amp;amp;evb-&amp;gt;event[i];
                uint32_t events = 0;

                log_debug(LOG_VVERB, &amp;quot;epoll %04&amp;quot;PRIX32&amp;quot; triggered on conn %p&amp;quot;,
                          ev-&amp;gt;events, ev-&amp;gt;data.ptr);

                if (ev-&amp;gt;events &amp;amp; EPOLLERR) {
                    events |= EVENT_ERR;
                }

                if (ev-&amp;gt;events &amp;amp; (EPOLLIN | EPOLLHUP)) {
                    events |= EVENT_READ;
                }

                if (ev-&amp;gt;events &amp;amp; EPOLLOUT) {
                    events |= EVENT_WRITE;
                }

                if (evb-&amp;gt;cb != NULL) {
                    evb-&amp;gt;cb(ev-&amp;gt;data.ptr, events);
                }
            }
            return nsd;
        }
    }
}
&lt;/pre&gt;
&lt;p&gt;每次调用event_wait, 如果没有事件则一直等, 如果有事件, 调用回调，并返回.&lt;/p&gt;
&lt;p&gt;注意: 这里用的都是边缘触发 EPOLLET (redis本身用的是水平触发)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="event-create"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id68"&gt;上层对event_create 的使用&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
core_ctx_create(){
    /* initialize server pool from configuration */  pool 是一种隔离单位
    status = server_pool_init(&amp;amp;ctx-&amp;gt;pool, &amp;amp;ctx-&amp;gt;cf-&amp;gt;pool, ctx);

    ctx-&amp;gt;evb = event_base_create(EVENT_SIZE, &amp;amp;core_core); //这里有个EVENT_SIZE 是1024, core_core 是一个基础回调, 处理读写.
    status = server_pool_preconnect(ctx);
    status = proxy_init(ctx);
}
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
ctx-&amp;gt;evb = event_base_create(EVENT_SIZE, &amp;amp;core_core); //这里有个EVENT_SIZE 是1024, 在epool里面没用, 设置的回调 core_core 是一个基础回调, 处理读写.
&lt;/pre&gt;
&lt;p&gt;event_add_in里面, &lt;tt class="docutils literal"&gt;data.ptr&lt;/tt&gt; 是一个conn数据结构,&lt;/p&gt;
&lt;p&gt;所以，有事件的时候, 调用  &lt;tt class="docutils literal"&gt;core_core(conn, events)&lt;/tt&gt;, 这里events 说明是读还是写事件.&lt;/p&gt;
&lt;p&gt;接下来的 &lt;tt class="docutils literal"&gt;proxy_init&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
proxy_each_init(void *elem, void *data) {
    struct server_pool *pool = elem;
    struct conn *p;

    p = conn_get_proxy(pool); //获得一个proxy类型的 conn, 它的回调设置: conn-&amp;gt;recv = proxy_recv;
    status = proxy_listen(pool-&amp;gt;ctx, p); //做bind/listen/set noblocking/加到epool
}
&lt;/pre&gt;
&lt;p&gt;这里设置的回调 proxy_recv, 就是做accept, 建立与客户端的连接:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
proxy_recv(struct context *ctx, struct conn *conn)
{
    conn-&amp;gt;recv_ready = 1;
    do {
        status = proxy_accept(ctx, conn);
        if (status != NC_OK) {
            return status;
        }
    } while (conn-&amp;gt;recv_ready);
    return NC_OK;
}
&lt;/pre&gt;
&lt;p&gt;用proxy_accept 与客户端建立连接, 获得client 类型的conn, 并且加入到事件队列:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static rstatus_t
proxy_accept(struct context *ctx, struct conn *p) {
    rstatus_t status;
    struct conn *c;
    int sd;

    for (;;) {//死循环去做. 不带sleep!!
        sd = accept(p-&amp;gt;sd, NULL, NULL);
        if (sd &amp;lt; 0) {
            ...
            return NC_ERROR;
        }
        break;
    }

    c = conn_get(p-&amp;gt;owner, true, p-&amp;gt;redis); //获得一个client类型的连接
    c-&amp;gt;sd = sd;

    status = nc_set_nonblocking(c-&amp;gt;sd);
    status = event_add_conn(ctx-&amp;gt;evb, c);

    return NC_OK;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="event-wait"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id69"&gt;上层对event_wait的使用&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
core_loop(struct context *ctx)
{
    nsd = event_wait(ctx-&amp;gt;evb, ctx-&amp;gt;timeout);
    ...
}
&lt;/pre&gt;
&lt;p&gt;超清晰的主循环:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void
nc_run(struct instance *nci)
{
    rstatus_t status;
    struct context *ctx;

    ctx = core_start(nci);
    if (ctx == NULL) {
        return;
    }

    /* run rabbit run */
    for (;;) {
        status = core_loop(ctx);
        if (status != NC_OK) {
            break;
        }
    }

    core_stop(ctx);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="libevent"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id70"&gt;和libevent 对比&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;从数据结构, 函数命令来看, 受到libevnet和nginx的强烈影响.&lt;/p&gt;
&lt;p&gt;(redis是自己的事件框架, memcached 就是用libevent作为事件框架)&lt;/p&gt;
&lt;p&gt;libevent 的结构大概是这样的(不准确)&lt;/p&gt;
&lt;p&gt;event, 类似连接的概念:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct event {
    TAILQ_ENTRY (event) ev_next;
    TAILQ_ENTRY (event) ev_active_next;
    TAILQ_ENTRY (event) ev_signal_next;
    unsigned int min_heap_idx;  /* for managing timeouts */

    struct event_base *ev_base;

    int ev_fd;
    short ev_events;
&lt;/pre&gt;
&lt;p&gt;event_base是暴露给外面的统一接口:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct event_base {
    const struct eventop *evsel;
    void *evbase;
    int event_count;        /* counts number of total events */
    int event_count_active; /* counts number of active events */
    ...
}
&lt;/pre&gt;
&lt;p&gt;用法:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
//获得listen_fd
listen_fd = network_server_socket(cfg-&amp;gt;listen_host, cfg-&amp;gt;listen_port);

struct event *ev_accept;
ev_accept = event_new(g_server.event_base, listen_fd, EV_READ | EV_PERSIST, on_accept, NULL);
event_add(ev_accept, NULL);
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id13"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id71"&gt;重要结构&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="server-poolserver"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id72"&gt;server_pool和server.&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;在 &lt;tt class="docutils literal"&gt;server_pool.h&lt;/tt&gt; 中注释写的非常清楚, 还有示意图:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
*  +-------------+
*  |             |&amp;lt;---------------------+
*  |             |&amp;lt;------------+        |
*  |             |     +-------+--+-----+----+--------------+
*  |   pool 0    |+---&amp;gt;|          |          |              |
*  |             |     | server 0 | server 1 | ...     ...  |
*  |             |     |          |          |              |--+
*  |             |     +----------+----------+--------------+  |
*  +-------------+                                             //
*  |             |
*  |             |
*  |             |
*  |   pool 1    |
*  |             |
*  |             |
*  |             |
*  +-------------+
*  |             |
*  |             |
*  .             .
*  .    ...      .
*  .             .
*  |             |
*  |             |
*  +-------------+
*            |
*            |
*            //
&lt;/pre&gt;
&lt;p&gt;看看twemproxy的配置:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
s1:
  listen: 127.0.0.1:22124
  servers:
   - 127.0.0.1:11214:1
   - 127.0.0.1:11215:1
   - 127.0.0.1:11216:1
   - 127.0.0.1:11217:1
s2:
  listen: 127.0.0.1:22125
   - 127.0.0.1:11218:1
   - 127.0.0.1:11219:1
&lt;/pre&gt;
&lt;p&gt;这样的配置就对应着类似这样的结构:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-server_pool.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="conn-msg-mbuf"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id73"&gt;conn, msg, mbuf&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="conn"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id74"&gt;conn&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;前面event机制提供的事件注册接口, 注册的事件都是在conn上的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int event_add_in(struct event_base *evb, struct conn *c);
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
struct conn {
    TAILQ_ENTRY(conn)  conn_tqe;      /* link in server_pool / server / free q */
    void               *owner;        /* connection owner - server_pool / server */
                                     //对于client和proxy, conn-&amp;gt;owner 是server_pool 对象
                                     //对于server, conn-&amp;gt;owner 是一个server 对象
    ..
    struct msg_tqh     imsg_q;        /* incoming request Q */
    struct msg_tqh     omsg_q;        /* outstanding request Q */

    conn_recv_t        recv;          /* recv (read) handler */
    conn_recv_next_t   recv_next;     /* recv next message handler */
    conn_recv_done_t   recv_done;     /* read done handler */
    conn_send_t        send;          /* send (write) handler */
    conn_send_next_t   send_next;     /* write next message handler */
    conn_send_done_t   send_done;     /* write done handler */
    conn_close_t       close;         /* close handler */
    conn_active_t      active;        /* active? handler */
    ...
};
&lt;/pre&gt;
&lt;p&gt;conn有三种:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;proxy : 代表proxy监听的端口&lt;/li&gt;
&lt;li&gt;client: 代表一个client连接.&lt;/li&gt;
&lt;li&gt;server: 代表一个后端连接&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;三种conn的获取方式和事件处理钩子不一样:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;listen&lt;/strong&gt;: 通过 &lt;tt class="docutils literal"&gt;conn_get_proxy(void *owner)&lt;/tt&gt; 获取, 只指定了这几个函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
conn-&amp;gt;recv = proxy_recv;
conn-&amp;gt;close = proxy_close;
conn-&amp;gt;ref = proxy_ref;
conn-&amp;gt;unref = proxy_unref;
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;client&lt;/strong&gt;: 通过 &lt;tt class="docutils literal"&gt;conn_get(void *owner, bool client=true, bool redis)&lt;/tt&gt; 获取:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
conn-&amp;gt;recv = msg_recv;
conn-&amp;gt;recv_next = req_recv_next;    //分配下一个读缓冲区.
conn-&amp;gt;recv_done = req_recv_done;

conn-&amp;gt;send = msg_send;
conn-&amp;gt;send_next = rsp_send_next;
conn-&amp;gt;send_done = rsp_send_done;
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;server&lt;/strong&gt;: , 通过 &lt;tt class="docutils literal"&gt;conn_get(void *owner, bool client=false, bool redis)&lt;/tt&gt; 获取:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
conn-&amp;gt;recv = msg_recv;
conn-&amp;gt;recv_next = rsp_recv_next;
conn-&amp;gt;recv_done = rsp_recv_done;

conn-&amp;gt;send = msg_send;
conn-&amp;gt;send_next = req_send_next;
conn-&amp;gt;send_done = req_send_done;
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="msg"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id75"&gt;msg&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;msg代表一个请求体, 或者一个response, 对于mget之类, 它还会代表原request解析后的一个子request:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct msg {
    TAILQ_ENTRY(msg)     c_tqe;           /* link in client q */
    TAILQ_ENTRY(msg)     s_tqe;           /* link in server q */
    TAILQ_ENTRY(msg)     m_tqe;           /* link in send q / free q */

    uint64_t             id;              /* message id */
    struct msg           *peer;           /* message peer */
    struct conn          *owner;          /* message owner - client | server */

    struct rbnode        tmo_rbe;         /* entry in rbtree */

    struct mhdr          mhdr;            /* message mbuf header */
    uint32_t             mlen;            /* message length */
    ...
};
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="mbuf"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id76"&gt;mbuf&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;msg中用来保存请求/响应 内容的链表, 每个mbuf大小默认是16K, 可以配置, 范围在 &lt;tt class="docutils literal"&gt;512B - 64K&lt;/tt&gt; 之间&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id14"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id77"&gt;小结&lt;/a&gt;&lt;/h5&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;server_pool里面保存该pool上面所有client_conn的链表,&lt;/li&gt;
&lt;li&gt;server里面保存该server上所有server_conn的链表.&lt;/li&gt;
&lt;li&gt;conn里面的msg会分为in_q, 和out_q 两个msg链表&lt;/li&gt;
&lt;li&gt;每个msg会同时存在与一个client_conn的out_q 和server_conn的in_q里面&lt;/li&gt;
&lt;li&gt;msg中消息保存在mbuf链表中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;conn和msg的结构:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-conn-msg-struct.png" /&gt;
&lt;p&gt;他们的关系:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-conn-msg.png" /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id15"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id78"&gt;请求处理&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
./nc_connection.h
./nc_connection.c       //三种连接类型, 对象池处理(conn_get, conn_put), 底层读写(conn_recv, conn_sendv)

./nc_proxy.h
./nc_proxy.c            //建立listen socket(proxy_init), 对新连接做accetp (proxy_recv)

./nc_client.h
./nc_client.c           //判断是否有东西要写给client

./nc_server.h
./nc_server.c           //server, server_pool, 连接后端(server_connect), 后端的连接管理(server_pool_conn)

./nc_message.h
./nc_message.c          //msg 结构.

./nc_request.c
./nc_response.c         //对应的forward, filter 函数

./nc_mbuf.h
./nc_mbuf.c             //msg使用的buf.
&lt;/pre&gt;
&lt;div class="section" id="core-core"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id79"&gt;读写总控函数 core_core&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
core_core(void *arg, uint32_t events)
{
    conn-&amp;gt;events = events;
    if (events &amp;amp; EVENT_ERR) {
        core_error(ctx, conn);
        return NC_ERROR;
    }

    /* read takes precedence over write */
    if (events &amp;amp; EVENT_READ) {
        status = core_recv(ctx, conn); // //简单直接调用 conn-&amp;gt;recv
    }
    if (events &amp;amp; EVENT_WRITE) {
        status = core_send(ctx, conn); // //简单直接调用 conn-&amp;gt;send
    }

    return NC_OK;
}
&lt;/pre&gt;
&lt;p&gt;核心就是 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;recv&lt;/span&gt;&lt;/tt&gt; , &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;send&lt;/span&gt;&lt;/tt&gt;, 以及它们的变化.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="accept"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id80"&gt;accept连接&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;前面讲到proxy_init通过:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
p = conn_get_proxy(pool); 获得一个proxy类型的 conn, 它的回调设置: conn-&amp;gt;recv = proxy_recv;
&lt;/pre&gt;
&lt;p&gt;在 proxy_accept 中 accetp到一个连接后, 又通过:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
c = conn_get(p-&amp;gt;owner, true, p-&amp;gt;redis);
&lt;/pre&gt;
&lt;p&gt;获得一个client类型的conn, 这里会把conn-&amp;gt;recv设置为 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;conn-&amp;gt;recv&lt;/span&gt; = msg_recv&lt;/tt&gt;, 有数据发来时，就会调用 msg_recv&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nc-connection-c"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id81"&gt;nc_connection.c&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;很赞的注释:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
*                   nc_connection.[ch]
*                Connection (struct conn)
*                 +         +          +
*                 |         |          |
*                 |       Proxy        |
*                 |     nc_proxy.[ch]  |
*                 /                    \
*              Client                Server
*           nc_client.[ch]         nc_server.[ch]
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="messsage-c"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id82"&gt;messsage.c&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
*            nc_message.[ch]
*        _message (struct msg)
*            +        +            .
*            |        |            .
*            /        \            .
*         Request    Response      .../ nc_mbuf.[ch]  (mesage buffers)
*      nc_request.c  nc_response.c .../ nc_memcache.c; nc_redis.c (_message parser)

* Messages in nutcracker are manipulated by a chain of processing handlers,
* where each handler is responsible for taking the input and producing an
* output for the next handler in the chain. This mechanism of processing
* loosely conforms to the standard chain-of-responsibility design pattern

*             Client+             Proxy           Server+
*                              (nutcracker)
*                                   .
*       msg_recv {read event}       .       msg_recv {read event}
*         +                         .                         +
*         |                         .                         |
*         \                         .                         /
*         req_recv_next             .             rsp_recv_next
*           +                       .                       +
*           |                       .                       |       Rsp
*           req_recv_done           .           rsp_recv_done      &amp;lt;===
*             +                     .                     +
*             |                     .                     |
*    Req      \                     .                     /
*    ===&amp;gt;     req_filter*           .           *rsp_filter
*               +                   .                   +
*               |                   .                   |
*               \                   .                   /
*               req_forward-//  (1) . (3)  \\-rsp_forward
*                                   .
*                                   .
*       msg_send {write event}      .      msg_send {write event}
*         +                         .                         +
*         |                         .                         |
*    Rsp' \                         .                         /     Req'
*   &amp;lt;===  rsp_send_next             .             req_send_next     ===&amp;gt;
*           +                       .                       +
*           |                       .                       |
*           \                       .                       /
*           rsp_send_done-//    (4) . (2)    //-req_send_done
*
*
* (1) -&amp;gt; (2) -&amp;gt; (3) -&amp;gt; (4) is the normal flow of transaction consisting
* of a single request response, where (1) and (2) handle request from
* client, while (3) and (4) handle the corresponding response from the
* server.
&lt;/pre&gt;
&lt;p&gt;好有爱的注释!!&lt;/p&gt;
&lt;p&gt;对应这段注释的代码:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct conn *
conn_get(void *owner, bool client, bool redis)
{
    struct conn *conn;

    conn = _conn_get();

    conn-&amp;gt;client = client ? 1 : 0;

    if (conn-&amp;gt;client) {
        /*
         * client receives a request, possibly parsing it, and sends a
         * response downstream.
         */
        conn-&amp;gt;recv = msg_recv;
        conn-&amp;gt;recv_next = req_recv_next;
        conn-&amp;gt;recv_done = req_recv_done;

        conn-&amp;gt;send = msg_send;
        conn-&amp;gt;send_next = rsp_send_next;
        conn-&amp;gt;send_done = rsp_send_done;

        conn-&amp;gt;close = client_close;
        conn-&amp;gt;active = client_active;

        conn-&amp;gt;ref = client_ref;
        conn-&amp;gt;unref = client_unref;

        conn-&amp;gt;enqueue_inq = NULL;
        conn-&amp;gt;dequeue_inq = NULL;
        conn-&amp;gt;enqueue_outq = req_client_enqueue_omsgq;
        conn-&amp;gt;dequeue_outq = req_client_dequeue_omsgq;
    } else {
        /*
         * server receives a response, possibly parsing it, and sends a
         * request upstream.
         */
        conn-&amp;gt;recv = msg_recv;
        conn-&amp;gt;recv_next = rsp_recv_next;
        conn-&amp;gt;recv_done = rsp_recv_done;

        conn-&amp;gt;send = msg_send;
        conn-&amp;gt;send_next = req_send_next;
        conn-&amp;gt;send_done = req_send_done;

        conn-&amp;gt;close = server_close;
        conn-&amp;gt;active = server_active;

        conn-&amp;gt;ref = server_ref;
        conn-&amp;gt;unref = server_unref;

        conn-&amp;gt;enqueue_inq = req_server_enqueue_imsgq;
        conn-&amp;gt;dequeue_inq = req_server_dequeue_imsgq;
        conn-&amp;gt;enqueue_outq = req_server_enqueue_omsgq;
        conn-&amp;gt;dequeue_outq = req_server_dequeue_omsgq;
    }

    conn-&amp;gt;ref(conn, owner);

    return conn;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id83"&gt;一个请求被处理的流程&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;我们按照 messsage.c 里面的4个步骤&lt;/p&gt;
&lt;p&gt;后面的图都采用这样的表示方法:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-step-desc.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id17"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id84"&gt;初始状态&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;考察只有一个后端的情况, 假设有2个client要发送3个请求过来&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-state-0.png" /&gt;
&lt;div class="section" id="id18"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id85"&gt;1.读取请求&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;此时回调函数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
conn-&amp;gt;recv = msg_recv;
conn-&amp;gt;recv_next = req_recv_next;
conn-&amp;gt;recv_done = req_recv_done;
&lt;/pre&gt;
&lt;p&gt;函数调用栈:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-step-1.png" /&gt;
&lt;p&gt;每次发生 &lt;tt class="docutils literal"&gt;req_recv_done(req_forward)&lt;/tt&gt;, 就会调用 &lt;tt class="docutils literal"&gt;req_forward()&lt;/tt&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
req_forward(struct context *ctx, struct conn *c_conn, struct msg *msg)
{
    if (!msg-&amp;gt;noreply) {
        c_conn-&amp;gt;enqueue_outq(ctx, c_conn, msg);
    }

    //获得到后端的连接. (可能是新建, 或者从pool里面获取)
    s_conn = server_pool_conn(ctx, c_conn-&amp;gt;owner, key, keylen);

    s_conn-&amp;gt;enqueue_inq(ctx, s_conn, msg);
    event_add_out(ctx-&amp;gt;evb, s_conn);
}
&lt;/pre&gt;
&lt;p&gt;就有一个msg就出现在client_conn-&amp;gt;out_q, 同时出现在server_conn-&amp;gt;in_q&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-state-1.png" /&gt;
&lt;p&gt;req_forward用server_pool_conn获得一个server_conn.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id19"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id86"&gt;2.转发到后端&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;对于server_conn来说, 因为挂了epoll_out事件, 很快就会调用 conn-&amp;gt;send，也就是msg_send.&lt;/p&gt;
&lt;p&gt;此时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
conn-&amp;gt;send = msg_send;
conn-&amp;gt;send_next = req_send_next;
conn-&amp;gt;send_done = req_send_done;
&lt;/pre&gt;
&lt;p&gt;调用栈:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-step-2.png" /&gt;
&lt;p&gt;#这时, 每次发生 req_send_done, 这个msg就被放到server_conn-&amp;gt;out_q&lt;/p&gt;
&lt;p&gt;注意,  此时两个msg依然在client_conn-&amp;gt;in_q里面&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-state-2.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="id20"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id87"&gt;3.接收后端响应&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;因为server_conn的 epoll_in是一直开着的, 响应很快回来后, 就到了server_conn的 msg_recv
这个过程和调用栈1类似,不过两个函数钩子不一样(图中灰色框)&lt;/p&gt;
&lt;pre class="literal-block"&gt;
conn-&amp;gt;recv = msg_recv;(和&amp;lt;1&amp;gt;一样)
conn-&amp;gt;recv_next = rsp_recv_next;
conn-&amp;gt;recv_done = rsp_recv_done;
&lt;/pre&gt;
&lt;img alt="" src="/imgs/twemproxy-step-3.png" /&gt;
&lt;p&gt;这里 &lt;tt class="docutils literal"&gt;rsp_recv_next&lt;/tt&gt; 的作用是, 拿到下一个要接收的msg&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;rsp_forward&lt;/tt&gt; 会把 msg从 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;server_conn-&amp;gt;outq&lt;/span&gt;&lt;/tt&gt; 里面摘掉, 同时设置req和resp之间的一一对应关系&lt;/p&gt;
&lt;pre class="literal-block"&gt;
//establish msg &amp;lt;-&amp;gt; pmsg (response &amp;lt;-&amp;gt; request) link
pmsg-&amp;gt;peer = msg;
msg-&amp;gt;peer = pmsg;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;上面这个代码是整个过程的精华所在&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这时候, client的q_out上排队的req, 就有了对应的response&lt;/p&gt;
&lt;p&gt;这时也会设置:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
event_add_out(ctx-&amp;gt;evb, c_conn);
&lt;/pre&gt;
&lt;p&gt;每收到一个rsp, 就从server_conn的out_q摘掉, 并设置一一对应关系, 如下:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-state-3.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="client"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id88"&gt;4.把响应回给client&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;现在每个请求的msg都有了一个对应的response msg, client_conn的out事件也挂上了, 下面这个调用栈:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-step-4.png" /&gt;
&lt;p&gt;最终, 一切归于沉寂, 后端连接依然在:&lt;/p&gt;
&lt;img alt="" src="/imgs/twemproxy-state-4.png" /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="buf"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id89"&gt;buf处理上的特点&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;输入是通过mbuf &lt;strong&gt;链表&lt;/strong&gt; 来保存, 不会做realloc()&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;mbuf大小默认是16K, 可以配置, 范围在 &lt;tt class="docutils literal"&gt;512B - 64K&lt;/tt&gt; 之间&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;mbuf, msg, conn等都有对象池, 减少对象分配:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct context *
core_start(struct instance *nci)
{
    mbuf_init(nci);     //mbuf内存池
    msg_init();         //msg池
    conn_init();        //连接对象池
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;请求是会被pipeline到后端的
就是说, 不必等proxy接收完整的请求, 再传给后端, 解析出一个msg, 就传給后端(如果msg比较大, 比如set 一个10M的对象, 效率就会比较低)
得到一个request_msg, 就转给后端, 在后端响应之前, 请求的msg 是不会销毁的.
得到后端response_msg后, request_msg 和response_msg 一起回到内存池.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id21"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id90"&gt;后端如何处理&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;后端连接池的处理:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct conn *
server_conn(struct server *server)
{
    struct server_pool *pool;
    struct conn *conn;

    pool = server-&amp;gt;owner;

    if (server-&amp;gt;ns_conn_q &amp;lt; pool-&amp;gt;server_connections) {
        return conn_get(server, false, pool-&amp;gt;redis);
    }
    ASSERT(server-&amp;gt;ns_conn_q == pool-&amp;gt;server_connections);

    /*
     * 这里只是简单的转了一下, 如果一个conn正在使用, 那么它也会返回, 也就是说一个server conn会同时被 两个client conn使用.
     */
    conn = TAILQ_FIRST(&amp;amp;server-&amp;gt;s_conn_q);
    ASSERT(!conn-&amp;gt;client &amp;amp;&amp;amp; !conn-&amp;gt;proxy);

    TAILQ_REMOVE(&amp;amp;server-&amp;gt;s_conn_q, conn, conn_tqe);
    TAILQ_INSERT_TAIL(&amp;amp;server-&amp;gt;s_conn_q, conn, conn_tqe);

    return conn;
}
&lt;/pre&gt;
&lt;p&gt;这个连接池会受到每个server多少个后端连接这样一个限制, 如果没达到限制, 那么一定是创建连接.
如果达到限制了, 一定是返回其中一个连接.&lt;/p&gt;
&lt;p&gt;所以&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;proxy 刚起来的时候, 性能会比较差. 可以用server_each_preconnect解决.&lt;/li&gt;
&lt;li&gt;这个 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;pool-&amp;gt;server_connections&lt;/span&gt;&lt;/tt&gt; 一般都没有配置(默认值是1. 虽然一个连接可能可以应付绝大多数场景, 个人感觉这必须配置啊!!!)
也就是说 不管前端多少个client, 到后端redis, 就只有1个连接. -- 这是这种proxy的特色&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id22"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id91"&gt;协议&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;因为需要从mbuf链表里面解析, 解析器是手工打造的..
这里暂时不去分析它.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id23"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id92"&gt;hash&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;twemproxy支持的hash方法:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;one_at_a_time&lt;/li&gt;
&lt;li&gt;md5&lt;/li&gt;
&lt;li&gt;crc16&lt;/li&gt;
&lt;li&gt;crc32 (crc32 implementation compatible with libmemcached)&lt;/li&gt;
&lt;li&gt;crc32a (correct crc32 implementation as per the spec)&lt;/li&gt;
&lt;li&gt;fnv1_64&lt;/li&gt;
&lt;li&gt;fnv1a_64&lt;/li&gt;
&lt;li&gt;fnv1_32&lt;/li&gt;
&lt;li&gt;fnv1a_32&lt;/li&gt;
&lt;li&gt;hsieh&lt;/li&gt;
&lt;li&gt;murmur&lt;/li&gt;
&lt;li&gt;jenkins&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们看hashkit/nc_hashkit.h 中的这个定义:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#define HASH_CODEC(ACTION)                      \
    ACTION( HASH_ONE_AT_A_TIME, one_at_a_time ) \
    ACTION( HASH_MD5,           md5           ) \
    ACTION( HASH_CRC16,         crc16         ) \
    ACTION( HASH_CRC32,         crc32         ) \
    ACTION( HASH_CRC32A,        crc32a        ) \
    ACTION( HASH_FNV1_64,       fnv1_64       ) \
    ACTION( HASH_FNV1A_64,      fnv1a_64      ) \
    ACTION( HASH_FNV1_32,       fnv1_32       ) \
    ACTION( HASH_FNV1A_32,      fnv1a_32      ) \
    ACTION( HASH_HSIEH,         hsieh         ) \
    ACTION( HASH_MURMUR,        murmur        ) \
    ACTION( HASH_JENKINS,       jenkins       ) \

#define DEFINE_ACTION(_hash, _name) _hash,
typedef enum hash_type {
    HASH_CODEC( DEFINE_ACTION )
    HASH_SENTINEL
} hash_type_t;
#undef DEFINE_ACTION
&lt;/pre&gt;
&lt;p&gt;这个宏显得有些复杂, 我们用 &lt;tt class="docutils literal"&gt;gcc &lt;span class="pre"&gt;-E&lt;/span&gt;&lt;/tt&gt; 展开来看看:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ gcc -E hashkit/nc_hashkit.h
...
typedef enum hash_type {
    HASH_ONE_AT_A_TIME, HASH_MD5, HASH_CRC16, HASH_CRC32, HASH_CRC32A, HASH_FNV1_64, HASH_FNV1A_64, HASH_FNV1_32, HASH_FNV1A_32, HASH_HSIEH, HASH_MURMUR, HASH_JENKINS,
    HASH_SENTINEL
} hash_type_t;
&lt;/pre&gt;
&lt;p&gt;在这个 enum定义之后, 是这些函数定义:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
uint32_t hash_one_at_a_time(const char *key, size_t key_length);
void md5_signature(const unsigned char *key, unsigned int length, unsigned char *result);
uint32_t hash_md5(const char *key, size_t key_length);
uint32_t hash_crc16(const char *key, size_t key_length);
uint32_t hash_crc32(const char *key, size_t key_length);
uint32_t hash_crc32a(const char *key, size_t key_length);
uint32_t hash_fnv1_64(const char *key, size_t key_length);
uint32_t hash_fnv1a_64(const char *key, size_t key_length);
uint32_t hash_fnv1_32(const char *key, size_t key_length);
uint32_t hash_fnv1a_32(const char *key, size_t key_length);
uint32_t hash_hsieh(const char *key, size_t key_length);
uint32_t hash_jenkins(const char *key, size_t length);
uint32_t hash_murmur(const char *key, size_t length);
&lt;/pre&gt;
&lt;p&gt;在配置文件解析的时候, 用户指定一个hash函数名字, 需要解析为conf_pool.hash:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
struct conf_pool {
    struct string      name;                  /* pool name (root node) */
    struct conf_listen listen;                /* listen: */
    hash_type_t        hash;                  /* hash: */
}

char *
conf_set_hash(struct conf *cf, struct command *cmd, void *conf)
{
    struct string *value, *hash;
    for (hash = hash_strings; hash-&amp;gt;len != 0; hash++) {
        if (string_compare(value, hash) != 0) {
            continue;
        }

        *hp = hash - hash_strings;
        return CONF_OK;
    }
    return &amp;quot;is not a valid hash&amp;quot;;
}
&lt;/pre&gt;
&lt;p&gt;这里的hash_strings是在 nc_conf.c里定义的:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#define string(_str)   { sizeof(_str) - 1, (uint8_t *)(_str) }
#define DEFINE_ACTION(_hash, _name) string(#_name),
static struct string hash_strings[] = {
    HASH_CODEC( DEFINE_ACTION )
    null_string
};
#undef DEFINE_ACTION
&lt;/pre&gt;
&lt;p&gt;展开得到的是:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
gcc -E nc_conf.c  -I ./ | vim -
static struct string hash_strings[] = {
    { sizeof(&amp;quot;one_at_a_time&amp;quot;) - 1, (uint8_t *)(&amp;quot;one_at_a_time&amp;quot;) }, { sizeof(&amp;quot;md5&amp;quot;) - 1, (uint8_t *)(&amp;quot;md5&amp;quot;) }, { sizeof(&amp;quot;crc16&amp;quot;) - 1, (uint8_t *)(&amp;quot;crc16&amp;quot;) }, { sizeof(&amp;quot;crc32&amp;quot;) - 1, (uint8_t *)(&amp;quot;crc32&amp;quot;) }, { sizeof(&amp;quot;crc32a&amp;quot;) - 1, (uint8_t *)(&amp;quot;crc32a&amp;quot;) }, { sizeof(&amp;quot;fnv1_64&amp;quot;) - 1, (uint8_t *)(&amp;quot;fnv1_64&amp;quot;) }, { sizeof(&amp;quot;fnv1a_64&amp;quot;) - 1, (uint8_t *)(&amp;quot;fnv1a_64&amp;quot;) }, { sizeof(&amp;quot;fnv1_32&amp;quot;) - 1, (uint8_t *)(&amp;quot;fnv1_32&amp;quot;) }, { sizeof(&amp;quot;fnv1a_32&amp;quot;) - 1, (uint8_t *)(&amp;quot;fnv1a_32&amp;quot;) }, { sizeof(&amp;quot;hsieh&amp;quot;) - 1, (uint8_t *)(&amp;quot;hsieh&amp;quot;) }, { sizeof(&amp;quot;murmur&amp;quot;) - 1, (uint8_t *)(&amp;quot;murmur&amp;quot;) }, { sizeof(&amp;quot;jenkins&amp;quot;) - 1, (uint8_t *)(&amp;quot;jenkins&amp;quot;) },
    { 0, ((void *)0) }
};
&lt;/pre&gt;
&lt;p&gt;配置文件解析后, 被加载到server_pool里面:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
typedef uint32_t (*hash_t)(const char *, size_t);
struct server_pool {
    int                dist_type;            /* distribution type (dist_type_t) */
    int                key_hash_type;        /* key hash type (hash_type_t) */
    hash_t             key_hash;             /* key hasher */
}

#这个宏定义一个函数列表
#define DEFINE_ACTION(_hash, _name) hash_##_name,
static hash_t hash_algos[] = {
    HASH_CODEC( DEFINE_ACTION )
    NULL
};
#undef DEFINE_ACTION
&lt;/pre&gt;
&lt;p&gt;展开后:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static hash_t hash_algos[] = {
    hash_one_at_a_time, hash_md5, hash_crc16, hash_crc32, hash_crc32a, hash_fnv1_64, hash_fnv1a_64, hash_fnv1_32, hash_fnv1a_32, hash_hsieh, hash_murmur, hash_jenkins,
    ((void *)0)
};
&lt;/pre&gt;
&lt;p&gt;最后, 利用conf中解析出来的 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;cp-&amp;gt;hash&lt;/span&gt;&lt;/tt&gt; 为下标, 直接去这个数组的函数指针即可:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sp-&amp;gt;key_hash = hash_algos[cp-&amp;gt;hash];
&lt;/pre&gt;
&lt;div class="section" id="id24"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id93"&gt;具体hash函数&lt;/a&gt;&lt;/h4&gt;
&lt;div class="section" id="crc32"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id94"&gt;crc32&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;crc32是设计来计算校验码的, 并不适合算hash.&lt;/p&gt;
&lt;p&gt;twemproxy 0.2.4 里面包含的crc32算法 crc32使用的是 memcache 用的crc32.
最新的版本里面包含了一个 crc32a, 才是原来含义上的crc32:&lt;/p&gt;
&lt;p&gt;用 &lt;tt class="docutils literal"&gt;crc32a&lt;/tt&gt; , 我们才能用这段代码计算key被分布到哪里去了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import binascii
word = 'hello'
crc32 =  binascii.crc32(word) &amp;amp; 0xffffffff
print '%08x' % crc32, crc32%4
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="hsieh"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id95"&gt;hsieh&lt;/a&gt;&lt;/h5&gt;
&lt;/div&gt;
&lt;div class="section" id="jenkins-lookup3"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id96"&gt;Jenkins lookup3&lt;/a&gt;&lt;/h5&gt;
&lt;/div&gt;
&lt;div class="section" id="jenkins-one-at-a-time"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id97"&gt;Jenkins one_at_a_time&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;The Jenkins hash functions are a collection of (non-cryptographic) hash functions for multi-byte keys designed by Bob Jenkins. They can be used also as checksums&lt;/p&gt;
&lt;pre class="literal-block"&gt;
uint32_t jenkins_one_at_a_time_hash(char *key, size_t len)
{
    uint32_t hash, i;
    for(hash = i = 0; i &amp;lt; len; ++i)
    {
        hash += key[i];
        hash += (hash &amp;lt;&amp;lt; 10);
        hash ^= (hash &amp;gt;&amp;gt; 6);
    }
    hash += (hash &amp;lt;&amp;lt; 3);
    hash ^= (hash &amp;gt;&amp;gt; 11);
    hash += (hash &amp;lt;&amp;lt; 15);
    return hash;
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="fnv-xxx"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id98"&gt;FNV-XXX&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;Fowler–Noll–Vo is a non-cryptographic hash function created by Glenn Fowler, Landon Curt Noll, and Phong Vo.&lt;/p&gt;
&lt;p&gt;FNV-1实现简单:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hash = FNV_offset_basis
for each octet_of_data to be hashed
     hash = hash × FNV_prime
     hash = hash XOR octet_of_data
return hash
&lt;/pre&gt;
&lt;p&gt;FNV-1a, reverses the multiply and XOR steps.&lt;/p&gt;
&lt;p&gt;designed primarily for hashtable and checksum use(不适合作为加密用的hash函数)&lt;/p&gt;
&lt;p&gt;特点:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;速度快&lt;/li&gt;
&lt;li&gt;对0敏感, 只要x和xor, 步骤里面 出现一个0, 后面就都是0(可以加个固定常数, 但是这样会破坏随机性)
(好在字符串没有这个问题)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="murmur"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id99"&gt;murmur&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;MurmurHash performed well in a random distribution of regular keys.[7]&lt;/p&gt;
&lt;p&gt;这些都用了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
libstdc++ (ver 4.6), Perl,[24] nginx (ver 1.0.1),[25] Rubinius,[26] libmemcached (the C driver for Memcached),[27] maatkit,[28] Hadoop,[1] Kyoto Cabinet,[29], RaptorDB[30], and Cassandra.[31]
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id25"&gt;
&lt;h5&gt;&lt;a class="toc-backref" href="#id100"&gt;小结&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;hash函数的几个要求:
1. 均匀性(排除crc32)
2. 速度
3. 如果能用python/php计算 hash更好.&lt;/p&gt;
&lt;p&gt;时间消耗上, 大致是:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Murmur/Jenkins(2s) &amp;lt; FNV(4s) &amp;lt; CRC32(5s)
&lt;/pre&gt;
&lt;p&gt;应该选择Murmur或者FNV-1&lt;/p&gt;
&lt;p&gt;参考:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.azillionmonkeys.com/qed/hash.html"&gt;http://www.azillionmonkeys.com/qed/hash.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://programmers.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed"&gt;http://programmers.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed&lt;/a&gt;  (这个文章对随机性和速度做了详细考察)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;twemproxy 的github上一般都是用 &lt;tt class="docutils literal"&gt;fnv1a_64&lt;/tt&gt;:&lt;/p&gt;
&lt;p&gt;我们可以用下面这段python实现:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#/home/ning/idning/langtest/python/fnv
def hash_fnv1a_64(s):
    UINT32_MAX=2**32
    FNV_64_INIT = 0xcbf29ce484222325 % UINT32_MAX
    FNV_64_PRIME = 0x100000001b3 % UINT32_MAX

    hval = FNV_64_INIT
    for c in s:
        hval = hval ^ ord(c)
        hval = (hval * FNV_64_PRIME) % UINT32_MAX
    return hval
&lt;/pre&gt;
&lt;p&gt;相比起来, 对应的murmur要复杂些, 所以我们选择  &lt;tt class="docutils literal"&gt;fnv1a_64&lt;/tt&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="dispatch"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id101"&gt;dispatch方法&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ketama&lt;/li&gt;
&lt;li&gt;modula&lt;/li&gt;
&lt;li&gt;random&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="rbtree"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id102"&gt;rbtree&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;一个proxy为什么需要rbtree?? 用来做某种超时:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static struct rbtree tmo_rbt;    /* timeout rbtree */

void
msg_tmo_insert(struct msg *msg, struct conn *conn)
{
    struct rbnode *node;
    int timeout;

    timeout = server_timeout(conn);
    if (timeout &amp;lt;= 0) {
        return;
    }

    node = &amp;amp;msg-&amp;gt;tmo_rbe;
    node-&amp;gt;key = nc_msec_now() + timeout;
    node-&amp;gt;data = conn;

    rbtree_insert(&amp;amp;tmo_rbt, node);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="mget"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id103"&gt;如何处理mget&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="nginx"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id104"&gt;代码严重受nginx影响&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;active 和ready变量&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ngx_int_t
ngx_handle_read_event(ngx_event_t *rev, ngx_uint_t flags)
{
    if (ngx_event_flags &amp;amp; NGX_USE_CLEAR_EVENT) {

        /* kqueue, epoll */

        if (!rev-&amp;gt;active &amp;amp;&amp;amp; !rev-&amp;gt;ready) {
            if (ngx_add_event(rev, NGX_READ_EVENT, NGX_CLEAR_EVENT)
                == NGX_ERROR)
            {
                return NGX_ERROR;
            }
        }

        return NGX_OK;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id26"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id105"&gt;(代码)小结&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;代码质量非常好, 举例&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;函数开始写ASSERT:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int
event_wait(struct event_base *evb, int timeout)
{
    int ep = evb-&amp;gt;ep;
    struct epoll_event *event = evb-&amp;gt;event;
    int nevent = evb-&amp;gt;nevent;

    ASSERT(ep &amp;gt; 0);
    ASSERT(event != NULL);
    ASSERT(nevent &amp;gt; 0);
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;类名, 函数名, 注释都很赞.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;状态变迁: 因为逻辑相对简单, 不需要保存状态, 所以只是有一个conn.client 标志表示状态,  &lt;strong&gt;不需要一个状态机, 机制不同&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;从这个配置看, 完全的nginx风格:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static struct command conf_commands[] = {
    { string(&amp;quot;listen&amp;quot;),
      conf_set_listen,
      offsetof(struct conf_pool, listen) },

    { string(&amp;quot;hash&amp;quot;),
      conf_set_hash,
      offsetof(struct conf_pool, hash) },

    { string(&amp;quot;hash_tag&amp;quot;),
      conf_set_hashtag,
      offsetof(struct conf_pool, hash_tag) },

    { string(&amp;quot;server_connections&amp;quot;),
      conf_set_num,
      offsetof(struct conf_pool, server_connections) },

    null_command
};
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id27"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id106"&gt;注意&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;这个 &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;pool-&amp;gt;server_connections&lt;/span&gt;&lt;/tt&gt; 一般都没有配置(默认值是1. 虽然一个连接可能可以应付绝大多数场景, 个人感觉这必须配置啊!!!)&lt;/p&gt;
&lt;p&gt;也就是说 不管前端多少个client, 到后端redis, 就只有1个连接. -- 这是这种proxy的特色&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;通过msg-&amp;gt;peer 和msg-&amp;gt;owner 耦合client_conn与server_conn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;非常巧妙的设计, 多个前端, 可以同时复用后端的 &lt;strong&gt;一个连接&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
//下面这里建立的link是保证客户端收到的请求和响应一一对应的关键.
//client_conn-&amp;gt;out_q 里面还保存着按照发送顺序的请求msg. 这里收到了response 的msg之后.
//一一对应起来, 向客户端返回response的时候, 按照 client_conn-&amp;gt;out_q的顺序, 看相应的
//msg 的peer是否被设置了, 如果设置了, 就可以返回.  //
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;这也是与一般的proxy不一样的地方,
一般的proxy, 收到client_conn_1消息, 处理后找个后端连接发过去, 此时这个后端连接是不会被其它客户端连接复用的, 而这时收到的response也就必然是client_conn_1对应的response, 直接放到client_conn1的输出队列即可.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
//
/* establish msg &amp;lt;-&amp;gt; pmsg (response &amp;lt;-&amp;gt; request) link */
pmsg-&amp;gt;peer = msg;
msg-&amp;gt;peer = pmsg;
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里proxy必须保存req msg的body和resp msg的body, 如果后端网络/响应慢, 则req msg撑爆内存, 如果前端不读取, 则rsp msg撑爆内存.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;能用这种后端只开一个连接的proxy, 要求:&lt;/dt&gt;
&lt;dd&gt;&lt;ol class="first last arabic simple"&gt;
&lt;li&gt;后端交互包不会被打散, 即一个连接上, 包一定是连续的发出, 或者连续的收到.&lt;/li&gt;
&lt;li&gt;单连接上, 后端返回顺序和请求顺序一致.
如果服务器在一个连接上起多个线程来服务, 哪个线程先处理完，就 &lt;strong&gt;从这个连接&lt;/strong&gt; 返回, 那proxy层就乱套了(不过这时候如果有个req/resp id, 也是可以的)&lt;/li&gt;
&lt;li&gt;小包(req/resp都很小, 这样才容易满足1)&lt;/li&gt;
&lt;li&gt;后端处理很快(否则都堆在proxy了)&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id28"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id107"&gt;使用&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id29"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id108"&gt;编译&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="debug"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id109"&gt;debug级别&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;有两种debug: log_debug输出到日志和ASSERT:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
flag                         log    ASSERT
--enable-debug=no       =&amp;gt;   0      啥也不做
--enable-debug=log      =&amp;gt;   1      啥也不做
--enable-debug=yes      =&amp;gt;   1      出错时打日志
--enable-debug=full     =&amp;gt;   1      出错时core
&lt;/pre&gt;
&lt;p&gt;configure.ac:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
AS_CASE([x$enable_debug],
  [xfull], [AC_DEFINE([HAVE_ASSERT_PANIC], [1],
                      [Define to 1 if panic on an assert is enabled])
            AC_DEFINE([HAVE_DEBUG_LOG], [1], [Define to 1 if debug log is enabled])
           ],
  [xyes], [AC_DEFINE([HAVE_ASSERT_LOG], [1],
                     [Define to 1 if log on an assert is enabled])
           AC_DEFINE([HAVE_DEBUG_LOG], [1], [Define to 1 if debug log is enabled])
          ],
  [xlog], [AC_DEFINE([HAVE_DEBUG_LOG], [1], [Define to 1 if debug log is enabled])],
  [xno], [],
  [AC_MSG_FAILURE([invalid value ${enable_debug} for --enable-debug])])
AC_MSG_RESULT($enable_debug)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="core"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id110"&gt;core的问题&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;./configure --enable-debug=log&lt;/p&gt;
&lt;p&gt;有些老的gcc可能会core&lt;/p&gt;
&lt;p&gt;比如:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/115"&gt;https://github.com/twitter/twemproxy/issues/115&lt;/a&gt;
&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/146"&gt;https://github.com/twitter/twemproxy/issues/146&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in my machine(centos6.3):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ gcc -v
Using built-in specs.
Target: x86_64-redhat-linux
Thread model: posix
gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC)
&lt;/pre&gt;
&lt;p&gt;debug=no:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./configure  &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8                                         =&amp;gt; core
./configure CFLAGS=&amp;quot;-O1 -g3&amp;quot; &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8                         =&amp;gt; ok
./configure CFLAGS=&amp;quot;-O2 -g3&amp;quot; &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8                         =&amp;gt; core
./configure CFLAGS=&amp;quot;-O3 -g3&amp;quot; &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8                         =&amp;gt; core
&lt;/pre&gt;
&lt;p&gt;debug=log:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./configure --enable-debug=log &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8                       =&amp;gt; core
./configure CFLAGS=&amp;quot;-O1 -g3&amp;quot; --enable-debug=log &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8      =&amp;gt; ok
./configure CFLAGS=&amp;quot;-O2 -g3&amp;quot; --enable-debug=log &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8      =&amp;gt; core
./configure CFLAGS=&amp;quot;-O3 -g3&amp;quot; --enable-debug=log &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8      =&amp;gt; core
&lt;/pre&gt;
&lt;p&gt;debug=full:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./configure --enable-debug=full &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8                      =&amp;gt; ok
./configure CFLAGS=&amp;quot;-O1 -g3&amp;quot; --enable-debug=full &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8     =&amp;gt; ok
./configure CFLAGS=&amp;quot;-O2 -g3&amp;quot; --enable-debug=full &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8     =&amp;gt; ok
./configure CFLAGS=&amp;quot;-O3 -g3&amp;quot; --enable-debug=full &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8     =&amp;gt; ok
&lt;/pre&gt;
&lt;p&gt;在configure里面写了, 默认是-O2(看直接./configure 之后make的输出, 也能看到-O2):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
elif test $ac_cv_prog_cxx_g = yes; then
  if test &amp;quot;$GXX&amp;quot; = yes; then
    CXXFLAGS=&amp;quot;-g -O2&amp;quot;
  else
    CXXFLAGS=&amp;quot;-g&amp;quot;
  fi
else
  if test &amp;quot;$GXX&amp;quot; = yes; then
    CXXFLAGS=&amp;quot;-O2&amp;quot;
  else
    CXXFLAGS=
  fi
fi
&lt;/pre&gt;
&lt;p&gt;比较优化选项:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ gcc -c -Q -O1 --help=optimizers &amp;gt; /tmp/o1
$ gcc -c -Q -O2 --help=optimizers &amp;gt; /tmp/o2

-finline-small-functions
&lt;/pre&gt;
&lt;p&gt;分别用-O1 和-O2生成的二进制, 看某个函数的汇编, 差别太大了:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
objdump -d src/nutcracker.o1
&lt;/pre&gt;
&lt;p&gt;对函数禁止优化:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
有时候，我们希望对某个函数或者某块代码添加自己的优化选项
这个可以通过下面的宏实现：
对代码块的优化/禁止优化：
#pragma GCC push_options
#pragma GCC optimize (&amp;quot;O0&amp;quot;)

your code

#pragma GCC pop_options
to disable optimizations since GCC 4.4.
&lt;/pre&gt;
&lt;p&gt;对函数的优化/禁止优化:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
__attribute__((optimize(&amp;quot;O0&amp;quot;)))
&lt;/pre&gt;
&lt;p&gt;写了个脚本逐一去掉 -O2的选项:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cd ~/twemproxy &amp;amp;&amp;amp; ./configure CFLAGS=&amp;quot;-O1  -falign-functions -falign-jumps -falign-labels -falign-loops -fcaller-saves -fcrossjumping -fcse-follow-jumps -fdelete-null-pointer-checks -fexpensive-optimizations -fforward-propagate -fgcse -finline-small-functions -fipa-cp -foptimize-register-move -foptimize-sibling-calls -fpeephole2 -fregmove -freorder-blocks -freorder-functions -frerun-cse-after-loop -fschedule-insns2 -fstrict-aliasing&amp;quot; &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make -j 8
&lt;/pre&gt;
&lt;p&gt;去掉 -fstrict-aliasing 就好.&lt;/p&gt;
&lt;p&gt;带 -fstrict-aliasing  就会出问题.&lt;/p&gt;
&lt;p&gt;下面的就ok:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./configure CFLAGS=&amp;quot;-O3 -fno-strict-aliasing&amp;quot; &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id30"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id111"&gt;使用&lt;/a&gt;&lt;/h3&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;一般运行的时候需要指定一个pid文件, 如果这个命令连续运行两次, 则pid文件被清除:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ ll log/
total 16K
928376 -rw-r--r-- 1 ning ning 12K 2013-12-20 15:36 nutcracker-22000.log
928377 -rw-r--r-- 1 ning ning   5 2013-12-20 15:36 nutcracker-22000.pid
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ bin/nutcracker -d -c /tmp/r/nutcracker-22000/conf/nutcracker-22000.conf -o /tmp/r/nutcracker-22000/log/nutcracker-22000.log -p /tmp/r/nutcracker-22000/log/nutcracker-22000.pid -s 23000
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ ll log/
total 12K
928376 -rw-r--r-- 1 ning ning 12K 2013-12-20 15:36 nutcracker-22000.log
&lt;/pre&gt;
&lt;p&gt;因为第二个进程会启动后 先写pid文件, 发现listen失败, 就退出, 同时清空pid文件.
应该修改一下, 如果pid文件已经存在, 拒绝启动&lt;/p&gt;
&lt;p&gt;同时, 我们的部署脚本, 也需要一个kill任务. 强制kill&lt;/p&gt;
&lt;p&gt;redis 本身就是先listen, 后写pid文件.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;listen:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cluster0:
    listen: 127.0.0.5:22000
&lt;/pre&gt;
&lt;p&gt;这是进程只会监听127.0.0.5 上的端口:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
tcp        0      0 127.0.0.5:22000         0.0.0.0:*               LISTEN      8581/nutcracker
&lt;/pre&gt;
&lt;p&gt;需要改成:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cluster0:
    listen: 0.0.0.0:22000

    tcp        0      0 0.0.0.0:22000           0.0.0.0:*               LISTEN      19902/nutcracker
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id31"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id112"&gt;配置参数&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
alpha:
  listen: 127.0.0.1:22121
  hash: fnv1a_64
  distribution: ketama
  auto_eject_hosts: true
  redis: true
  server_retry_timeout: 2000
  server_failure_limit: 1
  servers:
   - 127.0.0.1:6379:1
&lt;/pre&gt;
&lt;div class="section" id="hashdistribution"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id113"&gt;hash和distribution见前面分析&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;div class="section" id="auto-eject-hosts"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id114"&gt;auto_eject_hosts相关&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;下面选项只在auto_eject_hosts时有用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;server_failure_limit(多少次开始弹出)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;The number of conseutive failures on a server that would leads to it being temporarily ejected when auto_eject_host is set to true&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;server_retry_timeout(每次弹出多长时间)&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;是说在这段时间内, 这个host是被eject的(不在hash环中)&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;这一块的代码 &lt;tt class="docutils literal"&gt;modula_update&lt;/tt&gt; 还没仔细看&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="timeout"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id115"&gt;timeout&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;默认情况下, twemproxy一直等着把请求传给后端, 但是如果等了timeout时间, proxy 就不会把这个请求传给后端, 而是向客户端回复一个&lt;/p&gt;
&lt;p&gt;SERVER_ERROR Connection timed outrn is sent back to the client.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="log"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id116"&gt;log&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;编译时加上log选项, 设为 LOG_INFO&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mbuf-size"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id117"&gt;mbuf size&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;default mbuf-size of 16K&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以在启动时指定:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/nutcracker -h
This is nutcracker-0.2.4

Usage: nutcracker [-?hVdDt] [-v verbosity level] [-o output file]
                  [-c conf file] [-s stats port] [-a stats addr]
                  [-i stats interval] [-p pid file] [-m mbuf size]

Options:
  -h, --help             : this help
  -V, --version          : show version and exit
  -t, --test-conf        : test configuration for syntax errors and exit
  -d, --daemonize        : run as a daemon
  -D, --describe-stats   : print stats description and exit
  -v, --verbosity=N      : set logging level (default: 5, min: 0, max: 11)
  -o, --output=S         : set logging file (default: stderr)
  -c, --conf-file=S      : set configuration file (default: conf/nutcracker.yml)
  -s, --stats-port=N     : set stats monitoring port (default: 22222)
  -a, --stats-addr=S     : set stats monitoring ip (default: 0.0.0.0)
  -i, --stats-interval=N : set stats aggregation interval in msec (default: 30000 msec)
  -p, --pid-file=S       : set pid file (default: off)
  -m, --mbuf-size=N      : set size of mbuf chunk in bytes (default: 16384 bytes)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="max-key-lenght"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id118"&gt;max key lenght&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;对memcache: ascii protocol key最多 250 characters. The key should not include whitespace, or 'r' or 'n' character.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;redis 没有这个限制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;nutcracker requires the key to be stored in a contiguous memory region.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;也就是说key必须小于mbuf size&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="server-connections-1"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id119"&gt;server_connections: &amp;gt; 1&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;如果client想要在一个pipeline里面读到最新的写, 就要设置server_connections:1,
如果我们设置 &lt;tt class="docutils literal"&gt;server_connections:2&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;那么:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
set foo bar
get foo
&lt;/pre&gt;
&lt;p&gt;后面这个get可能在另一个连接里面发过去, 所以不一定能读到 &lt;tt class="docutils literal"&gt;set foo bar&lt;/tt&gt; 的结果&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id32"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id120"&gt;监控&lt;/a&gt;&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;server_err&lt;/li&gt;
&lt;li&gt;server_timedout&lt;/li&gt;
&lt;li&gt;server_eof&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="redis-mgr"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id121"&gt;使用redis-mgr部署&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
cluster0 = {
    'cluster_name': 'cluster0',
    'user': 'ning',
    'sentinel':[
        ('127.0.0.5:21001', '/tmp/r/sentinel-21001'),
        ('127.0.0.5:21002', '/tmp/r/sentinel-21002'),
        ('127.0.0.5:21003', '/tmp/r/sentinel-21003'),
    ],
    'redis': [
        # master(host:port, install path)       ,  slave(host:port, install path)
        ('127.0.0.5:20000', '/tmp/r/redis-20000'), ('127.0.0.5:30000', '/tmp/r/redis-30000'),
        ('127.0.0.5:20001', '/tmp/r/redis-20001'), ('127.0.0.5:30001', '/tmp/r/redis-30001'),
        ('127.0.0.5:20002', '/tmp/r/redis-20002'), ('127.0.0.5:30002', '/tmp/r/redis-30002'),
        ('127.0.0.5:20003', '/tmp/r/redis-20003'), ('127.0.0.5:30003', '/tmp/r/redis-30003'),
    ],
    'nutcracker': [
        ('127.0.0.5:22000', '/tmp/r/nutcracker-22000'),
        ('127.0.0.5:22001', '/tmp/r/nutcracker-22001'),
        ('127.0.0.5:22002', '/tmp/r/nutcracker-22002'),
    ],
}
&lt;/pre&gt;
&lt;p&gt;对redis的benchmark(在我自己机器上):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark -h 127.0.0.5 -p 20000 -t get,set -n 1000000
====== SET ======
  1000000 requests completed in 18.65 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

86.50% &amp;lt;= 1 milliseconds
99.66% &amp;lt;= 2 milliseconds
53613.55 requests per second

====== GET ======
  1000000 requests completed in 16.25 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.25% &amp;lt;= 1 milliseconds
99.89% &amp;lt;= 2 milliseconds
61557.40 requests per second
&lt;/pre&gt;
&lt;p&gt;对proxy 的benchmark:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ redis-benchmark -h 127.0.0.5 -p 22000 -t get,set -n 1000000
====== SET ======
  1000000 requests completed in 21.45 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

86.42% &amp;lt;= 1 milliseconds
99.76% &amp;lt;= 2 milliseconds
46628.74 requests per second

====== GET ======
  1000000 requests completed in 48.91 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

30.70% &amp;lt;= 1 milliseconds
44.95% &amp;lt;= 2 milliseconds
20445.30 requests per second
&lt;/pre&gt;
&lt;p&gt;高并发先, 直连redis性能差, cpu都起不来.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id33"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id122"&gt;日志级别&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;我们如果编译debug版本:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cd nutcracker-0.2.4/ &amp;amp;&amp;amp; ./configure CFLAGS=&amp;quot;-O1&amp;quot; --enable-debug=full --prefix=`pwd`/../output &amp;amp;&amp;amp; make -j 8 &amp;amp;&amp;amp; make install
&lt;/pre&gt;
&lt;p&gt;默认的日志级别是5, 就会有很多连接日志:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[Mon Jan 20 09:44:01 2014] nc_core.c:207 close c 12 '127.0.0.5:52020' on event 0001 eof 1 done 1 rb 26714 sb 13301
[Mon Jan 20 09:44:01 2014] nc_proxy.c:337 accepted c 12 on p 11 from '127.0.0.5:52021'
[Mon Jan 20 09:44:02 2014] nc_core.c:207 close c 12 '127.0.0.5:52021' on event 0001 eof 1 done 1 rb 26741 sb 13315
[Mon Jan 20 09:44:02 2014] nc_proxy.c:337 accepted c 12 on p 11 from '127.0.0.5:52022'
[Mon Jan 20 09:44:04 2014] nc_core.c:207 close c 12 '127.0.0.5:52022' on event 0001 eof 1 done 1 rb 26768 sb 13329
[Mon Jan 20 09:44:04 2014] nc_proxy.c:337 accepted c 12 on p 11 from '127.0.0.5:52024'
[Mon Jan 20 09:44:05 2014] nc_core.c:207 close c 12 '127.0.0.5:52024' on event 0001 eof 1 done 1 rb 26795 sb 13343
[Mon Jan 20 09:44:05 2014] nc_proxy.c:337 accepted c 12 on p 11 from '127.0.0.5:52025'
[Mon Jan 20 09:44:06 2014] nc_core.c:207 close c 12 '127.0.0.5:52025' on event 0001 eof 1 done 1 rb 26822 sb 13357
[Mon Jan 20 09:44:06 2014] nc_proxy.c:337 accepted c 12 on p 11 from '127.0.0.5:52026'
[Mon Jan 20 09:44:07 2014] nc_core.c:207 close c 12 '127.0.0.5:52026' on event 0001 eof 1 done 1 rb 26849 sb 13371
[Mon Jan 20 09:44:07 2014] nc_proxy.c:337 accepted c 12 on p 11 from '127.0.0.5:52027'
[Mon Jan 20 09:44:08 2014] nc_core.c:207 close c 12 '127.0.0.5:52027' on event 0001 eof 1 done 1 rb 26876 sb 13385
[Mon Jan 20 09:44:08 2014] nc_proxy.c:337 accepted c 12 on p 11 from '127.0.0.5:52028'
&lt;/pre&gt;
&lt;p&gt;处理方法:&lt;/p&gt;
&lt;div class="section" id="id34"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id123"&gt;修改日志级别:&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/nutcracker -h
This is nutcracker-0.2.4

Usage: nutcracker [-?hVdDt] [-v verbosity level] [-o output file]
                  [-c conf file] [-s stats port] [-a stats addr]
                  [-i stats interval] [-p pid file] [-m mbuf size]

Options:
  -h, --help             : this help
  -V, --version          : show version and exit
  -t, --test-conf        : test configuration for syntax errors and exit
  -d, --daemonize        : run as a daemon
  -D, --describe-stats   : print stats description and exit
  -v, --verbosity=N      : set logging level (default: 5, min: 0, max: 11)
  -o, --output=S         : set logging file (default: stderr)
  -c, --conf-file=S      : set configuration file (default: conf/nutcracker.yml)
  -s, --stats-port=N     : set stats monitoring port (default: 22222)
  -a, --stats-addr=S     : set stats monitoring ip (default: 0.0.0.0)
  -i, --stats-interval=N : set stats aggregation interval in msec (default: 30000 msec)
  -p, --pid-file=S       : set pid file (default: off)
  -m, --mbuf-size=N      : set size of mbuf chunk in bytes (default: 16384 bytes)
&lt;/pre&gt;
&lt;p&gt;使用 &lt;tt class="docutils literal"&gt;nutcracker &lt;span class="pre"&gt;-v&lt;/span&gt; 0&lt;/tt&gt; 即可&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id35"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id124"&gt;2.动态调整日志级别:&lt;/a&gt;&lt;/h4&gt;
&lt;pre class="literal-block"&gt;
case SIGTTIN:
    actionstr = &amp;quot;, up logging level&amp;quot;;
    action = log_level_up;
    break;

case SIGTTOU:
    actionstr = &amp;quot;, down logging level&amp;quot;;
    action = log_level_down;
    break;

case SIGHUP:
    actionstr = &amp;quot;, reopening log file&amp;quot;;
    action = log_reopen;
    break;
&lt;/pre&gt;
&lt;p&gt;所以:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kill -s TTOU  23787
&lt;/pre&gt;
&lt;p&gt;日志显示:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[Mon Jan 20 09:44:09 2014] nc_signal.c:122 signal 22 (SIGTTOU) received, down logging level
[Mon Jan 20 09:44:09 2014] nc_log.c:95 down log level to 4
&lt;/pre&gt;
&lt;p&gt;此时就没有连接日志了.&lt;/p&gt;
&lt;p&gt;如果想要多看日志:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kill -s TTIN 15797
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id36"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id125"&gt;3.切日志&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;如果我们需要用日志统计流量, 客户端信息, 可以切日志, 方法:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ mv log/nutcracker.log log/nutcracker.log.20140120
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ ll log/
total 124K
813654 -rw-r--r-- 1 ning ning 114K 2014-01-20 09:44 nutcracker.log.20140120
813655 -rw-r--r-- 1 ning ning    5 2014-01-20 09:33 nutcracker.pid
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ cat log/nutcracker.pid
23787

#doit
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ cat log/nutcracker.pid | xargs kill -s HUP
ning&amp;#64;ning-laptop /tmp/r/nutcracker-22000$ ll log/
total 124K
813688 -rw-r--r-- 1 ning ning    0 2014-01-20 09:49 nutcracker.log
813654 -rw-r--r-- 1 ning ning 114K 2014-01-20 09:49 nutcracker.log.20140120
813655 -rw-r--r-- 1 ning ning    5 2014-01-20 09:33 nutcracker.pid
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id37"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id126"&gt;自己实现一个自动的主从切换?&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;0配置, 利用sentinel用的方式, 获知sentinel的位置.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="sentinel"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id127"&gt;sentinel验证&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;如果一主一丛, 主彻底挂了, 从应该是提升为主, 而給老主发的&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id38"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id128"&gt;配置和优化&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="m-512"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id129"&gt;-m 512&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;速度提高, 内存消耗减少(一般消息都小于512字节)&lt;/p&gt;
&lt;p&gt;注意: 不能滥用, twemproxy实现里面, 一个key必须放在一个mbuf里面(解析器, 为了防止拷贝数据做的限制), 所以, 如果key长度大于mbuf大小, 会打印错误:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if (r-&amp;gt;rlen &amp;gt;= mbuf_data_size()) {
    log_error(&amp;quot;parsed bad req %&amp;quot;PRIu64&amp;quot; of type %d with key &amp;quot;
              &amp;quot;length %d that greater than or equal to maximum&amp;quot;
              &amp;quot; redis key length of %d&amp;quot;, r-&amp;gt;id, r-&amp;gt;type,
              r-&amp;gt;rlen, mbuf_data_size());
    goto error;
}
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
Mbuf enables zero copy for requests and responses flowing through the proxy. By default an mbuf is 16K

nutcracker requires the key to be stored in a contiguous memory region. Since all requests and responses in nutcracker are stored in mbuf, the maximum length of the redis key is limited by the size of the maximum available space for data in mbuf (mbuf_data_size()).
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id39"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id130"&gt;问题&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="preconnect-true-redis-core"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id131"&gt;preconnect: true 的时候, 如果后端redis挂掉, 会core&lt;/a&gt;&lt;/h3&gt;
&lt;pre class="literal-block"&gt;
[Tue Dec 24 21:10:20 2013] nc_util.c:291 [0] /lib64/tls/libpthread.so.0 [0x302b80c420]
[Tue Dec 24 21:10:20 2013] nc_util.c:291 [1] bin/nutcracker(server_unref+0x5a) [0x405f7a]
[Tue Dec 24 21:10:20 2013] nc_util.c:291 [2] bin/nutcracker(server_close+0x1ae) [0x40681e]
[Tue Dec 24 21:10:20 2013] nc_util.c:291 [3] bin/nutcracker(core_loop+0x89) [0x4054d9]
[Tue Dec 24 21:10:20 2013] nc_util.c:291 [4] bin/nutcracker(main+0x4b5) [0x40f1c5]
[Tue Dec 24 21:10:20 2013] nc_util.c:291 [5] /lib64/tls/libc.so.6(__libc_start_main+0xdb) [0x302af1c4bb]
[Tue Dec 24 21:10:20 2013] nc_util.c:291 [6] bin/nutcracker [0x40507a]
[Tue Dec 24 21:10:20 2013] nc_signal.c:122 signal 11 (SIGSEGV) received, core dumping


似乎是这个问题: https://github.com/twitter/twemproxy/issues/146
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="pipeline-replay"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id132"&gt;pipeline/replay时消耗大量内存:&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/203"&gt;https://github.com/twitter/twemproxy/issues/203&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:~/idning-github/redis-mgr$ cat tests/a.py
import socket
import time

HOST = '127.0.0.5'
PORT = 24000

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.connect((HOST, PORT))

data = '*3\r\n$3\r\nSET\r\n$13\r\nkkk-100001480\r\n$13\r\nvvv-100001480\r\n'
for i in range(100*1000):
    s.sendall(data)

ning&amp;#64;ning-laptop:~/idning-github/redis-mgr$ time python tests/a.py

real        0m0.797s
user        0m0.280s
sys 0m0.120s
&lt;/pre&gt;
&lt;p&gt;I found that twemproxy consume 1.6G of  memeory, and the memory will not free after the client shutdown:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ning&amp;#64;ning-laptop:/tmp/r/nutcracker-24000$ ps aux | grep nut
ning      2017  0.5 14.8 1652068 1186692 ?     Sl   09:43   0:00 bin/nutcracker -d -c /tmp/r/nutcracker-24000/conf/nutcracker.conf -o /tmp/r/nutcracker-24000/log/nutcracker.log -p /tmp/r/nutcracker-24000/log/nutcracker.pid -s 25000 -v 4

100*1000*52(msg length) = 5MB
&lt;/pre&gt;
&lt;p&gt;send 5MB to twemproxy, it will consume 1.6G memory...&lt;/p&gt;
&lt;p&gt;if we deploy twemporxy and redis on the same machine. they will killed by OOMKiller.&lt;/p&gt;
&lt;p&gt;原因:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./bin/nutcracker -h
...
-m, --mbuf-size=N      : set size of mbuf chunk in bytes (default: 16384 bytes)
&lt;/pre&gt;
&lt;p&gt;default mbuf size is 16K, and twemproxy will alloc at least one mbuf for one msg, so 100*1000 msgs will use 1.6G memory.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;twemproxy will not free the request mbuf until client read the response&lt;/li&gt;
&lt;li&gt;twemproxy not reduce memory on mbuf pool.
it only call &lt;tt class="docutils literal"&gt;mbuf_free&lt;/tt&gt; on &lt;tt class="docutils literal"&gt;mbuf_deinit&lt;/tt&gt;, which is called on server down&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;that is a big pipeline, got huge memory consumption&lt;/p&gt;
&lt;p&gt;this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
data = '*3\r\n$3\r\nSET\r\n$13\r\nkkk-100001480\r\n$13\r\nvvv-100001480\r\n'
for i in range(1*1000):
    s.sendall(data)

#print s.recv(10*1000)
&lt;/pre&gt;
&lt;p&gt;endswith:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
==9226== 311,064 bytes in 997 blocks are possibly lost in loss record 38 of 38
==9226==    at 0x4C274A8: malloc (vg_replace_malloc.c:236)
==9226==    by 0x411C75: _nc_alloc (nc_util.c:224)
==9226==    by 0x409B6B: _msg_get (nc_message.c:200)
==9226==    by 0x409CC5: msg_get (nc_message.c:268)
==9226==    by 0x40A1DC: msg_recv (nc_message.c:439)
==9226==    by 0x406178: core_core (nc_core.c:158)
==9226==    by 0x41BBB7: event_wait (nc_epoll.c:269)
==9226==    by 0x405F88: core_loop (nc_core.c:316)
==9226==
==9226== LEAK SUMMARY:
==9226==    definitely lost: 0 bytes in 0 blocks
==9226==    indirectly lost: 0 bytes in 0 blocks
==9226==      possibly lost: 352,937 bytes in 1,129 blocks
==9226==    still reachable: 27,735 bytes in 50 blocks
==9226==         suppressed: 0 bytes in 0 blocks
==9226== Reachable blocks (those to which a pointer was found) are not shown.
==9226== To see them, rerun with: --leak-check=full --show-reachable=yes
&lt;/pre&gt;
&lt;p&gt;this script:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
data = '*3\r\n$3\r\nSET\r\n$13\r\nkkk-100001480\r\n$13\r\nvvv-100001480\r\n'
for i in range(1*1000):
    s.sendall(data)

#print s.recv(10*1000)
&lt;/pre&gt;
&lt;p&gt;ends with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
==9255== 4,292,608 bytes in 262 blocks are possibly lost in loss record 40 of 40
==9255==    at 0x4C274A8: malloc (vg_replace_malloc.c:236)
==9255==    by 0x411C75: _nc_alloc (nc_util.c:224)
==9255==    by 0x40BCF5: mbuf_get (nc_mbuf.c:46)
==9255==    by 0x40BD4A: mbuf_split (nc_mbuf.c:241)
==9255==    by 0x40A1AA: msg_recv (nc_message.c:434)
==9255==    by 0x406178: core_core (nc_core.c:158)
==9255==    by 0x41BBB7: event_wait (nc_epoll.c:269)
==9255==    by 0x405F88: core_loop (nc_core.c:316)
==9255==
==9255== LEAK SUMMARY:
==9255==    definitely lost: 0 bytes in 0 blocks
==9255==    indirectly lost: 0 bytes in 0 blocks
==9255==      possibly lost: 4,376,723 bytes in 535 blocks
&lt;/pre&gt;
&lt;p&gt;原因是太快的向proxy发送大量数据, proxy 不管三七二十一, 都把数据全部接收下来, 再慢慢处理, 这就造成大量msg对象堆在proxy的内存中,&lt;/p&gt;
&lt;p&gt;nutcracker always try to receive at the client side:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rstatus_t
core_core(void *arg, uint32_t events)
{
    /* read takes precedence over write */
    if (events &amp;amp; EVENT_READ) {
        status = core_recv(ctx, conn);      //call conn-&amp;gt;recv (msg_recv)
        if (status != NC_OK || conn-&amp;gt;done || conn-&amp;gt;err) {
            core_close(ctx, conn);
            return NC_ERROR;
        }
    }
    ...
}
&lt;/pre&gt;
&lt;p&gt;if the client write to the socket, it will always success, (something like &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;redis-cli&lt;/span&gt; &lt;span class="pre"&gt;--pipe&lt;/span&gt;&lt;/tt&gt; ) then message queued at nutcracker, and got timeouted,&lt;/p&gt;
&lt;p&gt;the problem is client do not know when to stop sending request,&lt;/p&gt;
&lt;p&gt;I think we can add a config like &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;max-queue&lt;/span&gt;&lt;/tt&gt;, if nutcracker got too much request queued, it stop read at the client side.&lt;/p&gt;
&lt;p&gt;so the client will block on sending&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mgetcase"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id133"&gt;mget慢这个case&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We are looking to use TwemProxy with Redis for sharding. We have use cases where we may need to fetch about 10k keys in one go from across multiple shards. However, when I try this with TwemProxy on a test setup (described below), it takes about 1.7 seconds to return. If I fired the same request on a single Redis instance directly, it returns in about 16ms.&lt;/p&gt;
&lt;p&gt;-m 512, I got the best results. With this, multi-key get on 10k keys returned in about 750ms&lt;/p&gt;
&lt;p&gt;For example, if my input buffer from read syscall contains 10 messages = [1, 2, 3, 4, 5, 6, ... 10], we leave existing message &amp;quot;1&amp;quot; in its current mbuf and copy messages from [2,3,4,5, ...10] to a new mbuf. Once message &amp;quot;1&amp;quot; is processed, we then we copy messages from [3,4,5,6,...10] to a new mbuf and so on and on. So, to split messages [1,2,3...10] across 10 mbufs we are doing quadratic instead of linear copies. This is really unfortunate,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id40"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id134"&gt;应该允许释放mbuf&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;否则一旦分配，就不释放&lt;/p&gt;
&lt;p&gt;大量并发mget, 就需要用小的mbuf size&lt;/p&gt;
&lt;p&gt;This is the reason why for 'large number' of connections or for wide multi-get like requests, you want to choose a small value for mbuf-size like 512&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id41"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id135"&gt;#一轮完了再集中加事件, 不要多次加, 重复加&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;实际上, 已经做了这个优化, 只有第一次加事件的时候才真正加:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
static void
req_forward(struct context *ctx, struct conn *c_conn, struct msg *msg)

    ...

    /* enqueue the message (request) into server inq */
    if (TAILQ_EMPTY(&amp;amp;s_conn-&amp;gt;imsg_q)) {
        status = event_add_out(ctx-&amp;gt;evb, s_conn);
        if (status != NC_OK) {
            req_forward_error(ctx, c_conn, msg);
            s_conn-&amp;gt;err = errno;
            return;
        }
    }
    s_conn-&amp;gt;enqueue_inq(ctx, s_conn, msg);
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id42"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id136"&gt;#可能的优化:mget&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="section" id="id43"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id137"&gt;改造&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;single 模式, 支持所有命令, 简单proxy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="key"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id138"&gt;key过长回错误&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id44"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id139"&gt;社区情况&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;pull-request:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;支持select db:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/217"&gt;https://github.com/twitter/twemproxy/pull/217&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/102"&gt;https://github.com/twitter/twemproxy/pull/102&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;支持ping:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/119/files"&gt;https://github.com/twitter/twemproxy/pull/119/files&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;支持auth:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/81"&gt;https://github.com/twitter/twemproxy/pull/81&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;issues 大家的呼声:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;配置热加载 &lt;tt class="docutils literal"&gt;TODO&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/215"&gt;https://github.com/twitter/twemproxy/issues/215&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/6"&gt;https://github.com/twitter/twemproxy/issues/6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;pubsub &lt;tt class="docutils literal"&gt;TODO&lt;/tt&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/130"&gt;https://github.com/twitter/twemproxy/issues/130&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;select/auth/ping 的支持&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/103"&gt;https://github.com/twitter/twemproxy/issues/103&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/102"&gt;https://github.com/twitter/twemproxy/pull/102&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/81"&gt;https://github.com/twitter/twemproxy/pull/81&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;pipeline 下内存消耗:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/158"&gt;https://github.com/twitter/twemproxy/issues/158&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/issues/203"&gt;https://github.com/twitter/twemproxy/issues/203&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;支持sentinel 自动主从切换.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其它人的一些改动:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;openbaas/aduong等同学支持了auth/ping/quit. 已经在twitter/twemproxy 里面的 auth_and_select 分支. 但是select 的支持没做.&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/aduong/twemproxy/compare/0.2.4%2Bquit"&gt;https://github.com/aduong/twemproxy/compare/0.2.4%2Bquit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/aduong/twemproxy/commit/871537d912f3036daeea883d7ed1ef6f642fa15e"&gt;https://github.com/aduong/twemproxy/commit/871537d912f3036daeea883d7ed1ef6f642fa15e&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/twitter/twemproxy/pull/81"&gt;https://github.com/twitter/twemproxy/pull/81&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;另一个同学的后续改动: &lt;a class="reference external" href="https://github.com/jdi-tagged/twemproxy/commit/5ba615865fff547f997998bcc9634ab680d83645"&gt;https://github.com/jdi-tagged/twemproxy/commit/5ba615865fff547f997998bcc9634ab680d83645&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;auth 没什么用, 但是ping和quit, 因为php-redis 里面关连接之前都会quit, 所以有用.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;yuyuyu101/twemproxy 很久以前做了kqueue 的port, 不过没有merge 到主干&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;jbfavre/twemproxy 主要做一些打包工作, 比如debian包.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;shaofengniu/twemproxy 做了很多工作. 代码改动超过5000行.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id45"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id140"&gt;小结&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;twemproxy 对pipeline型的读写, 性能不好.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id46"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id141"&gt;期望&lt;/a&gt;&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ping/auth/quit 的几个支持希望能尽快merge到主干&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="all"></category></entry></feed>